<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Minio</title>
      <link href="/2025/01/01/2025-01-01-Minio/"/>
      <url>/2025/01/01/2025-01-01-Minio/</url>
      
        <content type="html"><![CDATA[<h1 id="Miniio-Docker-部署"><a href="#Miniio-Docker-部署" class="headerlink" title="Miniio Docker 部署"></a>Miniio Docker 部署</h1><pre><code class="language-shell">docker run -d \  --name minio \  -p 9000:9000 \  -p 9001:9001 \  -v /home/docker/minio/data:/data \  -v /home/docker/minio/config:/root/.minio \  -e MINIO_ROOT_USER=admin \  -e MINIO_ROOT_PASSWORD=12345678 \  minio/minio:RELEASE.2024-11-07T00-52-20Z server /data --console-address &quot;:9001&quot; -address &quot;:9000&quot;#服务器的控制台地址为:9090 服务地址为 :9000</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>KingBaseEs</title>
      <link href="/2024/12/26/2024-12-26-KingBaseEs/"/>
      <url>/2024/12/26/2024-12-26-KingBaseEs/</url>
      
        <content type="html"><![CDATA[<h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><pre><code>/home/kingbase/userdata/ docker run -tid --privileged --restart always \-p 4321:54321 \-v /home/docker/kingBaseEs/data/:/home/kingbase/userdata/ \-e NEED_START=yes  \-e DB_USER=kingbase  \-e DB_PASSWORD=123456 \-e DB_MODE=mysql  \--name kingbase  \kingbase_v008r006c008b0014_single_x86:v1 /usr/sbin/init b5844c77f5cdc64ffab138dbd2c4f6a3b91d3215c77fffdbc9fbbbc5befbc2b4</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>2024-12-02-Artifactory</title>
      <link href="/2024/12/02/2024-12-02-Artifactory/"/>
      <url>/2024/12/02/2024-12-02-Artifactory/</url>
      
        <content type="html"><![CDATA[<pre><code class="language-shell">docker pull docker.bintray.io/jfrog/artifactory-oss:latest</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>2024-11-27-PostgreSQL</title>
      <link href="/2024/11/27/2024-11-27-PostgreSQL/"/>
      <url>/2024/11/27/2024-11-27-PostgreSQL/</url>
      
        <content type="html"><![CDATA[<h2 id="DOCKER部署"><a href="#DOCKER部署" class="headerlink" title="DOCKER部署"></a>DOCKER部署</h2><h3 id="单机"><a href="#单机" class="headerlink" title="单机"></a>单机</h3><pre><code>创建env配置文件#pgsqlenv.envPOSTGRES_PASSWORD=123456</code></pre><pre><code class="language-shell"># 指定 端口 指定挂载目录 密码docker run -d --rm --name pgsql  --env-file /home/docker/pgsql/pgsqlenv.env -p 15432:5432 --network inet -v /home/docker/pgsql/data/:/var/lib/postgresql/data/ postgres:14.10</code></pre><h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><h2 id="创建-用户-数据库"><a href="#创建-用户-数据库" class="headerlink" title="创建 用户 数据库"></a>创建 用户 数据库</h2><pre><code class="language-shell">#连接到容器内docker exec -it pgsql psql -U postgres$ psql (14.10 (Debian 14.10-1.pgdg120+1))$ Type &quot;help&quot; for help.#\q 退出postgres=# \q</code></pre><pre><code>创建用户 CREATE USER sonar WITH PASSWORD &#39;123456&#39;;创建数据库CREATE DATABASE sonarqubedb;赋权GRANT ALL PRIVILEGES ON DATABASE sonarqubedb TO sonar;</code></pre><h2 id="备份和恢复"><a href="#备份和恢复" class="headerlink" title="备份和恢复"></a>备份和恢复</h2><pre><code class="language-shell">#备份#pg_dump  -U username -h hostname dbname &gt; backup.sql#pg_dumpall  -U username -h hostname  &gt; backupall.sql#-U 指定用户名#-h 指定服务器的主机名（可选，如果是在本地可以省略）#dbname 是要备份的数据库名。#backup.sql 是备份文件的名字docker exec -it psql pg_dumpall  -U sonar sonarqubedb &gt; /home/sonaralldb.sql  docker exec -it psql pg_dumpall  -U sonar  &gt; backall.sql  #恢复#psql -U username -h hostname -d dbname -f backup.sql#-U 指定用户名。#-h 指定服务器的主机名（可选，如果是在本地可以省略）。#-d 指定要恢复到的数据库名。#-f 指定备份文件docker exec -it psql -U sonar -d sonarqubedb  -f sonaralldb.sql</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> PostgreSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自动化质量分析</title>
      <link href="/2024/11/27/2024-11-27-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B4%A8%E9%87%8F%E5%88%86%E6%9E%90/"/>
      <url>/2024/11/27/2024-11-27-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B4%A8%E9%87%8F%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>准备<a href="''">gitlib</a>  准备sonar需要的数据库<a href="''">PostgreSQL</a></p><h2 id="SonarQube-部署"><a href="#SonarQube-部署" class="headerlink" title="SonarQube 部署"></a>SonarQube 部署</h2><pre><code class="language-shell">#启用临时容器 复制出默认配置docker run --rm -d sonarqube:10.7.0-community# 复制配置文件docker cp ba50e4b9d592:/opt/sonarqube/conf/ /home/docker/sonar/conf/</code></pre><blockquote><p>修改&#x2F;home&#x2F;docker&#x2F;sonar&#x2F;conf&#x2F;下的配置文件 sonar.properties 调整数据库连接信息 </p></blockquote><pre><code>sonar.jdbc.username=sonarsonar.jdbc.password=123456sonar.jdbc.url=jdbc:postgresql://pgsql:5432/sonarqubedb?currentSchema=public</code></pre><pre><code class="language-shell">#设置官方推荐的值sudo sysctl -w vm.max_map_count=524288sudo sysctl -w fs.file-max=131072sudo ulimit -n 131072sudo ulimit -u 8192docker run -d --rm --name sonarqube  -p 19000:9000 \-v /home/docker/sonar/conf:/opt/sonarqube/conf \-v /home/docker/sonar/data:/opt/sonarqube/data \-v /home/docker/sonar/logs:/opt/sonarqube/logs \-v /home/docker/sonar/extensions:/opt/sonarqube/extensions \--privileged=true --network inet sonarqube:10.7.0-community# 查看启动日志 docker logs -f sonarqube</code></pre><blockquote><p>登录 ip:19000   默认 账号 admin 密码 admin (测试修改Qwer1234.1234)</p></blockquote><h2 id="集成gitlab-sonar的自动化质量分析"><a href="#集成gitlab-sonar的自动化质量分析" class="headerlink" title="集成gitlab+sonar的自动化质量分析"></a>集成gitlab+sonar的自动化质量分析</h2><ul><li><strong>为sonar创建gitlab token</strong></li></ul><img src="/.io//11/27/2024-11-27-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B4%A8%E9%87%8F%E5%88%86%E6%9E%90/gitlab_create_token.png" class title="创建token 创建token"><img src="/.io//11/27/2024-11-27-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B4%A8%E9%87%8F%E5%88%86%E6%9E%90/gitlab_get_token.png" class title="glpat-APfX39mKPqwgZdNpsmzT 得到token"><ul><li><strong>sonar 配置gitlab</strong><blockquote><p>进入sonar 配置  进入配置页面 选择gitlab 配置gitlab的url和token 然后再配置具体导入的项目</p></blockquote></li></ul><img src="/.io//11/27/2024-11-27-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B4%A8%E9%87%8F%E5%88%86%E6%9E%90/sonar-gitlab-config.png" class title="sonar配置 sonar配置"><img src="/.io//11/27/2024-11-27-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B4%A8%E9%87%8F%E5%88%86%E6%9E%90/sonar-gitlab-config2.png" class title="sonar配置 sonar配置"><img src="/.io//11/27/2024-11-27-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B4%A8%E9%87%8F%E5%88%86%E6%9E%90/sonar-gitlab-config1.png" class title="sonar配置 sonar配置"><img src="/.io//11/27/2024-11-27-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B4%A8%E9%87%8F%E5%88%86%E6%9E%90/sonar-config-key.png" class title="sonar配置 sonar配置"><ul><li><strong>部署&#x2F;配置gitlibrunner</strong><blockquote><p>为自动化准备代码提交的编译  打包 以及sonar的自动分析 需要 maven 和 sonar-scanner </p></blockquote></li><li><ul><li>gitlib-runner<blockquote><p>部署docker gitlab-runner  执行器为docker</p></blockquote></li></ul></li></ul><pre><code class="language-shell">docker run -d --name gitlab-runner --privileged=true -v /var/run/docker.sock:/var/run/docker.sock -v /home/docker/gitlab-runner/config:/etc/gitlab-runner --network inet gitlab/gitlab-runner:latestdocker exec -it gitlab-runner gitlab-runner register \  --non-interactive \  --url &quot;http://gitlab/&quot;\  --registration-token &quot;glrt-pZPKN7V8FN1auqag6mTR&quot; \  --executor &quot;docker&quot;\  --docker-image maven-runner:1.0.0 \    --description &quot;docker-runner&quot; \  --tag-list &quot;docker,aws&quot; \  --run-untagged=&quot;true&quot; \  --locked=&quot;false&quot; \  --access-level=&quot;not_protected&quot;</code></pre><p>可在&#x2F;etc&#x2F;gitlab-runner&#x2F;config.toml配置执行器</p><pre><code class="language-toml">concurrent = 1check_interval = 0[session_server]  session_timeout = 1800[[runners]]  name = &quot;Docker-mavenGitLab-Runner&quot;  url = &quot;http://gitlab&quot;  token = &quot;&quot;  executor = &quot;docker&quot;  [runners.docker]    tls_verify = false    image = &quot;maven-runner:1.0.0&quot;    privileged = false    disable_cache = false    volumes = [&quot;/cache&quot;]    shm_size = 0  [runners.cache]    Type = &quot;s3&quot;    Path = &quot;s3 - cache - path&quot;    Shared = true</code></pre><ul><li><ul><li>maven-runner</li></ul></li></ul><pre><code class="language-Dockerfile">FROM openjdk:11-jdk-alpineENV MAVEN_VERSION =3.9.9# 设置工作目录WORKDIR /usr/local# 下载maven 到 /usr/local 并解压RUN wget https://dlcdn.apache.org/maven/maven-3/3.9.9/binaries/apache-maven-3.9.9-bin.tar.gz \&amp;&amp; tar -zxvf /usr/local/apache-maven-3.9.9-bin.tar.gz# 将本地的Maven安装文件复制到容器中（如果需要自定义Maven版本）# ADD apache-maven-3.9.9-bin.tar.gz /usr/local# 设置Maven环境变量（如果是复制安装文件的方式）ENV MAVEN_HOME /usr/local/apache-maven-3.9.9# 将Maven添加到PATH环境变量中（如果是复制安装文件的方式）ENV PATH $PATH:$MAVEN_HOME/binCMD [&quot;bash&quot;]</code></pre><pre><code class="language-shell">docker image build --no-cache -t maven-runner:1.0.0 .docker run --rm -d  --name maven-runner maven-runner:1.0.0</code></pre><p>修改gitlab-ci.yml</p><pre><code class="language-yaml">stages:          # List of stages for jobs, and their order of execution  - mavenbuildstage: mavenbuild # Docker in Docker。官方建议显式指定相同版本号，以免版本不一致导致的兼容性问题。 image: docker:20.10.16 services:  - docker:20.10.16-dind script:   - docker run --name projectname-maven-runner -d --rm  maven-runner bash echo &quot;Compiling the code...&quot; after_script:  # 4. 删除本地镜像  - docker stop projectname-maven-runner tags:  - projectname-maven-runner</code></pre><ul><li>-sonar-scanner</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> gitlib </tag>
            
            <tag> sonar </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式事务</title>
      <link href="/2024/11/04/2024-11-04-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
      <url>/2024/11/04/2024-11-04-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h3 id="事务四大特性ACID"><a href="#事务四大特性ACID" class="headerlink" title="事务四大特性ACID"></a>事务四大特性ACID</h3><ul><li>A（Atomic）：原子性，构成事务的所有操作，要么都执行完成，要么全部不执行，不可能出现部分成功部分失败的情况。</li><li>C（Consistency）：一致性，在事务执行前后，数据库的一致性约束没有被破坏。比如：张三向李四转 100 元，转账前和转账后的数据是正确状态这叫一致性，如果出现张三转出 100 元，李四账户没有增加 100 元这就出现了数 据错误，就没有达到一致性。</li><li>I（Isolation）：隔离性，数据库中的事务一般都是并发的，隔离性是指并发的两个事务的执行互不干扰，一个事务不能看到其他事务的运行过程的中间状态。通过配置事务隔离级别可以比避免脏读、重复读问题。</li><li>D（Durability）：持久性，事务完成之后，该事务对数据的更改会持久到数据库，且不会被回滚。</li></ul><h3 id="CAP原则"><a href="#CAP原则" class="headerlink" title="CAP原则"></a>CAP原则</h3><ul><li>一致性(Consistency)：所有节点在同一时间具有相同的数据</li><li>可用性(Availability) ：保证每个请求不管成功或者失败都有响应(某个系统的某个节点挂了，但是并不影响系统的接受或者发出请求)</li><li>分区容错性(Partition tolerance) 系统中任意信息的丢失或失败不会影响系统的继续运作 (在整个系统中某个部分，挂掉了，或者宕机了，并不影响整个系统的运作或者说使用)</li></ul><h3 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h3><ul><li>Basically Available(基本可用)<br>基本可用就是假设系统某个模块出现了不可预知的故障，但其他模块依旧可用。</li><li>Soft State(软状态)<br>软状态指的是允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。</li><li>Eventually Consistent(最终一致性)<br>上面讲到的软状态不可能一直是软状态，必须有时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性，因此所有客户端对系统的数据访问最终都能够获取到最新的值，而这个时间期限取决于网络延时，系统负载，数据复制方案等因素。</li></ul><h3 id="seata-分布式事务"><a href="#seata-分布式事务" class="headerlink" title="seata 分布式事务"></a>seata 分布式事务</h3><h4 id="seata部署"><a href="#seata部署" class="headerlink" title="seata部署"></a>seata部署</h4><p>1.准备注册中心 nacos  存储使用<a href="https://zhangzt123.github.io/2021/07/20/2021-07-20-Mysql%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/">mysql</a></p><pre><code class="language-shell">#mysql参考Mysql安装以及常用命令#nacos-standalone.envPREFER_HOST_MODE=hostnameMODE=standaloneSPRING_DATASOURCE_PLATFORM=mysqlNACOS_AUTH_IDENTITY_KEY=2222NACOS_AUTH_IDENTITY_VALUE=2xxxNACOS_AUTH_TOKEN=SecretKey012345678901234567890123456789012345678901234567890123456789# 启动nacosdocker run -d  --name nacos2 --hostname=&quot;nacos2&quot; \--env-file /home/docker/nacos/nacos-standalone.env \-v /home/docker/nacos/logs/:/home/nacos/logs/ -v /home/docker/nacos/conf/application.properties:/home/nacos/conf/application.properties \-p 8848:8848 -p 9848:9848 --network inet --restart always  nacos/nacos-server:v2.4.3</code></pre><p>2.准备seata-server 服务端 配置 复制出配置文件 并修改 参考application.example.yml<br>docker run -d -p 8091:8091 -p 7091:7091  –name seata-serve seataio&#x2F;seata-server:latest<br>docker cp seata-serve:&#x2F;seata-server&#x2F;resources &#x2F;User&#x2F;seata&#x2F;config</p><pre><code class="language-yml">#server:  port: 7091spring:  application:    name: seata-serverconsole:  user:    username: seata    password: seatalogging:  config: classpath:logback-spring.xml  file:    path: /home/logs/seataseata:  security:      secretKey: &#39;seata&#39;      tokenValidityInMilliseconds: 1000000  config:    # support: nacos 、 consul 、 apollo 、 zk  、 etcd3    type: nacos    nacos:      server-addr: nacos2:8848      namespace:      group: SEATA_GROUP      data-id: seataServer.properties  registry:    # support: nacos 、 eureka 、 redis 、 zk  、 consul 、 etcd3 、 sofa    type: nacos    preferred-networks: 30.240.*    nacos:      application: seata-server      server-addr: nacos2:8848      group: SEATA_GROUP      namespace:      cluster: default  server:    service-port: 8091    max-commit-retry-timeout: -1    max-rollback-retry-timeout: -1    rollback-retry-timeout-unlock-enable: false    enableCheckAuth: true    retryDeadThreshold: 130000    xaerNotaRetryTimeout: 60000    recovery:      handle-all-session-period: 1000    undo:      log-save-days: 7      log-delete-period: 86400000    session:      branch-async-queue-size: 5000 #branch async remove queue size      enable-branch-async-remove: false #enable to asynchronous remove branchSession  store:    # support: file 、 db 、 redis    mode: db    session:      mode: db    lock:      mode: db#db和redis为高可用模式db需要新建的表如下#https://github.com/apache/incubator-seata/tree/develop/script/server/db    db:      datasource: druid      db-type: mysql      driver-class-name: com.mysql.jdbc.Driver      url: jdbc:mysql://mysql:3306/seata?rewriteBatchedStatements=true      user: root      password: 123456      min-conn: 5      max-conn: 100      global-table: global_table      branch-table: branch_table      lock-table: lock_table      distributed-lock-table: distributed_lock      query-limit: 100      max-wait: 5000  metrics:    enabled: false    registry-type: compact    exporter-list: prometheus    exporter-prometheus-port: 9898  transport:    rpc-tc-request-timeout: 30000    enable-tc-server-batch-send-response: false    shutdown:      wait: 3    thread-factory:      boss-thread-prefix: NettyBoss      worker-thread-prefix: NettyServerNIOWorker      boss-thread-size: 1</code></pre><p>3.启动seata-server cluster</p><pre><code class="language-shell">docker run -d --rm --name seata-server \        -p 8091:8091 \        -p 7091:7091 \        -v /home/docker/seata/logs:/home/logs/seata/ \        -v /home/docker/seata/config:/seata-server/resources  \        --network inet \        seataio/seata-server:1.5.0</code></pre><h4 id="Seata-模式"><a href="#Seata-模式" class="headerlink" title="Seata 模式"></a>Seata 模式</h4><h5 id="XA模式"><a href="#XA模式" class="headerlink" title="XA模式"></a>XA模式</h5><h5 id="AT模式"><a href="#AT模式" class="headerlink" title="AT模式"></a>AT模式</h5><h5 id="TCC模式"><a href="#TCC模式" class="headerlink" title="TCC模式"></a>TCC模式</h5><h5 id="saga模式"><a href="#saga模式" class="headerlink" title="saga模式"></a>saga模式</h5><h4 id="seata示例"><a href="#seata示例" class="headerlink" title="seata示例"></a>seata示例</h4>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>kafka的介绍及使用</title>
      <link href="/2024/10/23/2024-10-23-kafka%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
      <url>/2024/10/23/2024-10-23-kafka%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="AMQP协议"><a href="#AMQP协议" class="headerlink" title="AMQP协议"></a>AMQP协议</h2><blockquote><p>&emsp;&emsp;AMQP，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端&#x2F;中间件不同产品，不同的开发语言等条件的限制。Erlang中的实现有RabbitMQ等。</p></blockquote><h2 id="docker-集群部署"><a href="#docker-集群部署" class="headerlink" title="docker 集群部署"></a>docker 集群部署</h2><h3 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h3><blockquote><p>首先部署<a href="https://zhangzt123.github.io/2019/11/11/2020-02-29-zookeeper%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/">zookeeper集群</a>（参考zookepper集群安装配置）然后创建日志目录log1 log2 log3 用于挂载 然后创建三个配置文件配置 server.properties 每台机器 borker.id</p></blockquote><p>配置文件 三个服务的broker.id各不同 需要区分开</p><pre><code>############################# Server Basics #############################broker.id=1#broker.id=2#broker.id=3zookeeper.connect=zk1:2181,zk2:2181,zk3:2181############################# Socket Server Settings #############################......############################# Log Basics ############################## A comma separated list of directories under which to store log fileslog.dirs=/kfk/logs......</code></pre><p>启动docker kafka容器 默认的entrypoint执行时会覆盖配置文件 虽然可通过环境变量方式配置 但这边采用挂载配置文件的方式 通过指定命令的方式执行 在最后添加&#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-server-start.sh &#x2F;opt&#x2F;kafka&#x2F;config&#x2F;server.properties</p><pre><code class="language-shell">docker run -d --rm --name kfk1 --hostname=&quot;kfk1&quot; -e JMX_PORT=&quot;19987&quot; -e KAFKA_JMX_OPTS=&quot;-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false&quot;  -v /home/docker/kafka/config/kfk1/:/opt/kafka/config/ -v /home/docker/kafka/logs/log1:/kfk/logs -p 19091:19091 -p 19987:19987 --network inet  apache/kafka:3.8.0 /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties\&amp;&amp;\docker run -d --rm --name kfk2 --hostname=&quot;kfk2&quot; -e JMX_PORT=&quot;19988&quot; -e KAFKA_JMX_OPTS=&quot;-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false&quot;  -v /home/docker/kafka/config/kfk2/:/opt/kafka/config/ -v /home/docker/kafka/logs/log2:/kfk/logs -p 19092:19092 -p 19988:19988  --network inet  apache/kafka:3.8.0 /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties\&amp;&amp;\docker run -d --rm --name kfk3 --hostname=&quot;kfk3&quot; -e JMX_PORT=&quot;19989&quot; -e KAFKA_JMX_OPTS=&quot;-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false&quot;  -v /home/docker/kafka/config/kfk3/:/opt/kafka/config/ -v /home/docker/kafka/logs/log3:/kfk/logs -p 19093:19093 -p 19989:19989  --network inet  apache/kafka:3.8.0 /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties</code></pre><ul><li>EFAK<blockquote><p>准备解压好的efak文件 通过dockerfile打包成自制容器</p></blockquote></li></ul><pre><code class="language-Dockerfile">FROM openjdk:11-jdk# 更换国内镜像源并安装ke.sh执行必要的工具RUN echo &quot;deb https://mirrors.ustc.edu.cn/debian/ bookworm main contrib non-free non-free-firmware \deb-src https://mirrors.ustc.edu.cn/debian/ bookworm main contrib non-free non-free-firmware \deb https://mirrors.ustc.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware \deb-src https://mirrors.ustc.edu.cn/debian/ bookworm-updates main contrib non-free non-free-firmware \deb https://mirrors.ustc.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware \deb-src https://mirrors.ustc.edu.cn/debian/ bookworm-backports main contrib non-free non-free-firmware \deb https://mirrors.ustc.edu.cn/debian-security/ bookworm-security main contrib non-free non-free-firmware \deb-src https://mirrors.ustc.edu.cn/debian-security/ bookworm-security main contrib non-free non-free-firmware&quot; &gt; /etc/apt/sources.list &amp;&amp; \apt-get update &amp;&amp; apt-get install -y procps gawk coreutils # 复制efak文件 entrypoint 文件到容器内COPY ./efak-web-3.0.1 ./entrypoint.sh  /opt/efak/WORKDIR /opt/efak/#ke必要的环境变量ENV KE_HOME=/opt/efak/ENTRYPOINT [&quot;/opt/efak/entrypoint.sh&quot; ]</code></pre><pre><code class="language-shell">#entrypoint 执行ke.sh 并通过tail阻塞#!/bin/bashnohup /opt/efak/bin/ke.sh start ;\tail -f /opt/efak/logs/log.log</code></pre><p>执行打包命令</p><pre><code class="language-shell">docker image build -f ./Dockerfile -t efak:1.0.0 .</code></pre><p>efak的配置文件</p><pre><code class="language-properties">#system-config.properties####################################### multi zookeeper &amp; kafka cluster list# Settings prefixed with &#39;kafka.eagle.&#39; will be deprecated, use &#39;efak.&#39; instead####################################### efak.zk.cluster.alias=cluster1,cluster2efak.zk.cluster.alias=cluster1cluster1.zk.list=zk1:2181,zk2:2181,zk3:2181.........####################################### kafka sqlite jdbc driver address 使用sqlite记得创建/hadoop/kafka-eagle/db/ 目录######################################efak.driver=org.sqlite.JDBCefak.url=jdbc:sqlite:/hadoop/kafka-eagle/db/ke.dbefak.username=rootefak.password=www.kafka-eagle.org####################################### kafka mysql jdbc driver address####################################### efak.driver=com.mysql.cj.jdbc.Driver# efak.url=jdbc:mysql://127.0.0.1:3306/ke?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull# efak.username=root# efak.password=123456</code></pre><p>启动容器</p><pre><code class="language-shell">docker run --rm   --name efak --hostname=&quot;efak&quot; -v /home/docker/efak/system-config.properties:/opt/efak/conf/system-config.properties -v /hadoop/kafka-eagle/db/:/hadoop/kafka-eagle/db/  -p 8048:8048 --network inet  efak:1.0.0</code></pre><p>全部启动后 docker ps </p><pre><code class="language-shell">zhangzhitong@zhangzhitong-virtual-machine:/home/docker/efak$ docker psCONTAINER ID   IMAGE                COMMAND                   CREATED          STATUS          PORTS                                                                                                                                             NAMES397e8a1986f7   efak:1.0.0           &quot;/opt/efak/entrypoin…&quot;   21 minutes ago   Up 21 minutes   0.0.0.0:8048-&gt;8048/tcp, :::8048-&gt;8048/tcp                                                                                                         efak4344959a4507   apache/kafka:3.8.0   &quot;/__cacert_entrypoin…&quot;   8 hours ago      Up 8 hours      0.0.0.0:19093-&gt;19093/tcp, :::19093-&gt;19093/tcp, 9092/tcp, 0.0.0.0:19989-&gt;19989/tcp, :::19989-&gt;19989/tcp                                            kfk3952e64d71704   apache/kafka:3.8.0   &quot;/__cacert_entrypoin…&quot;   8 hours ago      Up 8 hours      0.0.0.0:19092-&gt;19092/tcp, :::19092-&gt;19092/tcp, 9092/tcp, 0.0.0.0:19988-&gt;19988/tcp, :::19988-&gt;19988/tcp                                            kfk294de141e0da4   apache/kafka:3.8.0   &quot;/__cacert_entrypoin…&quot;   8 hours ago      Up 8 hours      0.0.0.0:19091-&gt;19091/tcp, :::19091-&gt;19091/tcp, 9092/tcp, 0.0.0.0:19987-&gt;19987/tcp, :::19987-&gt;19987/tcp                                            kfk16b53bd089bec   zookeeper:3.9.2      &quot;/docker-entrypoint.…&quot;   10 hours ago     Up 10 hours     8080/tcp, 0.0.0.0:12183-&gt;2181/tcp, :::12183-&gt;2181/tcp, 0.0.0.0:32772-&gt;2888/tcp, :::32772-&gt;2888/tcp, 0.0.0.0:32773-&gt;3888/tcp, :::32773-&gt;3888/tcp   zk332526de8b56f   zookeeper:3.9.2      &quot;/docker-entrypoint.…&quot;   10 hours ago     Up 10 hours     8080/tcp, 0.0.0.0:12182-&gt;2181/tcp, :::12182-&gt;2181/tcp, 0.0.0.0:32770-&gt;2888/tcp, :::32770-&gt;2888/tcp, 0.0.0.0:32771-&gt;3888/tcp, :::32771-&gt;3888/tcp   zk2c945f184a078   zookeeper:3.9.2      &quot;/docker-entrypoint.…&quot;   10 hours ago     Up 10 hours     8080/tcp, 0.0.0.0:12181-&gt;2181/tcp, :::12181-&gt;2181/tcp, 0.0.0.0:32768-&gt;2888/tcp, :::32768-&gt;2888/tcp, 0.0.0.0:32769-&gt;3888/tcp, :::32769-&gt;3888/tcp   zk1</code></pre><img src="/.io//10/23/2024-10-23-kafka%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/overview.png" class title="efak管理界面1 http:&#x2F;&#x2F;localhost:8048&#x2F;"><img src="/.io//10/23/2024-10-23-kafka%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/zk.png" class title="efak管理界面zk http:&#x2F;&#x2F;localhost:8048&#x2F;"><img src="/.io//10/23/2024-10-23-kafka%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/kfk.png" class title="efak管理界面kfk http:&#x2F;&#x2F;localhost:8048&#x2F;"><img src="/.io//10/23/2024-10-23-kafka%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/tv.png" class title="efak管理界面tv http:&#x2F;&#x2F;localhost:8048&#x2F;"><h3 id="Kraft"><a href="#Kraft" class="headerlink" title="Kraft"></a>Kraft</h3><p>docker kafka 通过inspect命令查看镜像启动执行了一个&#x2F;__cacert_entrypoint.sh &#x2F;etc&#x2F;kafka&#x2F;docker&#x2F;run  -&gt; run -&gt; configureDefaults-&gt;configure-&gt;launch  依次通过cat 命令查看，最后发现执行的是&#x2F;opt&#x2F;kafka&#x2F;bin&#x2F;kafka-server-start.sh &#x2F;opt&#x2F;kafka&#x2F;config&#x2F;server.properties 那么集群配置则需要对&#x2F;opt&#x2F;kafka&#x2F;config&#x2F;server.properties该配置文件进行挂载修改即可</p><h3 id="zookeeper向Kraft迁移"><a href="#zookeeper向Kraft迁移" class="headerlink" title="zookeeper向Kraft迁移"></a>zookeeper向Kraft迁移</h3>]]></content>
      
      
      <categories>
          
          <category> MQ </category>
          
          <category> 消息中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch</title>
      <link href="/2024/10/05/2024-10-05-Pytorch/"/>
      <url>/2024/10/05/2024-10-05-Pytorch/</url>
      
        <content type="html"><![CDATA[<p>有时间再研究</p><hr>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ElatsicSearch使用及相关问题</title>
      <link href="/2024/09/06/2024-09-06-ElatsicSearch%E4%BD%BF%E7%94%A8%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/"/>
      <url>/2024/09/06/2024-09-06-ElatsicSearch%E4%BD%BF%E7%94%A8%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a><em>搭建</em></h2><hr><h3 id="单机"><a href="#单机" class="headerlink" title="单机"></a>单机</h3><hr><pre><code class="language-shell">docker run -d --name es-single -e ES_JAVA_OPTS=&quot;-Xms512m -Xmx2048m&quot; -v /home/docker/es/config/single:/usr/share/elasticsearch/config -v /home/docker/es/data/single:/usr/share/elasticsearch/data -v /home/docker/es/logs/single:/usr/share/elasticsearch/logs -p 9200:9200 -p 9300:9300 --network inet  elasticsearch:8.1.0docker run -d --name kibana-single -p 5601:5601 -e ELASTICSEARCH_HOSTS=http://es-single:9200 -e I18N_LOCALE=zh-CN -v /home/docker/kibana/config/kibana-single.yml:/usr/share/kibana/config/kibana.yml --network inet  kibana:8.1.0</code></pre><pre><code class="language-conf">#es-singlecluster.name: &quot;docker-single&quot;network.host: 0.0.0.0discovery.type: single-node  #单节点模式# Enable security featuresxpack.security.enabled: falsexpack.security.enrollment.enabled: falsexpack.security.http.ssl:  enabled: true  keystore.path: certs/http.p12xpack.security.transport.ssl:  enabled: true  verification_mode: certificate  keystore.path: certs/transport.p12  truststore.path: certs/transport.p12  ...</code></pre><pre><code class="language-conf">#Kibana-single# Default Kibana configuration for docker targetserver.host: &quot;0.0.0.0&quot;server.shutdownTimeout: &quot;5s&quot;elasticsearch.hosts: [ &quot;http://172.17.0.1:9200&quot; ]monitoring.ui.container.elasticsearch.enabled: truei18n.locale: &quot;zh-CN&quot;</code></pre><h3 id="集群CLUSTER"><a href="#集群CLUSTER" class="headerlink" title="集群CLUSTER"></a>集群CLUSTER</h3><hr><img src="/.io//09/06/2024-09-06-ElatsicSearch%E4%BD%BF%E7%94%A8%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/es_cluster.png" class title="master和data分开集群"><blockquote><p>&emsp;</p></blockquote><pre><code class="language-shell">### 启动三master 三datadocker run -d  --name master-a -e ES_JAVA_OPTS=&quot;-Xms1024m -Xmx1024m&quot; -v /home/docker/es/config/master1:/usr/share/elasticsearch/config -v /home/docker/es/data/master1:/usr/share/elasticsearch/data -v /home/docker/es/logs/master1:/usr/share/elasticsearch/logs -p ::9200 -p ::9300 --network inet  elasticsearch:8.1.0\&amp;&amp;\docker run -d  --name master-b -e ES_JAVA_OPTS=&quot;-Xms1024m -Xmx1024m&quot; -v /home/docker/es/config/master2:/usr/share/elasticsearch/config -v /home/docker/es/data/master2:/usr/share/elasticsearch/data -v /home/docker/es/logs/master2:/usr/share/elasticsearch/logs -p ::9200 -p ::9300 --network inet  elasticsearch:8.1.0\&amp;&amp;\docker run -d  --name master-c -e ES_JAVA_OPTS=&quot;-Xms1024m -Xmx1024m&quot; -v /home/docker/es/config/master3:/usr/share/elasticsearch/config -v /home/docker/es/data/master3:/usr/share/elasticsearch/data -v /home/docker/es/logs/master3:/usr/share/elasticsearch/logs -p ::9200 -p ::9300 --network inet  elasticsearch:8.1.0\&amp;&amp;\docker run -d  --name es-data1 -e ES_JAVA_OPTS=&quot;-Xms1024m -Xmx1024m&quot; -v /home/docker/es/config/data1:/usr/share/elasticsearch/config -v /home/docker/es/data/data1:/usr/share/elasticsearch/data -v /home/docker/es/logs/data1:/usr/share/elasticsearch/logs -p ::9200 -p ::9300 --network inet  elasticsearch:8.1.0\&amp;&amp;\docker run -d  --name es-data2 -e ES_JAVA_OPTS=&quot;-Xms1024m -Xmx1024m&quot; -v /home/docker/es/config/data2:/usr/share/elasticsearch/config -v /home/docker/es/data/data2:/usr/share/elasticsearch/data -v /home/docker/es/logs/data2:/usr/share/elasticsearch/logs -p ::9200 -p ::9300 --network inet  elasticsearch:8.1.0\&amp;&amp;\docker run -d  --name es-data3 -e ES_JAVA_OPTS=&quot;-Xms1024m -Xmx1024m&quot; -v /home/docker/es/config/data3:/usr/share/elasticsearch/config -v /home/docker/es/data/data3:/usr/share/elasticsearch/data -v /home/docker/es/logs/data3:/usr/share/elasticsearch/logs -p ::9200 -p ::9300 --network inet  elasticsearch:8.1.0</code></pre><pre><code class="language-yml">#master 配置三台#集群名称 如果改变名称则需要整个集群重启cluster.name: my-es-cluster#节点名称 默认为主机名node.name: master-node-a#node.name: master-node-b#node.name: master-node-c#指定节点角色为主节点node.roles: [ master ]path.data: /usr/share/elasticsearch/data#绑定ip,开启远程访问,可以配置0.0.0.0network.host: 0.0.0.0#单节点(single-node)还是多节点 默认为多节点discovery.type: multi-node#主节点选举投票最小节点数 （候选节点数/2+1 eg 3/2+1 ） 从7开始最新版本已无该配置#discovery.zen.minimum_master_nodes: 2#用于集群发现discovery.seed_hosts:   - master-a:9300   - master-b:9300   - master-c:9300#指定哪些节点被初始化为主节点cluster.initial_master_nodes:    - master-node-a   - master-node-b   - master-node-c#----------------------- BEGIN SECURITY AUTO CONFIGURATION -----------------------xpack.security.enabled: falsexpack.security.enrollment.enabled: falsexpack.security.http.ssl:  enabled: true  keystore.path: certs/http.p12xpack.security.transport.ssl:  enabled: true  verification_mode: certificate  keystore.path: certs/transport.p12  truststore.path: certs/transport.p12#----------------------- END SECURITY AUTO CONFIGURATION -------------------------</code></pre><pre><code class="language-yml">#data节点 配置三台#集群名称 如果改变名称则需要整个集群重启cluster.name: my-es-cluster#节点名称 默认为主机名node.name: data-node-a#node.name: data-node-b#node.name: data-node-c#指定节点角色为主节点node.roles: [ data ]path.data: /usr/share/elasticsearch/data#绑定ip,开启远程访问,可以配置0.0.0.0network.host: 0.0.0.0#单节点(single-node)还是多节点 默认为多节点discovery.type: multi-node#用于集群发现discovery.seed_hosts:   - master-a:9300   - master-b:9300   - master-c:9300#指定哪些节点被初始化为主节点cluster.initial_master_nodes:    - master-node-a   - master-node-b   - master-node-c#----------------------- BEGIN SECURITY AUTO CONFIGURATION -----------------------xpack.security.enabled: falsexpack.security.enrollment.enabled: falsexpack.security.http.ssl:  enabled: true  keystore.path: certs/http.p12xpack.security.transport.ssl:  enabled: true  verification_mode: certificate  keystore.path: certs/transport.p12  truststore.path: certs/transport.p12#----------------------- END SECURITY AUTO CONFIGURATION -------------------------</code></pre><pre><code class="language-conf">#Kibana-single# Default Kibana configuration for docker targetserver.host: &quot;0.0.0.0&quot;server.shutdownTimeout: &quot;5s&quot;elasticsearch.hosts: [ &quot;http://master-a:9200&quot; ,&quot;http://master-b:9200&quot;,&quot;http://master-c:9200&quot;]monitoring.ui.container.elasticsearch.enabled: truei18n.locale: &quot;zh-CN&quot;</code></pre><blockquote><p>&emsp;查看集群节点 集群状态</p></blockquote><pre><code class="language-shell">#查看集群节点curl http://localhost:9200/_cat/nodes?vip         heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name172.18.0.5           12          98   8    1.39    1.47     0.98 d         -      data-node-a172.18.0.2           22          98   8    1.39    1.47     0.98 m         *      master-node-a172.18.0.3           35          98   8    1.39    1.47     0.98 m         -      master-node-b172.18.0.4           40          98   8    1.39    1.47     0.98 m         -      master-node-c#集群健康curl http://localhost:9200/_cluster/health?pretty&#123;  &quot;cluster_name&quot; : &quot;my-es-cluster&quot;,  &quot;status&quot; : &quot;green&quot;,  &quot;timed_out&quot; : false,  &quot;number_of_nodes&quot; : 4,  &quot;number_of_data_nodes&quot; : 1,  &quot;active_primary_shards&quot; : 7,  &quot;active_shards&quot; : 7,  &quot;relocating_shards&quot; : 0,  &quot;initializing_shards&quot; : 0,  &quot;unassigned_shards&quot; : 0,  &quot;delayed_unassigned_shards&quot; : 0,  &quot;number_of_pending_tasks&quot; : 0,  &quot;number_of_in_flight_fetch&quot; : 0,  &quot;task_max_waiting_in_queue_millis&quot; : 0,  &quot;active_shards_percent_as_number&quot; : 100.0&#125;</code></pre><h4 id="节点-Node"><a href="#节点-Node" class="headerlink" title="节点 Node"></a>节点 Node</h4><hr><blockquote><p><strong>节点数据路径设置</strong> 配置文件中配置 path.data:  &#x2F;var&#x2F;elasticsearch&#x2F;data 也可以使用命令方式 elasticsearch -Epath.data&#x3D;&#x2F;var&#x2F;elasticsearch&#x2F;data</p></blockquote><h5 id="Coordinating-Node"><a href="#Coordinating-Node" class="headerlink" title="Coordinating Node"></a>Coordinating Node</h5><blockquote><p><strong>Coordinating Node</strong>：协调节点(我理解为读节点) 负责接受Client的请求， 将请求分发到合适的节点，最终把结果汇集到一起 每个节点启动后默认都是 coordinating 节点。设置其他类型全部为 false</p></blockquote><blockquote><p><strong>Coordinating only node</strong>：单协调节点  该节点设置为负责协调 处理路由请求、处理搜索缩减阶段和分发批量索引等 ,不负责主数据和数据的存储，但过多的单协调节点会增加集群负担 配置方式 node.roles: [ ] </p></blockquote><h5 id="Ingest-Node"><a href="#Ingest-Node" class="headerlink" title="Ingest Node"></a>Ingest Node</h5><blockquote><p><strong>Ingest Node</strong>：摄取节点可以执行由一个或多个摄取处理器组成的预处理管道。根据摄取处理器执行的操作类型和所需资源 默认节点启动都是 通过node.roles: [ ingest ] 配置</p></blockquote><h5 id="Master-eligible-nodes"><a href="#Master-eligible-nodes" class="headerlink" title="Master eligible nodes"></a>Master eligible nodes</h5><blockquote><p><strong>Master eligible nodes</strong>：候选主节点,专注于管理集群。有资格成为主节点的节点也会充当协调节点,但不应将专用主节点用于此目的 每个节点启动后，默认就是一个Master eligible节点，即都可以参与集群选举，成为Master节点。通过node.roles: [ master ]设置</p></blockquote><blockquote><p><strong>Voting-only master-eligible node</strong>:投票专用的有主节点资格的节点是一种参与主节点选举但不会作为集群中被选出的主节点的节点, 仅用于投票 通过 node.roles: [  master, voting_only ]设置 同时也可以担任其他角色。例如数据节点  node.roles: [ data, master, voting_only ]</p></blockquote><h5 id="Data-Node"><a href="#Data-Node" class="headerlink" title="Data Node"></a>Data Node</h5><blockquote><p><strong>Generic data node</strong>：通用数据节点 包括所有数据节点，负责保存分片数据 节点启动后，默认就是数据节点。数据节点包含索引content 通过node.roles: [ data ]设置</p></blockquote><blockquote><p><strong>Content data node</strong>: 内容数据节点是内容层的一部分。存储在内容层中的数据通常是一系列项目的集合，例如产品目录或文章档案。与时间序列数据不同，内容的值在一段时间内相对保持恒定，所以随着时间推移将其移动到具有不同性能特征的层是没有意义的。内容数据通常有很长的数据保留要求，并且无论数据有多旧，都希望能够快速检索到项目<br>内容层是必需的。系统索引和其他不属于数据流的索引会自动分配到内容层。</p></blockquote><blockquote><p><strong>Hot data node</strong>:  热数据节点是热层的一部分。热层是时间序列数据进入 Elasticsearch 的入口，保存着你最近、最常搜索的时间序列数据。热层中的节点在读取和写入方面都需要快速，这需要更多的硬件资源和更快的存储（固态硬盘）。为了实现弹性，热层中的索引应配置为使用一个或多个副本。 通过node.roles: [ data_hot ]设置</p></blockquote><blockquote><p><strong>Warm data node</strong>：温数据节点是温层的一部分。时间序列数据在被查询的频率低于热层中最近索引的数据时，可以移动到温层。温层通常保存最近几周的数据。仍然允许更新，但可能不频繁。温层中的节点通常不需要像热层中的节点那样快速。为了提高弹性，温层中的索引应配置为使用一个或多个副本。 通过node.roles: [ data_warm ]设置</p></blockquote><blockquote><p><strong>Cold data node</strong>:冷数据节点是冷层的一部分。当你不再需要定期搜索时间序列数据时，它可以从温层移动到冷层。虽然仍然可搜索，但这个层通常针对较低的存储成本而非搜索速度进行优化 通过node.roles: [ data_cold ]设置</p></blockquote><blockquote><p><strong>Frozen data node</strong>:冻结数据节点 一旦数据不再被查询，或者很少被查询，它可能会从冷层移动到冻结层，通过node.roles: [ data_frozen ]设置</p></blockquote><h5 id="Remote-eligible-node"><a href="#Remote-eligible-node" class="headerlink" title="Remote-eligible node"></a>Remote-eligible node</h5><blockquote><p><strong>Remote-eligible node</strong>: 远程节点 可以连接到远程集群 可以跨集群搜索和同步数据</p></blockquote><h5 id="Machine-Learning-Node"><a href="#Machine-Learning-Node" class="headerlink" title="Machine Learning Node"></a>Machine Learning Node</h5><blockquote><p><strong>Machine Learning Node</strong>：负责跑机器学习的节点 node.roles: [ ml, remote_cluster_client]</p></blockquote><h5 id="Transform-node"><a href="#Transform-node" class="headerlink" title="Transform node"></a>Transform node</h5><blockquote><p><strong>Transform node</strong>：转换节点运行转换并处理转换 API 请求 node.roles: [ transform, remote_cluster_client ]</p></blockquote><h4 id="分片-Shard"><a href="#分片-Shard" class="headerlink" title="分片 Shard"></a>分片 Shard</h4><blockquote><p>主分片 ：Primary Shard，主要是用于解决数据水平扩展的问题，通过主分片，可以将数据分发到集群的所有结点上面，每一个分片是一个Lucene的一个实例，分片在创建之后，不允许被修改，因为获取数据需要通过hash取模运算，改了数量就会直接影响结果<br>副本分片 ： Replica Shard，用于解决数据高可用的问题，就是主分片的一个拷贝，主分片数在创建之后不允许被修改，副本分片数是允许被修改的，并且在一定程度上，可以通过增加副本数来提高服务读取数据的性能。但是副本分片最好是设置成0或者1，如果是日志数据，可以直接设置为0，如果是商品信息这种检索数据，那么可以直接设置成为1。</p></blockquote><h4 id="分段存储-Segments"><a href="#分段存储-Segments" class="headerlink" title="分段存储 Segments"></a>分段存储 Segments</h4><blockquote><p>索引文档以段的形式存储在磁盘上，索引文件被拆分为多个子文件，则每个子文件叫作段，每一个段本身都是一个倒排索引，并且段具有不变性，一旦索引的数据被写入硬盘，就不可再修改。<br>在底层采用了分段存储模式，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能。<br>段被写入到磁盘后会生成一个提交点，提交点是一个用来记录所有提交后段信息的文件。<br>一个段一旦拥有了提交点，就说明这个段只有读的权限，失去了写的权限 。相反， 当段在内存中时，就只有写的权限，而不具备读数据的权限，意味着不能被检索。<br>段的概念提出主要是因为：在早期全文检索中为整个文档集合建立了一个很大的倒排索引，并将其写入磁盘中。如果索引有更新，就需要重新全量创建一个索引来替换原来的索引。这种方式在数据量很大时效率很低，并且由于创建一次索引的成本很高，所以对数据的更新不能过于频繁，也就不能保证时效性。</p></blockquote><blockquote><p>段的不变性的优点：<br>不需要锁，如果从来不更新索引，那就不需要担心多进程同时修改数据的问题。一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。其它缓存(像Filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。写入单个大的倒排索引允许数据被压缩，减少磁盘I&#x2F;O和需要被缓存到内存的索引的使用量。</p></blockquote><blockquote><p>段的不变性的缺点：<br>当对旧数据进行删除时，旧数据不会马上被删除，而是在.del文件中被标记为删除。而旧数据只能等到段更新时才能被移除，这样会造成大量的空间浪费。若有一条数据频繁的更新，每次更新都是新增新的标记旧的，则会有大量的空间浪费。每次新增数据时都需要新增一个段来存储数据。当段的数量太多时，对服务器的资源例如文件句柄的消耗会非常大。在查询的结果中包含所有的结果集，需要排除被标记删除的旧数据，这增加了查询的负担。</p></blockquote><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><hr><h4 id="增删改查"><a href="#增删改查" class="headerlink" title="增删改查"></a>增删改查</h4><ul><li><p>ES支持的字段类型</p><blockquote><p>text<br>keyword<br>date<br>float</p></blockquote></li><li><p>创建索引</p></li></ul><pre><code class="language-json">PUT /test_index&#123;  &quot;settings&quot;: &#123;    //更多参考https://www.cainiaojc.com/elasticsearch/elasticsearch-index-modules.html    &quot;index&quot;:&#123;        //索引具有的分片的数量        &quot;number_of_shards&quot;: 6,        //每个主分片具有的副本数。        &quot;number_of_replicas&quot;: 1     &#125;  &#125;,  //字段类型定义  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;filed1&quot;: &#123;        &quot;type&quot;: &quot;text&quot;      &#125;,      &quot;filed2&quot;: &#123;        &quot;type&quot;: &quot;keyword&quot;      &#125;,      &quot;filed3&quot;: &#123;        &quot;type&quot;: &quot;date&quot;      &#125;,      &quot;filed4&quot;: &#123;        &quot;type&quot;: &quot;float&quot;      &#125;    &#125;  &#125;&#125;</code></pre><ul><li>修改索引setting</li></ul><pre><code class="language-json">PUT /test_index/_settings&#123;  &quot;index&quot;:&#123;  //每个主分片具有的副本数。  &quot;number_of_replicas&quot;: 0   &#125; &#125;</code></pre><h2 id="ES-常见问题汇总及解决方案"><a href="#ES-常见问题汇总及解决方案" class="headerlink" title="ES 常见问题汇总及解决方案"></a><em>ES 常见问题汇总及解决方案</em></h2><hr><h3 id="启动异常"><a href="#启动异常" class="headerlink" title="启动异常"></a>启动异常</h3><h4 id="max-virtual-memory-areas-vm-max-map-count-65530-is-too-low-increase-to-at-least-262144"><a href="#max-virtual-memory-areas-vm-max-map-count-65530-is-too-low-increase-to-at-least-262144" class="headerlink" title="max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]"></a>max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</h4><blockquote><p>系统中的 vm.max_map_count 参数设置的值太低  编辑 &#x2F;etc&#x2F;sysctl.conf  添加 vm.max_map_count&#x3D;262144  通过sudo sysctl -p 使之生效</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> ElatsicSearch </tag>
            
            <tag> es </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis使用及相关问题</title>
      <link href="/2024/08/29/2024-08-29-Redis%E4%BD%BF%E7%94%A8%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/"/>
      <url>/2024/08/29/2024-08-29-Redis%E4%BD%BF%E7%94%A8%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis基本使用"><a href="#Redis基本使用" class="headerlink" title="Redis基本使用"></a><em>Redis基本使用</em></h2><h3 id="Redis数据结构"><a href="#Redis数据结构" class="headerlink" title="Redis数据结构"></a>Redis数据结构</h3><ul><li><p>字符串(String)</p><blockquote><p>set</p></blockquote></li><li><p>列表(List)</p><blockquote><p>list</p></blockquote></li><li><p>哈希(Hash) </p><blockquote><p>hash </p></blockquote></li><li><p>集合(Set)</p><blockquote><p>set</p></blockquote></li><li><p>有序集合(Zset)</p><blockquote><p>set</p></blockquote></li><li><p>HyperLogLogs (基数统计) </p><blockquote><p>…</p></blockquote></li><li><p>Bitmap (位存储)</p><blockquote><p>…</p></blockquote></li><li><p>geospatial (地理位置)</p><blockquote><p>…</p></blockquote></li></ul><h3 id="Docker搭建-主从-哨兵-集群"><a href="#Docker搭建-主从-哨兵-集群" class="headerlink" title="Docker搭建 主从  哨兵 集群"></a>Docker搭建 主从  哨兵 集群</h3><hr><blockquote><p>配置文件示例 <a href="https://github.com/redis/redis/blob/7.4.0/redis.conf">https://github.com/redis/redis/blob/7.4.0/redis.conf</a> <a href="https://github.com/redis/redis/blob/7.4.0/sentinel.conf">https://github.com/redis/redis/blob/7.4.0/sentinel.conf</a></p></blockquote><h4 id="Docker搭建单例Redis"><a href="#Docker搭建单例Redis" class="headerlink" title="Docker搭建单例Redis"></a>Docker搭建单例Redis</h4><pre><code class="language-shell">#单例运行docker run -d --name redis -v /home/docker/redis/config/redis-single.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/:/data/  -p 6379:6379 --rm redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf#操作docker exec -it containerId redis-cli</code></pre><pre><code class="language-conf">#redis.conf################################## NETWORK ######################################不要用127.0.0.1 绑定具体的ip 否则无法通过redis-cli -h ip -p port 进行外部访问# bind 192.168.1.100 10.0.0.1     # listens on two specific IPv4 addresses# bind 127.0.0.1 ::1              # listens on loopback IPv4 and IPv6# bind * -::*                     # like the default, all available interfacesbind * -::*#关闭保护模式否则只能本机访问protected-mode noport 6379################################# GENERAL #####################################pidfile /var/run/redis_6379.pidloglevel notice#日志文件logfile &quot;/data/redis-master.log&quot;databases 16################################ SNAPSHOTTING  ################################save 3600 1 300 100 60 1#存储文件dbfilename redis_master_dump.rdb# Note that you must specify a directory here, not a file name.dir ./################################# REPLICATION #################################replica-serve-stale-data yesreplica-read-only yesrepl-diskless-sync yesrepl-diskless-sync-delay 5repl-diskless-sync-max-replicas 0repl-diskless-load disabledrepl-disable-tcp-nodelay no...</code></pre><pre><code class="language-cmd">127.0.0.1:6379&gt; info server# Serverredis_version:7.4.0redis_git_sha1:00000000redis_git_dirty:0redis_build_id:a4a1a8bba24ad866redis_mode:standaloneos:Linux 6.8.0-40-generic x86_64arch_bits:64monotonic_clock:POSIX clock_gettimemultiplexing_api:epollatomicvar_api:c11-builtingcc_version:12.2.0process_id:1process_supervised:norun_id:076e63887ee1e69251e0c523f27e2ee28399f9eetcp_port:6379server_time_usec:1726197123775604uptime_in_seconds:1438uptime_in_days:0hz:10configured_hz:10lru_clock:14921091executable:/data/redis-serverconfig_file:/usr/local/etc/redis/redis.confio_threads_active:0listener0:name=tcp,bind=127.0.0.1,bind=-::1,port=6379</code></pre><h4 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h4><img src="/.io//08/29/2024-08-29-Redis%E4%BD%BF%E7%94%A8%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/master-salve.png" class><pre><code class="language-shell">#使用自定义的网络#masterdocker run -d --name redis-master -v /home/docker/redis/config/redis-master.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/:/data/ -v /home/docker/redis/logs:/usr/local/etc/redis/log/ --network inet -p 6379:6379 --rm  redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf  &amp;&amp;#slave1docker run -d --name redis-slave1 -v /home/docker/redis/config/redis-slave1.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/:/data/ -v /home/docker/redis/logs:/usr/local/etc/redis/log/ --network inet -p 6380:6379 --rm redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf  &amp;&amp;#slave2docker run -d --name redis-slave2 -v /home/docker/redis/config/redis-slave2.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/:/data/ -v /home/docker/redis/logs:/usr/local/etc/redis/log/ --network inet -p 6381:6379 --rm redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf</code></pre><pre><code class="language-conf">#redis.conf################################## NETWORK ######################################不要用127.0.0.1 绑定具体的ip 否则无法通过redis-cli -h ip -p port 进行外部访问# bind 192.168.1.100 10.0.0.1     # listens on two specific IPv4 addresses# bind 127.0.0.1 ::1              # listens on loopback IPv4 and IPv6# bind * -::*                     # like the default, all available interfacesbind * -::*#关闭保护模式否则只能本机访问protected-mode no#masterport 6379#salve1#port 6380#salve2#port 6381################################# GENERAL #####################################pidfile /var/run/redis_6379.pid#pidfile /var/run/redis_6380.pid#pidfile /var/run/redis_6381.pidloglevel notice#日志文件logfile &quot;/data/redis-master.log&quot;#logfile &quot;/data/redis-salve1.log&quot;#logfile &quot;/data/redis-salve2.log&quot;databases 16################################ SNAPSHOTTING  ################################save 3600 1 300 100 60 1#存储文件dbfilename redis_master_dump.rdb#dbfilename redis_salve1_dump.rdb#dbfilename redis_salve2_dump.rdb# Note that you must specify a directory here, not a file name.dir ./################################# REPLICATION ##################################当在从节点配置时指定master# replicaof &lt;masterip&gt; &lt;masterport&gt;#replicaof redis-master 6379...</code></pre><pre><code class="language-cmd"> docker exec -it b822875a5056 redis-cli info REPLICATION# Replicationrole:masterconnected_slaves:2slave0:ip=172.18.0.3,port=6380,state=online,offset=14672,lag=0slave1:ip=172.18.0.4,port=6381,state=online,offset=14672,lag=0master_failover_state:no-failovermaster_replid:bff2af97b86f24cffb57550003a93538fd3aed59master_replid2:c85dd5eb038484fbd9faca0a429066a496722fecmaster_repl_offset:14672second_repl_offset:11859repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:11859repl_backlog_histlen:2814</code></pre><h4 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h4><img src="/.io//08/29/2024-08-29-Redis%E4%BD%BF%E7%94%A8%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/sentinel.png" class><pre><code class="language-shell"># 在主从基础上加入哨兵#Sentinel1docker run -d --name redis-sentinel1 -v /home/docker/redis/config/redis-sentinel.conf:/usr/local/etc/redis/sentinel.conf  -v /home/docker/redis/logs/sentinel1.log:/tmp/sentinel.log  --network inet -p 26379:26379 --rm  redis:7.4.0 redis-sentinel /usr/local/etc/redis/sentinel.conf  &amp;&amp;#Sentinel2docker run -d --name redis-sentinel2 -v /home/docker/redis/config/redis-sentinel.conf:/usr/local/etc/redis/sentinel.conf  -v /home/docker/redis/logs/sentinel2.log:/tmp/sentinel.log  --network inet -p 26380:26379 --rm redis:7.4.0 redis-sentinel /usr/local/etc/redis/sentinel.conf  &amp;&amp;#Sentinel3docker run -d --name redis-sentinel3 -v /home/docker/redis/config/redis-sentinel.conf:/usr/local/etc/redis/sentinel.conf  -v /home/docker/redis/logs/sentinel3.log:/tmp/sentinel.log --network inet -p 26381:26379 --rm redis:7.4.0 redis-sentinel /usr/local/etc/redis/sentinel.conf </code></pre><pre><code class="language-conf">#sentinel.confprotected-mode nodaemonize nopidfile /var/run/redis-sentinel.pidloglevel noticelogfile &quot;/data/sentinel.log&quot;# dir &lt;working-directory&gt;dir /tmp#  监控的master的ip 端口 以及 需要几个sentinel同意#6.2 以上版本的 sentinel 才能解析主机名# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;sentinel monitor mymaster redis-master 6379 2# HOSTNAMES SUPPORT 主机名支持SENTINEL resolve-hostnames yes#SENTINEL announce-hostnames yes...</code></pre><pre><code class="language-shell">#master 正常时docker exec redis-master redis-cli info Replication# Replicationrole:masterconnected_slaves:2slave0:ip=172.18.0.3,port=6380,state=online,offset=103968,lag=0slave1:ip=172.18.0.4,port=6379,state=online,offset=103968,lag=0master_failover_state:no-failovermaster_replid:26974803eec7dc51775e322c38428771928691aemaster_replid2:aa8b907c48b8501f8d8d5f895d4d359913c47897master_repl_offset:103968second_repl_offset:17260repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:17260repl_backlog_histlen:86709#master挂掉  redis-slave1 被选为masterdocker stop redis-masterdocker exec redis-slave1 redis-cli info Replication# Replicationrole:masterconnected_slaves:1slave0:ip=172.18.0.4,port=6379,state=online,offset=140844,lag=0master_failover_state:no-failovermaster_replid:b04d5e13f36a9d9dc8795cf15558b0b4b60f9260master_replid2:26974803eec7dc51775e322c38428771928691aemaster_repl_offset:140844second_repl_offset:130355repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:17260repl_backlog_histlen:123585#master回归正常后 master 变为redis-slave1的从节点docker exec redis-slave1 redis-cli -p 6380 info Replication# Replicationrole:masterconnected_slaves:2slave0:ip=172.18.0.4,port=6379,state=online,offset=170223,lag=0slave1:ip=172.18.0.2,port=6379,state=online,offset=170223,lag=1master_failover_state:no-failovermaster_replid:b04d5e13f36a9d9dc8795cf15558b0b4b60f9260master_replid2:26974803eec7dc51775e322c38428771928691aemaster_repl_offset:170358second_repl_offset:130355repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:17260repl_backlog_histlen:153099</code></pre><h4 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h4><img src="/.io//08/29/2024-08-29-Redis%E4%BD%BF%E7%94%A8%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/cluster.png" class><pre><code class="language-shell">sudo sysctl vm.overcommit_memory=1#docker stop cluster1 cluster2 cluster3 cluster4 cluster5 cluster6docker run -d --name cluster1 -v /home/docker/redis/config/redis-cluster.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/cluster1/:/data/  --network inet -p 6379:6379 -p ::16379  --rm  redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf --cluster-announce-hostname cluster1 --cluster-announce-human-nodename cluster1\&amp;&amp;\docker run -d --name cluster2 -v /home/docker/redis/config/redis-cluster.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/cluster2/:/data/  --network inet -p 6380:6379 -p ::16379  --rm redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf  --cluster-announce-hostname cluster2 --cluster-announce-human-nodename cluster2\&amp;&amp;\docker run -d --name cluster3 -v /home/docker/redis/config/redis-cluster.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/cluster3/:/data/  --network inet -p 6381:6379 -p ::16379  --rm redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf  --cluster-announce-hostname cluster3 --cluster-announce-human-nodename cluster3\&amp;&amp;\docker run -d --name cluster4 -v /home/docker/redis/config/redis-cluster.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/cluster4/:/data/  --network inet -p 6382:6379 -p ::16379  --rm redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf  --cluster-announce-hostname cluster4 --cluster-announce-human-nodename cluster4\&amp;&amp;\docker run -d --name cluster5 -v /home/docker/redis/config/redis-cluster.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/cluster5/:/data/  --network inet -p 6383:6379 -p ::16379  --rm redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf  --cluster-announce-hostname cluster5 --cluster-announce-human-nodename cluster5\&amp;&amp;\docker run -d --name cluster6 -v /home/docker/redis/config/redis-cluster.conf:/usr/local/etc/redis/redis.conf -v /home/docker/redis/data/cluster6/:/data/  --network inet -p 6384:6379 -p ::16379  --rm redis:7.4.0 redis-server /usr/local/etc/redis/redis.conf  --cluster-announce-hostname cluster6 --cluster-announce-human-nodename cluster6# 执行加入集群命令# docker exec -it cluster1 redis-cli --cluster create  cluster1:6379 cluster2:6379 cluster3:6379 cluster4:6379 cluster5:6379 cluster6:6379   --cluster-replicas 1 #输入yes</code></pre><pre><code class="language-conf"># 修改节点端口port 6379bind * -::*logfile &quot;/data/redis.log&quot;# 保护模式改为no，允许外部网络访问protected-mode no# 设置后台运行，改为yesdaemonize no# pid文件路径配置pidfile /var/run/redis_6379.pidsave 3600 1 300 100 60 1dbfilename redis_dump.rdbstop-writes-on-bgsave-error yesrdbcompression yesrdbchecksum yes# 开启集群模式cluster-enabled yes# 集群配置文件，根据端口不同修改cluster-config-file nodes-6379.conf#通过主机名找到集群cluster-preferred-endpoint-type hostname...</code></pre><pre><code class="language-shell">#查看集群信息docker exec -it cluster1 redis-cli cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_ping_sent:178cluster_stats_messages_pong_sent:172cluster_stats_messages_sent:350cluster_stats_messages_ping_received:172cluster_stats_messages_pong_received:178cluster_stats_messages_received:350total_cluster_links_buffer_limit_exceeded:0#docker exec -it cluster1 redis-cli cluster nodes49ae9c854a0122709c784a5653a7a7873d91db4e 172.18.0.7:6379@16379,cluster6 slave d450087aae42a2b9a724e92db72cd0c3402753e7 0 1726544317000 2 connected704651b58d37c065c848faf2a65580e78fec219e 172.18.0.4:6379@16379,cluster3 master - 0 1726544318000 3 connected 10923-163832cdc0f8009cbc5fd39b12ef49a4010cb9dffbd35 172.18.0.5:6379@16379,cluster4 slave 704651b58d37c065c848faf2a65580e78fec219e 0 1726544316459 3 connected36e60ceae53ead77730569651a1780c7b518e9df 172.18.0.2:6379@16379,cluster1 myself,master - 0 0 1 connected 0-5460d450087aae42a2b9a724e92db72cd0c3402753e7 172.18.0.3:6379@16379,cluster2 master - 0 1726544318483 2 connected 5461-109220dccee28bc5b8baa01568f13382cac380f0e66d9 172.18.0.6:6379@16379,cluster5 slave 36e60ceae53ead77730569651a1780c7b518e9df 0 1726544316000 1 connected# 直接连接会让你去cluster2上去操作zhangzhitong@zhangzhitong-virtual-machine:/home/docker$ docker exec cluster1 redis-cli get key1MOVED 9189 cluster2:6379#集群方式连接redis-cli -czhangzhitong@zhangzhitong-virtual-machine:/home/docker$ docker exec cluster1 redis-cli -c get key1zhangzhitong@zhangzhitong-virtual-machine:/home/docker$ docker exec cluster1 redis-cli -c set key1 zztOKzhangzhitong@zhangzhitong-virtual-machine:/home/docker$ docker exec cluster1 redis-cli -c get key1zzt</code></pre><h5 id="哈希槽hashslot"><a href="#哈希槽hashslot" class="headerlink" title="哈希槽hashslot"></a>哈希槽hashslot</h5><blockquote><p>Redis 集群并没有使用一致性 hash，而是引入了哈希槽的概念。Redis 集群有 16384（2^14）个哈<br>希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分<br>hash 槽。<br>集群使用公式slot&#x3D;CRC16（key）&#x2F;16384来计算key属于哪个槽，其中CRC16(key)语句用于计算key的CRC16 校验和</p></blockquote><h5 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h5><blockquote><p>RDB：RDB是Redis默认的持久化方式。按照一定的时间周期策略把内存的数据以快照的形式保存到硬盘的二进制文件。即Snapshot快照存储，对应产生的数据文件为dump.rdb，通过配置文件中的save参数来定义快照的周期。（ 快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品。）</p></blockquote><blockquote><p>AOF：Redis会将每一个收到的写命令都通过Write函数追加到文件最后，类似于MySQL的binlog。当Redis重启是会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。 当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。</p></blockquote><h2 id="Redis常见问题汇总及解决方案"><a href="#Redis常见问题汇总及解决方案" class="headerlink" title="Redis常见问题汇总及解决方案"></a><em>Redis常见问题汇总及解决方案</em></h2><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a><strong>缓存穿透</strong></h3><blockquote><p>数据从缓存中查不到之直接查库仍然未查到  可以通过布隆过滤器解决 </p></blockquote><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a><strong>缓存雪崩</strong></h3><blockquote><p>大量数据从缓存中失效掉 导致数据库被大量访问</p></blockquote><h3 id="如何利用jvm内存和redis做二级缓存-并且保证缓存数据的一致性"><a href="#如何利用jvm内存和redis做二级缓存-并且保证缓存数据的一致性" class="headerlink" title="如何利用jvm内存和redis做二级缓存 并且保证缓存数据的一致性"></a><strong>如何利用jvm内存和redis做二级缓存 并且保证缓存数据的一致性</strong></h3><h3 id="发现大key"><a href="#发现大key" class="headerlink" title="发现大key"></a><strong>发现大key</strong></h3><blockquote><p>bigkey 是指键值占用内存空间非常大的 key。通过命令可以找出</p></blockquote><pre><code class="language-shell">#迭代数据库中的所有键，并为每种类型（字符串、列表、集合、有序集合和哈希）报告最大的键和其大小。redis-cli --bigkeys</code></pre><h3 id="DB和缓存的一致性问题"><a href="#DB和缓存的一致性问题" class="headerlink" title="DB和缓存的一致性问题"></a><strong>DB和缓存的一致性问题</strong></h3><blockquote><p>1.先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那数据就不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存中 2.在高并发时 会出现 一个请求删除了缓存 但在数据写操作未完成时 另一个请求将数据库中的旧值再次写入缓存 导致缓存和数据库不一致。 此时可以对操作进行加锁 保证一个请求的删除和写数据库完成时另一个在去读，或者对同一数据的操作路由分发到同一台机器 将写读操作写入队列 顺序完成 保证数据一致性 同时也会导致请求的倾斜.</p></blockquote><h4 id="延迟双删"><a href="#延迟双删" class="headerlink" title="延迟双删"></a>延迟双删</h4><blockquote><p>先删除缓存 再写数据库 再延迟删除缓存 出现不一致情况较小</p></blockquote><h4 id="异步更新缓存"><a href="#异步更新缓存" class="headerlink" title="异步更新缓存"></a>异步更新缓存</h4><blockquote><p>MySQL binlog 配合canal+kafka增量订阅消费-&gt;消息队列&gt;增量数据更新到redis<br>– </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始学docker(五)</title>
      <link href="/2024/08/29/2024-08-29-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E4%BA%94)/"/>
      <url>/2024/08/29/2024-08-29-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E4%BA%94)/</url>
      
        <content type="html"><![CDATA[<h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a><strong>资源</strong></h2><hr><br><blockquote><p>内存为非可压缩资源 限制避免oom内存溢出<br>发生oom会触发进程被按照相对内存的使用量依次强制杀掉（kill -9 pid） 直到没有异常<br> –oom-score-adj int              Tune host’s OOM preferences (-1000 to 1000)<br>调整优先级 尽量避免被杀掉<br>Ram 物理内存<br>Swap 交换内存<br>-m 设置物理内存使用量<br>–memory-swap *  设置交换内存使用量  必须先限制物理内存 -m<br>–oom-kill-disable 禁止发生oom时被kill 必须先限制物理内存 -m</p></blockquote><hr><table border="5"><thead><tr>    <td width="150px">--memory-swap</td>    <td width="100px">--memory</td>    <td>功能</td></tr></thead><tbody></tbody><tr>    <td>正数S</td>    <td>正数M</td><td>容器可用空间为S其中 RAM为M swap为（S-M）若S=M 则无可用swap资源</td></tr><tr>    <td>0</td>    <td>正数M</td><td>相当于未设置swap</td></tr><tr>    <td>unset</td>    <td>正数M</td><td>若docker host 开启swap 容器可用则为2M </td></tr><tr>    <td>-1</td>    <td>正数M</td><td>若docker host 开启swap 则容器可使用主机全部swap资源  </td></tr></table><p>__*NOTE:__在容器中使用free命令查看的swap并不具有展示空间的指示意义。</p><blockquote><p>Cpu 为可压缩性资源<br>进程优先级交由cfs 内核调度器调整<br>进程分2类：<br>Cpu密集型<br>IO密集型<br>     –cpu-period int                 Limit CPU CFS (Completely Fair Scheduler) period<br>     –cpu-quota int                  Limit CPU CFS (Completely Fair Scheduler) quota<br>     –cpu-rt-period int              Limit CPU real-time period in microseconds限制cpu使用时间<br>     –cpu-rt-runtime int             Limit CPU real-time runtime in microseconds<br>  -c, –cpu-shares int                 CPU shares (relative weight)<br>     –cpus decimal                   Number of CPUs<br>     –cpuset-cpus string             CPUs in which to allow execution (0-3, 0,1)运行在那个cpu上 0开始<br>     –cpuset-mems string             MEMs in which to allow execution (0-3, 0,1)<br>docker top containername 查看资源使用情况</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始学docker(四)</title>
      <link href="/2023/01/26/2023-01-26-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E5%9B%9B)/"/>
      <url>/2023/01/26/2023-01-26-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E5%9B%9B)/</url>
      
        <content type="html"><![CDATA[<h2 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a><strong>镜像</strong></h2><br><blockquote><p>镜像采用分层构建 联合挂载 机制 最底层为bootfs (用于系统引导的文件系统 包括bootloader和kernel 容器启动后会被卸载),然后是rootfs(位于bootfs<br>之上表现为docker的根文件系统 由内核挂载为只读模式，在在镜像最上面挂载可写层。)</p></blockquote><p><img src="/.io//image.png" alt="image.png"></p><h3 id="镜像构建"><a href="#镜像构建" class="headerlink" title="镜像构建"></a><strong>镜像构建</strong></h3><br><pre><code class="language-shell"># 镜像构建命令docker image build -f DockerFile Context</code></pre><br><p><font color="#008000"><strong>NOTE</strong></font></p><blockquote><ul><li>注释信息 以# 开头</li><li>语句顺序执行</li><li>对大小写不敏感 约定俗称 关键字使用大写</li><li>第一个非注释行必须为FROM 命令 通过一个已有镜像制作</li><li>由于docker采用分层结构所以 每条语句都会产生新的层 ，所以尽量将语句放在一起写</li><li>主要 COPY ADD 本地文件时可以使用任何指的文件夹下的内容<br>docker build path|url|-</li></ul><p>   eg:  docker build . 指的是当前目录 所以只能使用当前目录下的文件</p><ul><li>可在dockerfile同目录下添加.dockerignore忽略文件 类似于git的.ignore</li><li>环境变量参数使用$param 或者${param}<br>${param+word}变量不为空使用word<br>${param-word} 变量为空使用默认值word</li></ul></blockquote><table><thead><tr><th>关键字</th><th>描述</th></tr></thead><tbody><tr><td>FROM</td><td>镜像来源</td></tr><tr><td>MAINTANIER</td><td>【使用：MAINTANIER “<a href="mailto:&#x7a;&#122;&#116;&#122;&#122;&#x74;&#64;&#101;&#109;&#97;&#105;&#x6c;&#46;&#x63;&#x6f;&#x6d;">zztzzt@email.com</a>“】镜像作者</td></tr><tr><td>LABEL</td><td>使用:单行多个&#x2F;多行 <br>LABEL key&#x3D;val key1&#x3D;val1 ….. <br> LABEL key&#x3D;val <br>LABEL  key1&#x3D;val1</td></tr><tr><td>COPY</td><td>复制文件到容器 COPY src target  src可以是多个为目录时则必须以&#x2F;结尾<br>COPY [–chown&#x3D;<user>:<group>] src… target<br>COPY [–chown&#x3D;<user>:<group>] [“src”,… “target”]</group></user></group></user></td></tr><tr><td>ADD</td><td>添加文件到容器 使用：<br> ADD src … target  <br> ADD [“src”,”src”….”target”]</td></tr><tr><td>VOLUME</td><td>指的用于挂载的目录挂载点 保证在容器启动时如果忘记指的会默认创建一个匿名存储卷来存储挂载点是不,这样容器消失后数据可以被保存下来.  使用:<br> VOLUME &#x2F;date <br> VOLUME &#x2F;date &#x2F;date1 <br>VOLUME[“&#x2F;date”,”&#x2F;date1”….. ]</td></tr><tr><td>EXPOSE</td><td>用于为容器打开指定要监听的端口实现与外部通信【EXPOSE 8080 8080&#x2F;tcp 8080&#x2F;udp】 tcp 和udp二选一 默认为tcp 该端口为可以暴露的接口 启动时并不会直接暴露</td></tr><tr><td>ENV</td><td>用于为镜像定义所需环境变量 可被dockerfile文件之后的指令所使用  和docker run –env 不同 此处是用在build过程中设置好的环境变量 【使用：ENV key&#x3D;val key1&#x3D;val1 ….. 】\反斜杠在此处还可用于转义空格<br> eg: COPY XXXXX  $key1</td></tr><tr><td>ARG</td><td>参数 可通过–build-arg key&#x3D;val 传入 也可被ENV使用<br>eg:<br> ARG author&#x3D;zzt<br> ENV AUTHOR&#x3D;${author+default}</td></tr><tr><td>RUN</td><td>运行sh命令在build过程【使用 ：RUN 命令1 &amp;&amp; 命令2 】 仅可运行基础镜像中存在的命令</td></tr><tr><td>CMD</td><td>运行命令在启动过程 <br>仅可运行基础镜像中存在的命令 <br>多个命令仅最后一个生效 <br>命令可以被docker run 启动时的命令替换掉<br>数组写法不可使用环境变量参数<br></td></tr><tr><td>ENTRYPOINT</td><td>和CMD相比 默认情况命令不会类替换掉 如要替换 <br>使用Docker container run –entrypoints “” container<br>定义多个ENTRYPOINT 最后一个生效<br>和CMD同时存在情况下 CMD会被当做参数交给ENTRYPOINT 执行<br>可通过添加entrypoint.sh 来让ENTRYPOINT 执行该文件 带入参数</td></tr><tr><td>USER</td><td>指定再容器中用哪个用户运行 USER user[:group] 或者USER UID[:GID]</td></tr><tr><td>ONBUILD</td><td>添加触发器 触发命令可以是dockerfile支持的任何命令 构建命令不会在自身文件构建是触发，在另一个镜像基于该镜像构建时会先触发该指令在处理后面的指令</td></tr><tr><td>HEALTHCHECK</td><td>健康检查<br>–interval&#x3D;30s(default) 每隔30检查一次<br>–timeout&#x3D; 30s (default) 超时时间<br>–start-period&#x3D; 0s  (default) 启动时健康检查延迟时间（等待程序启动完成）<br>–retries&#x3D;3 (default) 允许的失败次数</td></tr><tr><td>SHELL</td><td>指定程序默认要使用的shell程序<br> SHELL [“执行工具”,”参数”,”参数”, ….]</td></tr><tr><td>STOPSIGNAL</td><td>指定推出时的信号值 可以是SIG&lt; name &gt; 也可以是与内核syscall表中的位置匹配的无符号数字，例如9。默认值为SIGTERM</td></tr></tbody></table><p><br><br></p><ul><li>示例</li></ul><pre><code class="language-Dockerfile">#注释FROM image:tagMAINTANIER 镜像作者LABEL key1=val1 key2=val2WORKDIR /home/dockerCOPY ./testfile /home/ADD  ./testfile1 /home/VOLUME /date0VOLUME /date1 /date2VOLUME [&quot;/date3&quot;,&quot;/date4&quot;]USER zzt:zztgroupEXPOSE 80EXPOSE 8080/tcp 9090/udpSHELL [&quot;/bin/bash&quot;, &quot;-c&quot;]RUN touch fileSTOPSIGNAL SIGSTOPCMD [&quot;java&quot;,&quot;-server&quot; ,&quot;-jar&quot;,&quot;xxxx.jar&quot;]# CMD [&quot;&lt;command&gt;&quot;,&quot;param1&quot;,&quot;param2&quot;....]HEALTHCHECK --interval=30s --timeout= 30s --start-period= 0s --retries=3 CMD curl -f http://localhost:8080/ ||exit 1</code></pre><h3 id="多段构建"><a href="#多段构建" class="headerlink" title="多段构建"></a><strong>多段构建</strong></h3><br>>docker版本大于17.05 >多段构建时后面镜像可以基于之前镜像作为基础镜像 在镜像中为要构建的镜像添加AS标签进行关联 构建时默认不指定--target 标签时会全部构建 并且只有最后一个会获得imageName和tag 指定标签后 会从第一个开始构建直到指定的标签为止。比如 docker image build -f Dockerfile_state -t myweb1:v1 --target Myweb2  ./ 会从myweb1一直构建到myweb2 后面则不进行构建<br><pre><code class="language-DOCKERFILE">FROM openjdk:8 AS Myweb1LABEL  name=&quot;Myweb1&quot; \       author=zztLABEL createtime =2023.01.11FROM Myweb1 AS Myweb2LABEL  name1=&quot;Myweb2&quot; \       author=zztLABEL createtime =2023.01.11FROM Myweb1 AS Myweb3LABEL  name1=&quot;Myweb3&quot; \       author=zztLABEL createtime =2023.01.11FROM Myweb1 AS Myweb4LABEL  name1=&quot;Myweb4&quot; \       author=zztLABEL createtime =2023.01.11</code></pre><h4 id="BuildKit工具镜像构建"><a href="#BuildKit工具镜像构建" class="headerlink" title="BuildKit工具镜像构建"></a><strong><a href="https://docs.docker.com/build/buildkit/">BuildKit</a>工具镜像构建</strong></h4><blockquote><ul><li>docker版本大于18.06</li><li>通过docker daemon.json添加  {“features”: { “buildkit” : true }} 或者命令行输入$DOCKER_BUILDKIT&#x3D;1 docker build .</li><li>支持 # syntax&#x3D;docker&#x2F;dockerfile:1.2 文件开始添加 指的使用dockerfile的版本语法</li></ul></blockquote><h2 id="dockerCompose"><a href="#dockerCompose" class="headerlink" title="dockerCompose"></a><strong>dockerCompose</strong></h2><blockquote><p>&emsp;一个可以一次多个容器的工具使用yml作为配置。 <a href="https://docs.docker.com/compose/compose-file/compose-versioning/">compose-version</a>兼容版本映射关系</p></blockquote><h3 id="dockerCompose构建-运行镜像"><a href="#dockerCompose构建-运行镜像" class="headerlink" title="dockerCompose构建|运行镜像"></a><strong>dockerCompose构建|运行镜像</strong></h3><pre><code class="language-shell">#构建镜像docker compose -f MyDockerCompose.yml --profile dev  build#启动镜像docker compose -f MyDockerCompose.yml --profile dev  up#启动镜像 后台运行docker compose -f MyDockerCompose.yml --profile dev  up -d</code></pre><blockquote><p>示例</p></blockquote><pre><code class="language-yml">version: &quot;3.9&quot; #指定兼容的版本信息services:  myweb: #你的服务名    # container_name: myweb-compose #容器名称 如果指定则副本数量只能是1个    profiles:      - dev      - pro#构建信息定义    build: #指定服务是构建还是镜像 build image 2者不可同时出现      context: . #指定上下文 docker build path的path   . 当前目录      dockerfile: ./Dockerfile #dockerfile文件      args: #参数 相当于 docker build --build-arg        stoptime: 10        stoptime1: 10      labels: #标签 可以写入到镜像中        version: &quot;v1&quot;        redisversion: &quot;7.0.7&quot;      tags: #镜像标签 可多个        - &quot;myweb:v1&quot;      platforms: #镜像平台 linux/arm64/v8  windows/amd64 osx        - &quot;linux/amd64&quot;#部署信息定义    deploy:      mode: replicated # 部署模式 replicated（指定个数副本） 和 global （每个物理节点一个）      replicas: 2 # replicated副本模式时候指定副本个数      restart_policy: #重启策略         condition: on-failure #重启条件 none,on-failure,any        delay: 0s #等待重启时间间隔        max_attempts: 3 #重启允许失败次数 condition =any 是不允许指定        window: 1m #等待重启成功的空窗期      rollback_config: #回滚配置        parallelism: 1 #每次回滚的容器数.0全部容器同时回滚        delay: 0s #每组容器回滚的等待时间 默认0s        failure_action: pause #失败后要做的操作 continue or pause        monitor: 1m # 失败后每次更新任务到监控的时间 默认0S  允许单位(ns|us|ms|s|m|h)        max_failure_ratio: 0 # 回滚失败率 默认0        order: stop-first #回滚期间的操作顺序 stop-first(先停止再启动) start-first(先启动再停止)      update_config: #更新配置        parallelism: 1 #每次更新的容器数.0全部容器同时回滚        delay: 0s #每组容器更新的等待时间 默认0s        failure_action: pause #失败后要做的操作 continue or pause        monitor: 1m # 失败后每次更新任务到监控的时间 默认0S  允许单位(ns|us|ms|s|m|h)        max_failure_ratio: 0 # 更新失败率 默认0        order: stop-first #更新期间的操作顺序 stop-first(先停止再启动) start-first(先启动再停止)      endpoint_mode: vip #访问集群服务的方式 vip(虚拟ip) dnsrr(轮询)2种      labels:        mylable: &quot;lable&quot;#存储卷信息定义       volumes:       - type: volume #type包括 volume, bind, tmpfs         source: mydata #存储卷或者地址 tmpfs类型时无效        target: //home/docker/data0001 #挂载到容器内地址        read_only: false #存储卷是只读的        volume:          nocopy: true      - type: bind #type包括 volume, bind, tmpfs         source: /home/docker/data0002 #tmpfs类型时无效        target: /data #挂载到容器内地址        read_only: true #存储卷是只读的        bind:          propagation: private #绑定类型传播机制 rprivate, private, rshared, shared, rslave, slave          create_host_path: true # 自动创建本地路径          selinux: Z #z (shared) or Z (private)    # volumes_from: # 从某个容器或服务名复制来相同的挂载信息    #   - service_name    #   - service_name:ro    #   - container:container_name    #   - container:container_name:rw#网络信息定义    ports:      # - &quot;3000&quot;      # - &quot;3000-3005&quot;      - &quot;8080-8090:8080&quot;      # - &quot;9090-9091:8080-8081&quot;      # - &quot;49100:22&quot;      # - &quot;127.0.0.1:8001:8001&quot;      # - &quot;127.0.0.1:5000-5010:5000-5010&quot;      # - &quot;6060:6060/udp&quot;    expose: #容器可暴露端口      - &quot;8080&quot;    networks: #网络配置 可指定多个顶层networks的key      - myweb-network1      # - myweb-network2    command: [&quot;java&quot;,&quot;-jar&quot;,&quot;demo.jar&quot;] #命令 相当于docker run xxxcontainer command    # entrypoint: xxxx.sh    # entrypoint:  # 会覆盖镜像中的entrypoint指令    #   - java    #   - -jar    #   - demo.jar    # env_file: #添加环境变量通过文件 文件格式 key=val #用于注释    #    - .env      environment: #添加环境变量  environment和env_file同时出现优先取environment       - aaa=bbb    # extends: #从另一个compose文件扩展    #   file: xxxx.yml    #   service: xxxx    healthcheck: #健康检查      disable: true #禁用健康检查      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:8080&quot;]  # test如果使用list则第一个必须是NONE, CMD or CMD-SHELL中的一个      # test: [&quot;CMD-SHELL&quot;, &quot;curl -f http://localhost:8080||exit 1&quot;]      # test: curl -f http://localhost:8080||exit 1       interval: 1m30s      timeout: 10s      retries: 3      start_period: 40s  mywebmvntemplate:    profiles:      - dev      - pro    build:      context: .      dockerfile: ./Dockerfile_v1      tags:        - &quot;myweb_mvn_template:v1&quot;  mywebbytemp:    profiles:      - dev      - pro    depends_on: # 指定相互之间的依赖 简单写法|添加条件写法      - mywebmvntemplate#     depends_on:#       mywebmvntemplate:# # 依赖条件 service_started service_healthy service_completed_successfully#         condition: service_healthy    build:      context: .      dockerfile: ./Dockerfile_v2      tags:        - &quot;mywebbytemp:v1&quot;    ports:      - &quot;9090:8080&quot;  myimageapp:    profiles:      - dev      - pro    image: mywebbytemp:v1    depends_on:      # - mywebmvntemplate      - mywebbytemp    ports:      - &quot;9091:8080&quot;volumes: #顶层位置可以存储卷被多个服务使用 mydata值为空 会根据默认配置创建存储卷  mydata:    name: &quot;my-data&quot; #自定义卷名称    labels:      - &quot;key=val&quot;      - &quot;key2=val2&quot;    #external: true #external为true则不会自动创建mydata没有时会报错networks: #顶层网络配置  myweb-network1:    name: myweb-network1    external: false #为true时不创建该网络找不到该网络报错    driver: overlay #网络驱动汇总    attachable: true # 是否连接到该网络    labels:      - &quot;key1=val1&quot;      - &quot;key2=val2&quot;</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始学docker(三)</title>
      <link href="/2023/01/26/2023-01-26-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E4%B8%89)/"/>
      <url>/2023/01/26/2023-01-26-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E4%B8%89)/</url>
      
        <content type="html"><![CDATA[<h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a><strong>网络</strong></h2><table><thead><tr><th>网络驱动汇总</th><th>描述</th></tr></thead><tbody><tr><td>none</td><td>无网络</td></tr><tr><td>bridge</td><td>桥接 多个容器之间通过桥接网络交互</td></tr><tr><td>Host</td><td>主机网络 容器应用使用主机的网络</td></tr><tr><td>overlay</td><td>叠加网络 应用在多台机器之间通过叠加网络交互</td></tr><tr><td>ipvlan</td><td>虚拟ip</td></tr><tr><td>macvlan</td><td>Mac的虚拟ip网络</td></tr><tr><td>Third-party network plugins</td><td>三方网络插件</td></tr></tbody></table><br><h3 id="容器网络"><a href="#容器网络" class="headerlink" title="容器网络"></a><strong>容器网络</strong></h3><blockquote><p>2个容器之间共享同一个网络 ip 端口等,除去网络外其他的2个容器之间是相互隔离的 比如文件系统 主机名等</p></blockquote><p><img src="/.io//container.png" alt="container.png"></p><pre><code class="language-shell">docker container run -d  --name mynginx1 -P nginx95132de6a078docker container run -d --network container:95132de6a078  --name myredis -P  redisCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                                     NAMES5eff2b7c0866   redis     &quot;docker-entrypoint.s…&quot;   14 seconds ago   Up 13 seconds                                             myredis95132de6a078   nginx     &quot;/docker-entrypoint.…&quot;   22 minutes ago   Up 22 minutes   0.0.0.0:32768-&gt;80/tcp, :::32768-&gt;80/tcp   mynginxdocker inspect 5eff2b7c0866[    &#123;        &quot;Id&quot;: &quot;5eff2b7c0866749c28eeba80453fe163fdc9de6b3702084cd5b561346fdf606d&quot;,        ...        &quot;HostConfig&quot;: &#123;             ...            &quot;NetworkMode&quot;: &quot;container:95132de6a0783684dd208328247f96194609d7ebec58465271f7b36906f786d0&quot;,            ...        &#125;,        ...        &quot;NetworkSettings&quot;: &#123;            &quot;Bridge&quot;: &quot;&quot;,            &quot;SandboxID&quot;: &quot;&quot;,            &quot;HairpinMode&quot;: false,            &quot;LinkLocalIPv6Address&quot;: &quot;&quot;,            &quot;LinkLocalIPv6PrefixLen&quot;: 0,            &quot;Ports&quot;: &#123;&#125;,            &quot;SandboxKey&quot;: &quot;&quot;,            &quot;SecondaryIPAddresses&quot;: null,            &quot;SecondaryIPv6Addresses&quot;: null,            &quot;EndpointID&quot;: &quot;&quot;,            &quot;Gateway&quot;: &quot;&quot;,            &quot;GlobalIPv6Address&quot;: &quot;&quot;,            &quot;GlobalIPv6PrefixLen&quot;: 0,            &quot;IPAddress&quot;: &quot;&quot;,            &quot;IPPrefixLen&quot;: 0,            &quot;IPv6Gateway&quot;: &quot;&quot;,            &quot;MacAddress&quot;: &quot;&quot;,            &quot;Networks&quot;: &#123;&#125;        &#125;    &#125;]</code></pre><p>*Note 容器模式下不允许指定端口等信息 这些全部由绑定的那个容器的网络决定,否则会错误 docker: Error response from daemon: conflicting options: port publishing and the container type network mode.</p><br><h4 id="Host主机"><a href="#Host主机" class="headerlink" title="Host主机"></a><strong>Host主机</strong></h4><br><blockquote><p>容器启动共享主机网络,但其他仍然是隔离的,比如文件系统等. 使用主机网络时-p,–publish -P,–publish-all 这些参数会被忽略，容器使用的端口会占用主机端口</p></blockquote><p><img src="/.io//host.png" alt="host.png"></p><h4 id="bridge桥接"><a href="#bridge桥接" class="headerlink" title="bridge桥接"></a><strong>bridge桥接</strong></h4><br><blockquote><p>docker规定允许容器连接到同一个桥接网络上，连接到不同桥接网络的不能进行交互,docker启动后会在宿主机上默认创建一个名为docker0的虚拟桥接网络（可以理解为交换机）默认情况下 多个启动的容器都是通过docker0连接 相互可以访问。运行一个容器时会在容器中和容器外虚拟出一对网卡 一端连接到容器中一段连接到虚拟网桥上。docker0会为容器分配ip  构成以docker0为网桥的二层网络</p></blockquote><p><img src="/.io//bridge.png" alt="bridge.png"></p><pre><code class="language-shell"># 创建2个容器在同一个网桥上（未指定时默认docker0）容器之间可通过主机名相互访问docker container run --name nginx2 --rm -d -p 9091:80 nginxdocker container run --name nginx1 --rm -d -p 9092:80 nginx#不同网络之间相互访问 一个在docker0 桥 一个在docker1docker container run --name nginx1 --rm -d -p 9091:80 --network docker0 nginxdocker container run --name nginx2 --rm -d -p 9092:80 --network docker1 nginxdocker network connect docker1 nginx1docker network connect docker0 nginx2</code></pre><blockquote><p>通过daemon.json的配置可以修改默认docker0网桥的网络信息</p></blockquote><pre><code class="language-json">&#123;    &quot;bip&quot; : &quot;192.168.2.1/24&quot;,    &quot;fixed-cidr&quot; : &quot;10.20.0.0/16&quot;,    &quot;fixed-cidr-v6&quot; : &quot;2001:db8::/64&quot;,    &quot;mtu&quot; : &quot;1500&quot;,    &quot;default-getway&quot; : &quot;192.168.2.1&quot;,    &quot;default-getway-v6&quot; : &quot;2001:db8:abcd::89&quot;,    &quot;dns&quot; : [&quot;8.8.8.8&quot;,&quot;1.1.1.1&quot;]&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始学docker(二)</title>
      <link href="/2023/01/26/2023-01-26-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E4%BA%8C)/"/>
      <url>/2023/01/26/2023-01-26-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E4%BA%8C)/</url>
      
        <content type="html"><![CDATA[<h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a><strong>存储</strong></h2><blockquote><p>docker存储使用分层架构，如图所示，容器由最上面的可写层和容器层构成，每个容器启动后会产生不同的文件，这些文件全部在可写层上，各个容器之间各不相干，当容器被删除,文件也会被删除。启动的多个容器之间会使用相同的镜像，并各自产生不同的数据存在各自的可写层。所以镜像层可以共享打包进镜像的数据。</p></blockquote><p><img src="/.io//sharing-layers.png" alt="sharing-layers.png"></p><h3 id="copy-on-write"><a href="#copy-on-write" class="headerlink" title="copy-on-write"></a><strong>copy-on-write</strong></h3><blockquote><p>写复制也是docker文件系统中重要的组成部分, 比如当容器需要访问目录1时 读取文件1 对于文件1中的就是最新的则直接读取之前层中的文件1 当需要写操作时 比如要修改文件2 则先将文件2复制到可写层,对文件进行写操作之后，后续读取则取最新的文件2。</p></blockquote><p><img src="/.io//copy-on-write.png" alt="copy-on-write.png"></p><blockquote><p>挂载存储的方式共分为3中<br>1.bind 绑定宿主机任意位置挂载点<br>2.Volumes 由docker管理的宿主机上的文件系统路径为&#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;非docker进程不应修改该部分文件<br>3.tmpfs 使用系统内存进行存储临时文件系统 不会写入宿主机文件系统。</p></blockquote><p><img src="/.io//types-of-mounts-volume.png" alt="types-of-mounts-volume.png"></p><h3 id="存储卷Volumes"><a href="#存储卷Volumes" class="headerlink" title="存储卷Volumes"></a><strong>存储卷Volumes</strong></h3><pre><code class="language-shell"># -v参数# optional 可以多个逗号分割 例如 ro,rw-v [本地地址/存储卷]:[容器地址]:[optional]eg:docker container run -v myvo2:/home:rw nginx:latest# --mount参数# type                      volume# source/src                指定本地目录/网络位置/存储卷名# destination/dst/target    指定容器内目标位置# readonly/ro               指定容器对该文件只读# volume-opt                指定更多设置eg:docker container run --mount &#39;type=volume,src=myvo2,target=/home,readonly&#39; nginx:latest # 创建一个存储卷 docker volume create --label author=zzt myvo2# 查看 docker volume inspect myvo2[    &#123;        &quot;CreatedAt&quot;: &quot;2023-01-10T10:31:50+08:00&quot;,        &quot;Driver&quot;: &quot;local&quot;,        &quot;Labels&quot;: &#123;            &quot;author&quot;: &quot;zzt&quot;        &#125;,        &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/myvo2/_data&quot;,        &quot;Name&quot;: &quot;myvo2&quot;,        &quot;Options&quot;: &#123;&#125;,        &quot;Scope&quot;: &quot;local&quot;    &#125;] docker volume rm myvo1# 可指定具体的标签 #干掉 标签有 author docker volume prune --filter &quot;label=author&quot;#干掉 标签有 author 且等于zzt的 docker volume prune --filter &quot;label=author=zzt&quot;</code></pre><h3 id="bind绑定"><a href="#bind绑定" class="headerlink" title="bind绑定"></a><strong>bind绑定</strong></h3><pre><code class="language-sheel"># -v参数# optional 可以多个逗号分割 例如 ro,rw-v [本地地址/存储卷]:[容器地址]:[optional]eg:docker container run -v /home/docker:/home:rw nginx:latest# --mount参数# type                      bind# source/src                指定本地目录/网络位置/存储卷名# destination/dst/target    指定容器内目标位置# readonly/ro               指定容器对该文件只读# bind-propagation          rprivate, private, rshared, shared, rslave, slaveeg:docker container run --mount &#39;type=bind,src=/home/docker,target=/home,readonly&#39; nginx:latest </code></pre><h4 id="bind-propagation-绑定传递"><a href="#bind-propagation-绑定传递" class="headerlink" title="bind propagation 绑定传递"></a><strong>bind propagation 绑定传递</strong></h4><table><thead><tr><th>Propagation setting</th><th>描述</th></tr></thead><tbody><tr><td>rprivate</td><td>默认值 和 private 相同</td></tr><tr><td>shared</td><td>原挂载点上的所有子挂载点对于副本挂载点可见 副本挂载点中的所有子挂载点对于原挂载点也可见</td></tr><tr><td>slave</td><td>原挂载点中的所有子挂载点对于副本挂载点可见 反之不行。</td></tr><tr><td>private</td><td>原挂载点和副本挂载点的子挂载点只对自己可见</td></tr><tr><td>rshared</td><td>在shared的基础上也支持嵌套的挂载点</td></tr><tr><td>rslave</td><td>在slave基础上也支持嵌套的挂载点</td></tr></tbody></table><h3 id="tmpfs"><a href="#tmpfs" class="headerlink" title="tmpfs"></a>tmpfs</h3><pre><code class="language-sheel"># --tmpfs参数eg:docker container run --tmpfs /tmp1 nginx:latest# --mount参数# type                      tmpfs# destination/dst/target    指定容器内目标位置# tmpfs-size                临时文件大小限制,默认无限制# tmpfs-mode                临时文件模式  700 可读写运行 or 0770. Defaults 1777可写eg:  docker container run --mount &#39;type=tmpfs,target=/target&#39; nginx:latest </code></pre><blockquote><p><strong>区别</strong>:-v指定的宿主机地址总是会自动创建<br>&emsp;&emsp;&nbsp;–mount指定的宿主机地址如果不存在则会发生错误<br>eg:<br>docker container run –rm –mount ‘type&#x3D;bind,src&#x3D;&#x2F;home&#x2F;docker1,target&#x3D;&#x2F;home,readonly’ nginx:latest<br>docker: Error response from daemon: invalid mount config for type “bind”: bind source path does not exist: &#x2F;home&#x2F;docker1.</p></blockquote><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始学docker(一)</title>
      <link href="/2023/01/26/2023-01-26-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E4%B8%80)/"/>
      <url>/2023/01/26/2023-01-26-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6docker(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h2 id="docker架构"><a href="#docker架构" class="headerlink" title="docker架构"></a><strong>docker架构</strong></h2><p><a href="https://docs.docker.com/get-started/overview/">docker架构</a> , <a href="https://docs.docker.com/engine/api/">api</a></p><p><img src="/.io//architecture.png" alt="architecture.png"></p><br><h2 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a><strong>namespace</strong></h2><blockquote><p>底层通过6大命名空间进行隔离</p></blockquote><table><thead><tr><th align="left">namespae</th><th align="left">系统参数</th><th align="left">隔离内容</th></tr></thead><tbody><tr><td align="left">UTS</td><td align="left">CLONE_NEWUTS</td><td align="left">主机名域名</td></tr><tr><td align="left">IPC</td><td align="left">CLONE_NEWIPC</td><td align="left">进程间通信 信号量 消息队列 共享内存</td></tr><tr><td align="left">PID</td><td align="left">CLONE_NEWPID</td><td align="left">进程编号</td></tr><tr><td align="left">NETWORK</td><td align="left">CLONE_NEWNET</td><td align="left">网络</td></tr><tr><td align="left">MOUNT</td><td align="left">CLONE_NEWNS</td><td align="left">文件系统</td></tr><tr><td align="left">USER</td><td align="left">CLONE_NEWUSER</td><td align="left">用户和用户组</td></tr></tbody></table><h2 id="cgroup-控制组"><a href="#cgroup-控制组" class="headerlink" title="cgroup 控制组"></a><strong>cgroup 控制组</strong></h2><blockquote><p>cgroups是Linux内核提供的一种机制，这种机制可以根据需求把一系列系统任务及其子任务集合到按资源划分等级的不同组内，从而为系统资源管理提供一个统一的结果</p></blockquote><ul><li><strong>资源限制</strong>：可以对任务使用的资源总额进行限制</li><li><strong>优先级分配</strong>：通过分配的cpu时间片数量以及磁盘IO带宽大小，实际上相当于控制了任务运行优先级</li><li><strong>资源统计</strong>：可以统计系统的资源使用量，如cpu时长，内存用量等</li><li><strong>任务控制</strong>：cgroup可以对任务执行挂起、恢复等操作</li></ul><br><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a><strong>安装</strong></h2><blockquote><p>手动安装许按照以下依赖进行<br><img src="/.io//docker_install.jpg" alt="docker_install.jpg" title="docker_install.jpg"></p></blockquote><hr><pre><code class="language-shell">#删除本地的dockeryum remove docker \           docker-client \           docker-client-latest \           docker-common \           docker-latest \           docker-latest-logrotate \           docker-logrotate \           docker-engine \           docker-engine-selinux \           docker-selinux #安装yum-utilsyum install -y yum-utils#添加下载源yum-config-manager \    --add-repo \    http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repoyum install docker-ce docker-ce-cli containerd.io docker-compose-plugin#安装指定docker版本yum list docker-ce --showduplicates | sort -ryum install docker-ce-19.03.9-3.el7  docker-ce-cli-19.03.9-3.el7  containerd.io docker-compose-plugin# 开机自启/关闭自启systemctl enable/disable docker#启动/停止docker服务systemctl start/stop docker#如果daemon.json有改动记得重新加载dockerdaemonsystemctl daemon-reload#查看docker服务状态systemctl status docker#添加用户到docker组usermod -aG docker username</code></pre><br><h2 id="DOCKER-DAEMON"><a href="#DOCKER-DAEMON" class="headerlink" title="DOCKER DAEMON"></a><strong>DOCKER DAEMON</strong></h2><blockquote><p>dockerdaemon是用于监听dockerapi请求，与其他dockerdaemon交互,管理docker对象服务 docker对象包括镜像 容器 网络 存储卷等 默认配置在&#x2F;etc&#x2F;docker&#x2F;daemon.json文件 没有可以自行创建。 dockerdaemin的默认数据存放在&#x2F;var&#x2F;lib&#x2F;docker目录 可通过在daemon.json配置data-root属性进行修改。   重新加载daemon.json的修改 systemctl daemon-reload 配合重启docker进程一起</p></blockquote><ul><li>daemon.json示例</li></ul><pre><code class="language-json">&#123;  ......  //配置镜像源  //http  &quot;insecure-registries&quot;:[&quot;ip:port&quot;,&quot;p:port&quot;,&quot;......&quot;],    //https    &quot;registry-mirrors&quot;: [&quot;http://harbor.test.com&quot;,&quot;......&quot;],  //非SSL源管理镜像，这里加上  &quot;max-concurrent-downloads&quot;: 10,  //数据存储位置  &quot;data-root&quot;: &quot;/home/data&quot;,  //网络配置  &quot;bip&quot; : &quot;192.168.2.1/24&quot;,  &quot;fixed-cidr&quot; : &quot;10.20.0.0/16&quot;,  &quot;fixed-cidr-v6&quot; : &quot;2001:db8::/64&quot;,  &quot;mtu&quot; : &quot;1500&quot;,  &quot;default-getway&quot; : &quot;192.168.2.1&quot;,  &quot;default-getway-v6&quot; : &quot;2001:db8:abcd::89&quot;,  &quot;dns&quot; : [&quot;8.8.8.8&quot;,&quot;1.1.1.1&quot;]  ......&#125;</code></pre><blockquote><p>指定docker连接的服务器 默认本机”unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock”<br>Unix Socket 这是类unix系统进程间通讯的一种方式<br>指定tcp连接后可通过 docker -H xxx.xxx.xx.xxx:2375  连接到指定的docker服务端</p></blockquote><pre><code class="language-json">&#123;    &quot;hosts&quot;:[              //tcp默认端口2375              &quot;tcp:00.00.00.00:2375&quot;,              //tcp_tls 默认端口 2376              &quot;tcp_tls:00.00.00.00:2376&quot;,              &quot;unix:///var/run/docker.sock&quot;]&#125;</code></pre><p>&emsp;详细配置查看<a href="https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-configuration-file">Daemon_Doc</a> 可通过dockerd指令进行操作</p><h2 id="GC回收"><a href="#GC回收" class="headerlink" title="GC回收"></a>GC回收</h2><blockquote><p>GC运行在构建进程，主要用于清理构建镜像的过大的缓存文件以及过期的缓存</p></blockquote><pre><code class="language-shell"># 清除构建镜像的缓存$ docker builder prune$ docker buildx prune </code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><pre><code class="language-json">&#123;  &quot;builder&quot;: &#123;    &quot;gc&quot;: &#123;      &quot;enabled&quot;: true,      &quot;defaultKeepStorage&quot;: &quot;10GB&quot;,      &quot;policy&quot;: [          &#123;&quot;keepStorage&quot;: &quot;10GB&quot;, &quot;filter&quot;: [&quot;unused-for=2200h&quot;]&#125;,          &#123;&quot;keepStorage&quot;: &quot;50GB&quot;, &quot;filter&quot;: [&quot;unused-for=3300h&quot;]&#125;,          &#123;&quot;keepStorage&quot;: &quot;100GB&quot;, &quot;all&quot;: true&#125;      ]    &#125;  &#125;&#125;</code></pre><h2 id="修改Docker默认启动参数"><a href="#修改Docker默认启动参数" class="headerlink" title="修改Docker默认启动参数"></a>修改Docker默认启动参数</h2><p> 找到启动脚本&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service 添加如下配置信息以及文件</p><pre><code class="language-shell">EnvironmentFile=-/etc/default/docker #添加配置文件（-代表ignore error）#基本配置EnvironmentFile=-/etc/sysconfig/docker#存储EnvironmentFile=-/etc/sysconfig/docker-storage#网络EnvironmentFile=-/etc/sysconfig/docker-networkExecStart=/usr/bin/dockerd -H fd:// \-H unix:///var/run/docker.sock \-H tcp://172.21.114.51 \-H tcp://127.0.0.1 \--containerd=/run/containerd/containerd.sock \--config-file /etc/docker/daemon.json \$OPTIONS \$DOCKER_STORAGE_OPTIONS \$DOCKER_NETWORK_OPTIONS \$ADD_REGISTRY \$BLOCK_REGISTRY \$INSECURE_REGISTRY \$DOCKER_OPTS</code></pre><h2 id="运行容器常用命令"><a href="#运行容器常用命令" class="headerlink" title="运行容器常用命令"></a>运行容器常用命令</h2><pre><code class="language-shell">#启动一个容器docker container run imagename:tag#启动一个容器 名称为 cnamedocker container run  --name cname imagename:tag#启动一个容器 名称为 cname 在容器停止后删除容器docker container run  --rm --name cname imagename:tag#后台启动一个容器 名称为 cname 在容器停止后删除容器docker container run -d --rm --name cname imagename:tag#后台启动一个容器 名称为 cname 在容器停止后删除容器 并替换掉原镜像启动的命令docker container run -d --rm --name cname imagename:tag /bin/bash#后台启动一个容器 名称为 cname 容器总是自动重启 #no默认策略，在容器退出时不重启容器 #on-failure，在容器非正常退出时（退出状态非0）#always，在容器退出时总是重启容器#unless-stopped，在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器docker container run -d  --name cname  --restart always imagename:tag /bin/bash#后台启动一个容器 名称为 cname 在容器停止后删除容器 并添加环境变量 (-e可以多次)docker container run -d --rm --name cname  -e JAVA_HONE=/home/jdk8 -e MAVEN_HOME=/home/maven imagename:tag #启动一个容器 名称为 cname 在容器停止后删除容器 并替换掉原镜像启动的命令 与容器交互docker container run -it --rm --name cname imagename:tag /bin/bash#容器执行指定命令docker container exec -it 容器名/容器id  命令#停止一个容器docker container stop 容器名/容器id#删除一个容器docker container rm 容器名/容器id#重启一个容器docker container restart 容器名/容器id#查看容器日志docker container logs 容器名/容器id#查看容器暴露端口docker container port 容器名/容器id#查看容器进程信息docker container top 容器名/容器id</code></pre><h2 id="格式化输出"><a href="#格式化输出" class="headerlink" title="格式化输出"></a><a href="https://docs.docker.com/config/formatting/">格式化输出</a></h2><ul><li>使list转为字符串 使用指定的字符进行连接</li></ul><pre><code class="language-shell">docker inspect --format &#39;&#123;&#123;join .HostConfig.MaskedPaths ";"&#125;&#125;&#39; 5eff2b7c0866/proc/asound;/proc/acpi;/proc/kcore;/proc/keys;/proc/latency_stats;/proc/timer_list;/proc/timer_stats;/proc/sched_debug;/proc/scsi;/sys/firmware</code></pre><ul><li>根据指定字符进行字符串的拆分</li></ul><pre><code class="language-shell">[docker@iZ8vbdl6m2aje7b2bl04soZ myweb]$ docker inspect --format &#39;&#123;&#123;split .HostConfig.NetworkMode ":"&#125;&#125;&#39; 5eff2b7c0866[container 95132de6a0783684dd208328247f96194609d7ebec58465271f7b36906f786d0]</code></pre><ul><li>表格输出</li></ul><pre><code class="language-shell">docker inspect --format &#39;table &#123;&#123;.Id&#125;&#125; $ &#123;&#123;split .HostConfig.NetworkMode ":"&#125;&#125;&#39; 5eff2b7c0866table 5eff2b7c0866749c28eeba80453fe163fdc9de6b3702084cd5b561346fdf606d $ [container 95132de6a0783684dd208328247f96194609d7ebec58465271f7b36906f786d0]</code></pre><ul><li>json 格式输出字符串</li></ul><pre><code class="language-shell">docker inspect --format &#39;&#123;&#123;json .HostConfig.LogConfig &#125;&#125;&#39; 5eff2b7c0866&#123;&quot;Type&quot;:&quot;json-file&quot;,&quot;Config&quot;:&#123;&#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP</title>
      <link href="/2021/08/25/2021-08-25-HTTP/"/>
      <url>/2021/08/25/2021-08-25-HTTP/</url>
      
        <content type="html"><![CDATA[<h2 id="Http-Header-请求头"><a href="#Http-Header-请求头" class="headerlink" title="Http Header 请求头"></a>Http Header 请求头</h2><h3 id="Access-Control-Expose-Headers"><a href="#Access-Control-Expose-Headers" class="headerlink" title="Access-Control-Expose-Headers"></a>Access-Control-Expose-Headers</h3><hr><blockquote><p>Access-Control-Expose-Headers 响应报头指示哪些报头可以公开为通过列出他们的名字的响应的一部分<br>默认显示6个<br>Cache-Control,Content-Language,Content-Type,Expires,Last-Modified,Pragma<br>用法如下：可以添加更多允许暴露的请求头内容</p></blockquote><pre><code class="language-txt">Access-Control-Expose-Headers: &lt;header-name&gt;, &lt;header-name&gt;, ...</code></pre><hr>]]></content>
      
      
      <categories>
          
          <category> -数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mockito&amp;&amp;PowerMockito</title>
      <link href="/2021/08/25/2021-08-27-Mockito/"/>
      <url>/2021/08/25/2021-08-27-Mockito/</url>
      
        <content type="html"><![CDATA[<h2 id="Mockito"><a href="#Mockito" class="headerlink" title="Mockito"></a>Mockito</h2><hr><pre><code class="language-java">// 私有变量赋值FieldSetter.setField(Object target, Field field, Object value);</code></pre><h2 id="PowerMockito"><a href="#PowerMockito" class="headerlink" title="PowerMockito"></a>PowerMockito</h2><hr><blockquote><p>PowerMockito需要指定PowerMockRunner  使用PrepareForTest添加需要准备的类</p></blockquote><pre><code class="language-java">@RunWith(PowerMockRunner.class)@PrepareForTest(&#123;xxxx.class, xxxx.class,.....&#125;)public class ClassA &#123;&#125;</code></pre><h3 id="模拟测试方法内的静态方法调用"><a href="#模拟测试方法内的静态方法调用" class="headerlink" title="模拟测试方法内的静态方法调用"></a>模拟测试方法内的静态方法调用</h3><pre><code class="language-java">//模拟静态类 需要添加 PrepareForTest（StaticClass.class）//把要模拟的类添加到注解中PowerMockito.mockStatic(StaticClass.class);//模拟带返回值静态方法 （先模拟静态类）参数可以用Mockit的any来代替 也可以传入具体的对象  *Note 不能混用PowerMockito.when(StaticClass.StaticMethod((Mockito.any(),Mockito.anyBoolean())).thenReturn(ReturnObject);////模拟无返回值静态方法 （先模拟静态类）参数可以用Mockit的any来代替 也可以传入具体的对象  *Note 不能混用PowerMockito.doNothing().when(StaticClass.class，  &quot;StaticMethod&quot; , Mockito.any(),Mockito.any(),..... );////模拟无返回值静态方法  发生异常（先模拟静态类）参数可以用Mockit的any来代替 也可以传入具体的对象  *Note 不能混用 原则上被调用方法没有抛出异常是不允许模拟异常的 但是可以用运行时异常强行抛出PowerMockito.doThrow().when(StaticClass.class，  &quot;StaticMethod&quot; , Mockito.any(),Mockito.any(),..... );//doNothing doThrow doReturn 可以链式调用 表示方法按次序调用每次发生的事件//具有返回值的不允许使用 doNothing//eg： 表示方法被第一次调用返回1 第二次返回空 第三次 发生异常PowerMockito.doReturn(1).doReturn(null).doThrow(new Exception()).when(StaticClass.class，  &quot;StaticMethod&quot; , Mockito.any(),Mockito.any(),..... );</code></pre><h3 id="模拟测试方法内的对象实例化"><a href="#模拟测试方法内的对象实例化" class="headerlink" title="模拟测试方法内的对象实例化"></a>模拟测试方法内的对象实例化</h3><pre><code class="language-java">//eg: 需要模拟A类的实例化 以及xxMethod的调用public class TestClass &#123;    public String TestMethod()&#123;           A a= new A();            String str =a.xxMethod(xxx，xxx);    &#125;&#125;//模拟A 实例化 首先需要模拟A的实例 A a = PowerMockito.mock(A.class); // 当A实例化时候返回这个模拟的aPowerMockito.whenNew(A.class).withNoArguments().thenReturn(a);//调用xxMethodPowerMockito.when(a.xxMethod(Mockito.any(),Mockito.any(),Mockito.any().... ) ).thenReturn(Object);//////模拟无返回值方法 （先模拟静态类）参数可以用Mockit的any来代替 也可以传入具体的对象  *Note 不能混用PowerMockito.doNothing().when(a).Method( Mockito.any(),Mockito.any(),.....);////模拟无返回值方法  发生异常（先模拟静态类）参数可以用Mockit的any来代替 也可以传入具体的对象  *Note 不能混用PowerMockito.doThrow().when(a).Method( Mockito.any(),Mockito.any(),.....);</code></pre>]]></content>
      
      
      <categories>
          
          <category> -JAVA -Junit -单元测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -Junit </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql安装以及常用命令</title>
      <link href="/2021/06/19/2021-07-20-Mysql%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2021/06/19/2021-07-20-Mysql%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h3 id="docker-安装mysql"><a href="#docker-安装mysql" class="headerlink" title="docker 安装mysql"></a>docker 安装mysql</h3><p>mysql 配置文件</p><pre><code class="language-cnf"># For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html[mysqld]## Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M## Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin## Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Mskip-host-cacheskip-name-resolve##########################################################port=3306#设置服务器的默认字符集为utf8character-set-server=utf8#数据目录datadir=/var/lib/mysql#设置服务器的时区 未配置则为系统时区default-time-zone = &#39;+08:00&#39;#启用binlog 并指定文件 文件位置在datadir下log_bin=truelog-bin=mysql-binbinlog_format=rowserver-id=1#是否开启慢查询日志,1开启 0关闭slow-query-log=1#慢查询日志的输出路径slow_query_log_file=&quot;/var/log/slow_query.log#通用日志的输出方式TABLE,FILE,NONE,这里设置了输出到文件log-output=FILE#是否开启通用日志,1开启 0关闭general-log=1general_log_file=&quot;/var/log/general.log&quot;#通用日志的输出路径#错误日志log-error=/var/log/mysqld.err.log#######################################user=mysql# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0pid-file=/var/run/mysqld/mysqld.pidsocket=/var/run/mysqld/mysqld.socksecure-file-priv=/var/lib/mysql-files[client]#设置客户端的默认字符集default-character-set=utf8socket=/var/run/mysqld/mysqld.sock!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/</code></pre><pre><code class="language-shell">docker run -d  --name mysql --hostname=&quot;mysql&quot; -e MYSQL_ROOT_PASSWORD=123456   -v /home/docker/mysql/conf/my.cnf:/etc/mysql/my.cnf  -v /home/docker/mysql/data/:/var/lib/mysql/ -v /home/docker/mysql/log/:/var/log -p 3306:3306 --network inet --rm mysql:5.7</code></pre><h3 id="Jdbc连接的方式"><a href="#Jdbc连接的方式" class="headerlink" title="Jdbc连接的方式"></a>Jdbc连接的方式</h3><pre><code class="language-sql">-- jdbc:mysql://hostname:port/schema?useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true&amp;zeroDateTimeBehavior=convertToNull&amp;transformedBitIsBoolean=true&amp;serverTimezone=Asia/Shanghai&amp;allowMultiQueries=true</code></pre><h3 id="查询表结构"><a href="#查询表结构" class="headerlink" title="查询表结构"></a>查询表结构</h3><pre><code class="language-sql">-- 利用 information_schema 查询SELECT  x.TABLE_SCHEMA,x.COLUMN_NAME,x.DATA_TYPE,x.COLUMN_COMMENT,x.COLUMN_DEFAULTFROM information_schema.COLUMNS  xWHERE table_schema = &#39;table_schema&#39; AND table_name = &#39;table_name&#39;;</code></pre><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><pre><code class="language-sql">COALESCE ( expression,value1,value2……)-- 函数的第一个参数expression为待检测的表达式，而其后的参数个数不定。-- expression 不为空返回 expression 否则 判断value1不为空返回value1 -- 否则判断value2不为空返回value2 以此类推</code></pre>]]></content>
      
      
      <categories>
          
          <category> -数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前端遇见问题总结</title>
      <link href="/2020/12/26/2020-12-26-%E5%89%8D%E7%AB%AF%E9%81%87%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
      <url>/2020/12/26/2020-12-26-%E5%89%8D%E7%AB%AF%E9%81%87%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="一、ie-强制最新版本渲染（兼容性视图-）"><a href="#一、ie-强制最新版本渲染（兼容性视图-）" class="headerlink" title="一、ie 强制最新版本渲染（兼容性视图 ）"></a>一、ie 强制最新版本渲染（兼容性视图 ）</h2><blockquote><p>强制使用ie最新版本渲染可分为两种方式 </p></blockquote><ul><li>1). 前端</li></ul><pre><code class="language-html">&lt;!--  前端方式 大多数人比较了解   --&gt;&lt;head&gt;&lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;IE=edge,chrome=1&quot; /&gt;&lt;/head&gt;</code></pre><ul><li>2). 服务端</li></ul><pre><code class="language-java">/**** 服务端可以想响应头中添加 X-UA-Compatible 属性* 本次问题解决方式是向所以的响应中添加该属性 使ie使用最高版本渲染 禁止使用兼容模式 * 解决方案 添加filter 拦截 对所有响应中添加*/public class RespFilter implements Filter&#123;@Override    public void doFilter(ServletRequest arg0, ServletResponse arg1, FilterChain chain)            throws IOException, ServletException &#123;        // TODO Auto-generated method stub        HttpServletRequest req=(HttpServletRequest)arg0;        HttpServletResponse resp=(HttpServletResponse)arg0;        resp.setHeader(&quot;X-UA-Compatible&quot;,&quot;IE=edge,chrome=1&quot;);        chain.doFilter(req,resp);    &#125;&#125;@Configurationpublic class MyConfiguration &#123;    @Bean    public FilterRegistrationBean&lt;RespFilter&gt; respFilterRegistrationBean()&#123;        //通过FilterRegistrationBean实例设置优先级可以生效        //通过@WebFilter无效        FilterRegistrationBean&lt;RespFilter&gt; bean = new FilterRegistrationBean&lt;RespFilter&gt;();        bean.setFilter(new RespFilter());//注册自定义过滤器        bean.setName(&quot;respflilter&quot;);//过滤器名称        bean.addUrlPatterns(&quot;/*&quot;);//过滤所有路径        bean.setOrder(1);//优先级，最顶级        return bean;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> -前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -HTML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据库遇见问题总结</title>
      <link href="/2020/11/29/2020-11-29-%E6%95%B0%E6%8D%AE%E5%BA%93%E9%81%87%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/"/>
      <url>/2020/11/29/2020-11-29-%E6%95%B0%E6%8D%AE%E5%BA%93%E9%81%87%E8%A7%81%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h1 id="ORACLE"><a href="#ORACLE" class="headerlink" title="ORACLE"></a>ORACLE</h1><h2 id="1-undo空间不足"><a href="#1-undo空间不足" class="headerlink" title="1.undo空间不足"></a>1.undo空间不足</h2><blockquote><p>由于在同一个事务中多次对数据进行增删改之类的操作，在最后提交时候会占用相当大部分的undo空间，导致undo空间不足数据库出现问题，物化视图同样也会导致undo空间不足的问题，具体导致该问题最主要是操作数据量过大，所以 ，当操作数据需要在同一个事务中时候，需要主要数据量问题。！！！ 尽量避免大数据量。</p></blockquote><hr><h1 id="MYSQL"><a href="#MYSQL" class="headerlink" title="MYSQL"></a>MYSQL</h1>]]></content>
      
      
      <categories>
          
          <category> -数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -Oracle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Activiti工作流</title>
      <link href="/2020/10/14/2020-10-14-Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/"/>
      <url>/2020/10/14/2020-10-14-Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/</url>
      
        <content type="html"><![CDATA[<h2 id="一-核心接口"><a href="#一-核心接口" class="headerlink" title="一.核心接口"></a>一.核心接口</h2><h3 id="1-ProcessEngine-流程引擎"><a href="#1-ProcessEngine-流程引擎" class="headerlink" title="1.ProcessEngine 流程引擎"></a>1.ProcessEngine 流程引擎</h3><pre><code class="language-java">/***流程引擎 核心接口*public class ProcessEngineImpl implements ProcessEngine  该类为线程安全类*/public interface ProcessEngine &#123;    .......  RepositoryService getRepositoryService();  RuntimeService getRuntimeService();  FormService getFormService();  TaskService getTaskService();  HistoryService getHistoryService();  IdentityService getIdentityService();  ManagementService getManagementService();  DynamicBpmnService getDynamicBpmnService();  ProcessEngineConfiguration getProcessEngineConfiguration();  FormRepositoryService getFormEngineRepositoryService();  org.activiti.form.api.FormService getFormEngineFormService();&#125;</code></pre><blockquote><p>常用接口</p></blockquote><h3 id="2-RepositoryService-存储服务"><a href="#2-RepositoryService-存储服务" class="headerlink" title="2.RepositoryService 存储服务"></a>2.RepositoryService 存储服务</h3><blockquote><p>主要负责工作流的存储相关操作，包括部署 删除等</p></blockquote><pre><code class="language-java">public interface RepositoryService &#123;//创建部署 DeploymentBuilder createDeployment();//流程定义查询  ProcessDefinitionQuery createProcessDefinitionQuery();//部署查询DeploymentQuery createDeploymentQuery();//暂停流程void suspendProcessDefinitionById(String processDefinitionId);//启用流程 void activateProcessDefinitionById(String processDefinitionId); ......&#125;</code></pre><h3 id="3-RuntimeService-运行服务"><a href="#3-RuntimeService-运行服务" class="headerlink" title="3.RuntimeService 运行服务"></a>3.RuntimeService 运行服务</h3><blockquote><p>主要负责通过流程定义启动一个流程实例 包括启动 终止流程实例等操作</p></blockquote><pre><code class="language-java">public interface RuntimeService &#123;//通过流程定义启动一个流程 返回一个流程实例 ProcessInstance startProcessInstanceById(String processDefinitionId);// 使用流程实例id  删除一个正在进行中的流程 void deleteProcessInstance(String processInstanceId, String deleteReason/*删除原因*/);//创建流程实例查询对象ProcessInstanceQuery createProcessInstanceQuery();......&#125;</code></pre><h3 id="4-TaskService-任务服务"><a href="#4-TaskService-任务服务" class="headerlink" title="4.TaskService 任务服务"></a>4.TaskService 任务服务</h3><blockquote><p>主要负责流程中的每一个任务的操作 ，包括 任务查询 ，任务指定受理人，任务拾取 归还，  完成任务 等操作 </p></blockquote><pre><code class="language-java">public interface TaskService &#123;//删除任务 void deleteTask(String taskId, String deleteReason);//指定用户拾取该任务 不同于 setAssignee(String, String) 直接指定  这里会在有受理人的情况下进行校验void claim(String taskId, String userId);//指定任务为无人拾取  void unclaim(String taskId);//完成一个任务void complete(String taskId);......&#125;</code></pre><h3 id="5-HistoryService-历史服务"><a href="#5-HistoryService-历史服务" class="headerlink" title="5.HistoryService 历史服务"></a>5.HistoryService 历史服务</h3><blockquote><p>主要负责历史流程 任务的查询等操作</p></blockquote><pre><code class="language-java">public interface HistoryService &#123;//历史完成流程查询HistoricProcessInstanceQuery createHistoricProcessInstanceQuery();//历史任务查询HistoricTaskInstanceQuery createHistoricTaskInstanceQuery();//删除历史任务  void deleteHistoricTaskInstance(String taskId);//删除历史流程  void deleteHistoricProcessInstance(String processInstanceId);......&#125;</code></pre><hr><blockquote><p>*NOTE 还有其他接口在ProcessEngine下面</p></blockquote><h3 id="流程配置ProcessEngineConfiguration"><a href="#流程配置ProcessEngineConfiguration" class="headerlink" title="流程配置ProcessEngineConfiguration"></a>流程配置ProcessEngineConfiguration</h3><blockquote><p>看名字就知道该类为流程引擎的一个配置类，其中包括各个服务接口的创建，创建数据库表的配置包括DB_SCHEMA_UPDATE_FALSE，DB_SCHEMA_UPDATE_TRUE，DB_SCHEMA_UPDATE_CREATE_DROP 数据源配置等 ,在和spring一起使用是在依赖了activiti-spring时 会使用SpringProcessEngineConfiguration类作为实现,流程引擎processengine的创建会通过buildProcessEngine()方法进行创建。</p></blockquote><pre><code class="language-java">    /**不更新*/  public static final String DB_SCHEMA_UPDATE_FALSE = &quot;false&quot;;=  /**跟随流程引擎启动创建 流程引擎销毁时删除*/  public static final String DB_SCHEMA_UPDATE_CREATE_DROP = &quot;create-drop&quot;;  /** 更新*/  public static final String DB_SCHEMA_UPDATE_TRUE = &quot;true&quot;;</code></pre><h2 id="二-使用"><a href="#二-使用" class="headerlink" title="二.使用"></a>二.使用</h2><blockquote><p>activiti使用需要部署流程图 ，该流程图规定为一个bmpn文件，eclipse可安装绘制流程图的工具。 如下图安装即可 。 会在创建文件处有创建activiti的选项。</p></blockquote><p>Name: Activiti BPMN 2.0 designer<br>Location：<a href="http://activiti.org/designer/update/">http://activiti.org/designer/update/</a></p><img src="/.io//10/14/2020-10-14-Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/Activitidesigner.png" class title="Activitidesigner"><img src="/.io//10/14/2020-10-14-Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/eclipseactiviti.png" class title="eclipseactiviti"><h3 id="1-绘制流程图"><a href="#1-绘制流程图" class="headerlink" title="1.绘制流程图"></a>1.绘制流程图</h3><blockquote><p>从右侧拖入控件，填写需要的uel表达式 ，保存就好了。保存好的bmpn文件用于部署使用 ，其实质上是一个xml文件，其中包括各种控件的信息 位置等数据。</p></blockquote><img src="/.io//10/14/2020-10-14-Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/Screenshot2020-10-14165951.png" class title="图一"><img src="/.io//10/14/2020-10-14-Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/Screenshot2020-10-14170334.png" class title="图二"><img src="/.io//10/14/2020-10-14-Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/Screenshot2020-10-14170441.png" class title="图三"><blockquote><p>*NOTE: uel表达式受理人只能指定一个 ，在候选人和候选人组 可以设置多个 使用逗号隔开 例如：传入的内容时 user1,user2,user3,…. 这样的</p></blockquote><blockquote><p>在流程图中直接指定办理人的方式十分的不灵活，所以多数会使用uel表达式或者监听器方式为任务指定受理人。任务完成主要通过任务id即可完成，那么我们则需要使用受理人 候选人 ，或者候选人组拾取任务的方式，使用确定的受理人来查询任务获取任务id，以确定完成的任务是有受理人的。</p></blockquote><h3 id="2-uel指定受理人"><a href="#2-uel指定受理人" class="headerlink" title="2.uel指定受理人"></a>2.uel指定受理人</h3><p>如图 ，指定了uel表达式 assignee1  假设传入用户A为该任务的受理人 ，那么我们则需要使用A来获取该任务id 再完成任务。</p><img src="/.io//10/14/2020-10-14-Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/Screenshot2020-10-14170334.png" class title="图四"><pre><code class="language-java">//启动流程时传入参数 指定assignee1 是AMap&lt;String,Object&gt; variables=new HashMap&lt;String ,Object&gt;();var.put(&quot;assignee1&quot;, &quot;A&quot;);var.put(&quot;candidateusers&quot;, &quot;candidateuser1,candidateuser2&quot;);var.put(&quot;candidategroups&quot;, &quot;Mycandidategroup&quot;);ProcessInstance processInstance= runtimeService.startProcessInstanceById(&quot;ProcessDefinitionid&quot;,variables);///////////////////////////////////////////// 指定受理人查询 li例如ATask task = taskService.createTaskQuery().processInstanceId(processInstanceId).taskAssignee(user) .singleResult();if (task == null) &#123;// 指定候选人查询 candidateuser1和candidateuser2都可以查到该任务task = taskService.createTaskQuery().processInstanceId(processInstanceId).taskCandidateUser(user).singleResult();if (task == null) &#123;// 指定候选人组查询 Mycandidategroup 通过组获取任务task = taskService.createTaskQuery().processInstanceId(processInstanceId).taskCandidateGroup(group).singleResult();&#125;if (task != null)//任务拾取 需要任务拾取 ，即指定明确的受理人taskService.claim(task.getId(), user);&#125;if (task == null) &#123;return;&#125;taskService.complete(task.getId(), map);</code></pre><h3 id="3-监听器方式指定受理人"><a href="#3-监听器方式指定受理人" class="headerlink" title="3.监听器方式指定受理人"></a>3.监听器方式指定受理人</h3><blockquote><p>创建一个流程，在这个流程中为其中一个任务添加一个监听器，指定该监听器是在任务创建时候触发，如图，我们启动流程，这里是在流程启动后直接常见后续的任务，所以可以，该监听器被触发，为该任务设定指定的受理人用户A。后续即可通过该受理人找到该任务并完成 ，当然，不止可以添加受理人，删除 添加候选人 候选人组 以及向流程中添加变量都是可以的。</p></blockquote><img src="/.io//10/14/2020-10-14-Activiti%E5%B7%A5%E4%BD%9C%E6%B5%81/Screenshot2020-10-15105820.png" class title="图四"><pre><code class="language-java">public class MyTaskListener implements TaskListener&#123;@Overridepublic void notify(DelegateTask delegateTask) &#123;delegateTask.setAssignee(&quot;A&quot;);&#125;&#125;</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> -工作流 -Activiti </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Quartz集群</title>
      <link href="/2020/09/01/2020-09-01-Quartz%E9%9B%86%E7%BE%A4/"/>
      <url>/2020/09/01/2020-09-01-Quartz%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="quartz主要接口"><a href="#quartz主要接口" class="headerlink" title="quartz主要接口"></a>quartz主要接口</h2><ul><li>Scheduler调度器接口</li><li>JobDetail job描述</li><li>Trigger触发器</li><li>Job 具体的job</li><li>各种监听器 JobListener TriggerListener SchedulerListener</li></ul><blockquote><p>一个JobDetail包括一个job 其可以绑定多个触发器 ，然后交给调度器调度执行。</p></blockquote><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><pre><code class="language-java">//通过调度工厂创建调度器SchedulerFactory schedulerFactory = new StdSchedulerFactory();        Scheduler scheduler = schedulerFactory.getScheduler();        //添加监听器 可以为指定job 触发器 通过Matcher比较器接口        //scheduler.getListenerManager().addJobListener();        //scheduler.getListenerManager().addTriggerListener();        //scheduler.getListenerManager().addSchedulerListener();        //通过Myjob创建jobDetail Myjob实现Job接口        //主要job实现在execute(JobExecutionContext context)方法        JobDetail jobDetail = JobBuilder.newJob(Myjob.class).withIdentity(&quot;jobname&quot;,&quot;jobgroup&quot;).requestRecovery()                .build();        //创建触发器         Trigger trigger =TriggerBuilder.newTrigger()        .withIdentity(&quot;triggername&quot;,&quot;triggergroup&quot;)                .withSchedule(CronScheduleBuilder.cronSchedule(&quot;0 * * * * ?&quot;))                .startNow()//立即启动                .build();        //绑定 job和触发器        scheduler.scheduleJob(jobDetail,trigger);        scheduler.start();//启动所有job  可以在创建jobDetail 和trigger 之前启动</code></pre><h2 id="quartz集群"><a href="#quartz集群" class="headerlink" title="quartz集群"></a>quartz集群</h2><blockquote><p>quartz实现集群的方式时通过数据库锁的方式，其隶属于悲观锁，主要通过其配置文件来初始化调度器，其配置文件名为quartz.properties ，quartz默认使用StdScheduler的实现，其中包括大量的配置，其中部分配置如下</p></blockquote><pre><code class="language-properties">#基础配置#指定实例名 默认QuartzSchedulerorg.quartz.scheduler.instanceName =#集群模式使用AUTO 全大写org.quartz.scheduler.instanceId= AUTO#指定实例id生成器#org.quartz.scheduler.instanceIdGenerator.class=org.quartz.simpl.SimpleInstanceIdGenerator#org.quartz.scheduler.threadName =#org.quartz.scheduler.makeSchedulerThreadDaemon=true#org.quartz.scheduler.threadsInheritContextClassLoaderOfInitializer=# 线程配置org.quartz.threadPool.class =org.quartz.simpl.SimpleThreadPool# 线程数大于0org.quartz.threadPool.threadCount = 10#线程优先级org.quartz.threadPool.threadPriority=5#job存储 默认使用RAMJobStore 内存存储 集群默认使用JobStoreTX  jdbc存储#jobstoreorg.quartz.jobStore.class =org.quartz.impl.jdbcjobstore.JobStoreTX#数据源名称 必须org.quartz.jobStore.DataSource=mydatasource#驱动代理类 必须org.quartz.jobStore.DriverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegateorg.quartz.jobStore.useProperties=true#集群模式必须org.quartz.jobStore.isClustered=true#datasource数据源配置  也可使用jndiorg.quartz.dataSource=mydatasourceorg.quartz.dataSource.mydatasource.driver=com.mysql.jdbc.Driverorg.quartz.dataSource.mydatasource.URL=jdbc:mysql://192.168.118.134:3306/quartz?characterEncoding=utf-8&amp;useSSL=falseorg.quartz.dataSource.mydatasource.user=org.quartz.dataSource.mydatasource.password=org.quartz.dataSource.mydatasource.maxConnections=10#org.quartz.dataSource.mydatasource.connectionProvider.class=com.myquartz.config.MyConnectionProvider        ###更多配置 stdSchedulerFactory</code></pre><blockquote><p>调度工厂拥有两种构造器，通过properties 或者filepath 的方式加载配置文件，再通过配置文件创建调度器。</p></blockquote><h2 id="quartz-数据库表"><a href="#quartz-数据库表" class="headerlink" title="quartz 数据库表"></a>quartz 数据库表</h2><pre><code class="language-sql"> table qrtz_calendars;--存储calendars信息 table qrtz_fired_triggers;--存储已触发的触发器的状态和相关job信息 table qrtz_blob_triggers;--属于blob类型存储的自定义类型触发器 table qrtz_cron_triggers;--存储cron_triggers的触发器 table qrtz_simple_triggers;--存储简单的触发器 table qrtz_simprop_triggers;--存储CalendarIntervalTrigger和DailyTimeIntervalTrigger两种类型触发器 table qrtz_triggers;--存储触发器信息 table qrtz_job_details;-- 存储job信息 table qrtz_paused_trigger_grps;-- 存储已暂停的触发器 table qrtz_locks;--存储锁信息 table qrtz_scheduler_state;--存储调度器状态</code></pre><h2 id="spring集成quartz"><a href="#spring集成quartz" class="headerlink" title="spring集成quartz"></a>spring集成quartz</h2><blockquote><p>spring中已经集成了quartz ,其源码位置在spring-context 和 spring-context-support 下的scheduling包下，在传统的xml配置方式中，有个关键的类SchedulerFactoryBean，是作为spring和quartz连接的桥梁，在springboot中再次升级，采用自动配置的方式，所采用的类为QuartzAutoConfiguration，万变不离其宗，其中提供了关键了SchedulerFactoryBean的bean注入。</p></blockquote><h3 id="SchedulerFactoryBean"><a href="#SchedulerFactoryBean" class="headerlink" title="SchedulerFactoryBean"></a>SchedulerFactoryBean</h3><blockquote><p>SchedulerFactoryBean实现了InitializingBean ，其实现方法afterPropertiesSet即使关键中的关键，该方法默认会通过schedulerFactory创建一个stdscheduler，同时向stdscheduler中添加job ，触发器，以及监听器。</p></blockquote><pre><code class="language-java">@Overridepublic void afterPropertiesSet() throws Exception &#123;.......this.scheduler = prepareScheduler(prepareSchedulerFactory());try &#123;registerListeners();registerJobsAndTriggers();&#125;catch (Exception ex) &#123;......&#125;&#125;private SchedulerFactory prepareSchedulerFactory() throws SchedulerException, IOException &#123;SchedulerFactory schedulerFactory = this.schedulerFactory;if (schedulerFactory == null) &#123;schedulerFactory = BeanUtils.instantiateClass(this.schedulerFactoryClass);...return schedulerFactory;&#125;</code></pre><h3 id="QuartzAutoConfiguration"><a href="#QuartzAutoConfiguration" class="headerlink" title="QuartzAutoConfiguration"></a>QuartzAutoConfiguration</h3><blockquote><p>QuartzAutoConfiguration类是一个自动配置类，在项目启动时，通过@EnableAutoConfiguration进行配置的加载，该类出现在spring.factories文件中。其头部包括大量注解，通过@EnableConfigurationProperties(QuartzProperties.class)可以将quartz的配置信息从application配置文件中加载进来。AutoConfigureAfter则表示该类需要在指定的几个类都自动配置完成之后再进行配置。</p></blockquote><pre><code class="language-java">@Configuration(proxyBeanMethods = false)@ConditionalOnClass(&#123; Scheduler.class, SchedulerFactoryBean.class, PlatformTransactionManager.class &#125;)@EnableConfigurationProperties(QuartzProperties.class)@AutoConfigureAfter(&#123; DataSourceAutoConfiguration.class, HibernateJpaAutoConfiguration.class,LiquibaseAutoConfiguration.class, FlywayAutoConfiguration.class &#125;)</code></pre><blockquote><p>该类最为重要的是其中的quartzScheduler方法，其参数很多，具体如下,包括 几个重要的bean 其中有jobDetails，和 triggers 分别是任务和触发器的bean 表示该类方法还可将注册为bean的job和触发器 交由调度器调度 ，所以也可以直接将job和触发器注册为bean。</p></blockquote><pre><code class="language-java">@Bean@ConditionalOnMissingBeanpublic SchedulerFactoryBean quartzScheduler(QuartzProperties properties,ObjectProvider&lt;SchedulerFactoryBeanCustomizer&gt; customizers, ObjectProvider&lt;JobDetail&gt; jobDetails,Map&lt;String, Calendar&gt; calendars, ObjectProvider&lt;Trigger&gt; triggers, ApplicationContext applicationContext)</code></pre><h3 id="工具类"><a href="#工具类" class="headerlink" title="工具类"></a>工具类</h3><h4 id="application-yml"><a href="#application-yml" class="headerlink" title="application.yml"></a>application.yml</h4><pre><code class="language-yml">spring:  quartz:      schedulerName: myscheduler      autoStartup: true      job-store-type: JDBC#      jdbc:#          schema: classpath:org/quartz/impl/jdbcjobstore/tables_mysql.sql#      initialize-schema: ALWAYS# 可以用以添加quartz.properties有的配置      properties:           org:            quartz:scheduler:#全大写                    instanceId: AUTO                threadPool:                    class : org.quartz.simpl.SimpleThreadPool                    threadCount : 10                    threadPriority: 5                jobStore:                    isClustered: true</code></pre><h4 id="quartzMgr-java"><a href="#quartzMgr-java" class="headerlink" title="quartzMgr.java"></a>quartzMgr.java</h4><pre><code class="language-java">package com.myquartz.utils;import org.quartz.*;import java.util.ArrayList;import java.util.List;/** * quartz 工具类 * *Note: 一个job可以绑定多个触发器 一个触发器只能绑定一个job * 使用 *  1.将该类注入通过QuartzMgr(Scheduler scheduler)实例化 *  2.创建job createJob（...） *  3.绑定触发器 bindTrigger（....） * *  spring 注入 *   @ConditionalOnClass(value=&#123;SchedulerFactoryBean.class&#125;) *    @Bean *    public QuartzMgr quartzMgr(SchedulerFactoryBean quartzScheduler)&#123; *         QuartzMgr quartzMgr =new QuartzMgr(quartzScheduler.getScheduler()); *         return quartzMgr; *    &#125; */public final class QuartzMgr &#123;    private  QuartzMgr()&#123;&#125;    private static Scheduler scheduler = null;    /**     * 初始化     * @param scheduler     */    public  QuartzMgr(Scheduler scheduler)&#123;        if(this.scheduler==null)&#123;            synchronized (QuartzMgr.class)&#123;                if(this.scheduler==null)&#123;                    this.scheduler = scheduler;                &#125;            &#125;        &#125;    &#125;    /**     * 创建 job     * @param jobKey job名称 组     * @param job job执行class     * @param jobdescription job描述     * @param map job传入参数 可在job类中通过JobExecutionContext获得     * @return     * @throws SchedulerException     */    public JobKey createJob(JobKey jobKey,Class job,String jobdescription,JobDataMap map) throws SchedulerException, ClassNotFoundException &#123;        if(scheduler.checkExists(jobKey))&#123;            throw  new SchedulerException(jobKey.toString()+&quot;该job已存在&quot;);//            return jobKey;        &#125;       if(!Job.class.isAssignableFrom(job))&#123;//判断是Job的实现           throw  new SchedulerException(jobKey.toString()+&quot;该Class不是一个Job实现&quot;);       &#125;        JobDetail jobDetail = JobBuilder.newJob()                .ofType(job)                .storeDurably(true)//无论是否关联trigger都存在                .withIdentity(jobKey)                .withDescription(jobdescription)                .requestRecovery(true)//调度失败请求重新调度                .setJobData(map)                .build();        scheduler.addJob(jobDetail,false);        return jobKey;    &#125;    /**     * @see DailyTimeIntervalScheduleBuilder     * @see CronScheduleBuilder     * @see CalendarIntervalScheduleBuilder     * @see SimpleScheduleBuilder     * job绑定一个新触发器     * 一个job可以绑定多个触发器， 但是一个触发器只能绑定一个job     * @param jobKey 已存在的job 或者 createJob()创建     * @param triggerKey 触发器名称     * @param map  参数     * @param schedBuilder     * @see DailyTimeIntervalScheduleBuilder     * @see CronScheduleBuilder     * @see CalendarIntervalScheduleBuilder     * @see SimpleScheduleBuilder     * @param triggerdescription trigger描述     * @return     * @throws SchedulerException     */    public void bindTrigger(JobKey jobKey,TriggerKey triggerKey,JobDataMap map,ScheduleBuilder schedBuilder,String triggerdescription) throws SchedulerException &#123;        if(scheduler.checkExists(triggerKey))&#123;            throw  new SchedulerException(triggerKey.toString()+&quot;该触发器已存在&quot;);        &#125;        if(!scheduler.checkExists(jobKey))&#123;            throw  new SchedulerException(jobKey.toString()+&quot;该job不存在&quot;);        &#125;        TriggerBuilder triggerBuilder = TriggerBuilder.newTrigger();        triggerBuilder                .usingJobData(map)                .withIdentity(triggerKey)                .withSchedule(schedBuilder)//设定出发时间                .withDescription(triggerdescription)                .forJob(jobKey)                .startNow();        Trigger trigger = triggerBuilder.build();        scheduler.scheduleJob(trigger);//        return true;    &#125;    /**     * 更新触发时点     * @param     * @return     */    public void updateTrigger(TriggerKey oldtriggerKey,JobDataMap map,ScheduleBuilder schedBuilder,String triggerdescription) throws SchedulerException &#123;        if( !scheduler.checkExists(oldtriggerKey) )        &#123;            throw  new SchedulerException(oldtriggerKey.toString()+&quot;不存在&quot;);        &#125;        Trigger oldtrigger = scheduler.getTrigger(oldtriggerKey);        if (oldtrigger==null)&#123;            throw  new SchedulerException(oldtriggerKey.toString()+&quot;不存在&quot;);        &#125;        JobKey jobKey = oldtrigger.getJobKey();        Trigger newTrigger = TriggerBuilder.newTrigger()                    .startNow()                    .usingJobData(map)                    .forJob(jobKey)                    .withIdentity(oldtriggerKey)                    .withSchedule(schedBuilder)                    .withDescription(triggerdescription)                    .build();        scheduler.rescheduleJob(oldtriggerKey,newTrigger);//        return true;    &#125;    /**     * 删除任务     * @return     */    public void delScheduler(JobKey jobKey) throws SchedulerException &#123;        if(!scheduler.checkExists(jobKey))&#123;            throw  new SchedulerException(&quot;job&quot;+jobKey.toString()+&quot;不存在&quot;);        &#125;        List&lt;TriggerKey&gt; lists =getTriggerKeysOfJob(jobKey);        for(TriggerKey triggerKey : lists)&#123;            //停止触发器            scheduler.pauseTrigger(triggerKey);            //移除触发器            scheduler.unscheduleJob(triggerKey);        &#125;        //删除任务        scheduler.deleteJob(jobKey);        //return true;    &#125;    /**     * 停止任务     * @param jobKey     * @param triggerKey     * @return     */    public boolean pauseScheduler(JobKey jobKey,TriggerKey triggerKey) throws SchedulerException &#123;        if(!scheduler.checkExists(jobKey)|| !scheduler.checkExists(triggerKey))&#123;            throw  new SchedulerException(&quot;触发器&quot;+triggerKey.toString()+&quot;不存在或者job&quot;+jobKey.toString()+&quot;不存在&quot;);        &#125;        scheduler.pauseTrigger(triggerKey);        scheduler.pauseJob(jobKey);        return true;    &#125;    /**     * 恢复任务     * @param jobKey     * @param triggerKey     * @return     */    public boolean resumeScheduler(JobKey jobKey,TriggerKey triggerKey) throws SchedulerException &#123;        if(!scheduler.checkExists(jobKey)|| !scheduler.checkExists(triggerKey))&#123;            throw  new SchedulerException(&quot;触发器&quot;+triggerKey.toString()+&quot;不存在或者job&quot;+jobKey.toString()+&quot;不存在&quot;);        &#125;        scheduler.resumeJob(jobKey);        scheduler.resumeTrigger(triggerKey);        return true;    &#125;    /**     * 获得所有于该job绑定的触发器     * @param jobKey     * @return     */    public List&lt;TriggerKey&gt; getTriggerKeysOfJob(JobKey jobKey) throws SchedulerException &#123;        if(!scheduler.checkExists(jobKey))&#123;            throw  new SchedulerException(&quot;job&quot;+jobKey.toString()+&quot;不存在&quot;);        &#125;        List&lt;TriggerKey&gt; triggerKeys = new ArrayList&lt;&gt;();        List&lt;? extends Trigger&gt; triggers = scheduler.getTriggersOfJob(jobKey);        for (Trigger t:triggers) &#123;            triggerKeys.add(t.getKey());        &#125;        return triggerKeys;    &#125;    /**     * 获得触发器状态     *     * @param triggerKey     * @return NONE, NORMAL, PAUSED, COMPLETE, ERROR, BLOCKED     * @throws SchedulerException     */    public Trigger.TriggerState getTriggerState(TriggerKey triggerKey) throws SchedulerException &#123;        return  scheduler.getTriggerState(triggerKey);    &#125;    /**     * 获得正在执行的job     * @return     * @throws SchedulerException     */    public  List&lt;JobKey&gt; getExectingJob() throws SchedulerException &#123;        List&lt;JobKey&gt; jobKeys = new ArrayList&lt;&gt;();        List&lt;JobExecutionContext&gt; lists =scheduler.getCurrentlyExecutingJobs();        for(JobExecutionContext jobExecutionContext : lists)&#123;            jobKeys.add(jobExecutionContext.getJobDetail().getKey());        &#125;        return jobKeys;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> -spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -定时任务 -Quartz </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring统一异常处理</title>
      <link href="/2020/08/18/2020-08-18-%E7%BB%9F%E4%B8%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/"/>
      <url>/2020/08/18/2020-08-18-%E7%BB%9F%E4%B8%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="统一异常处理的使用"><a href="#统一异常处理的使用" class="headerlink" title="统一异常处理的使用"></a>统一异常处理的使用</h2><p>以下是一个会出现数组越界的例子，当出现问题时，通常使用try catch 将出现异常的代码块包起来，美观度极差！！！ ，通过使用spring的异常处理可以将所有的异常统一起来处理，不仅提高美观度，最主要是减少trycatch的重复使用。</p><pre><code class="language-java">@Controllerpublic class TestController &#123;@ResponseBody@RequestMapping(value = &quot;/hello&quot;,method = &#123;RequestMethod.GET&#125;)public String hello(HttpServletRequest request, HttpServletResponse response)&#123;response.setContentType(&quot;application/json&quot;);ArrayList list = new ArrayList();list.get(100);//数组越界return &quot;hello&quot;;&#125;&#125;</code></pre><p>只需添加如下类 使用@ControllerAdvice 控制增强，配合@ExceptionHandler使用 ,当发生数组越界异常则会使用IndexOutOfBoundsExceptionHandler方法统一对异常进行处理，当出现该类未处理的异常时，统一交给commonExceptionHandler对异常进行处理。</p><pre><code class="language-java">@ControllerAdvicepublic class DefaultExceptionHandler &#123;/** * 公共异常处理 * @param e * @return */@ExceptionHandler(value = &#123;Exception.class&#125;)public String commonExceptionHandler(Exception e)&#123;System.out.println(e.getMessage());return e.getMessage();&#125;/** * 处理数组越界 * @param e * @return */@ExceptionHandler(value = &#123;IndexOutOfBoundsException.class&#125;)public String IndexOutOfBoundsExceptionHandler(Exception e)&#123;System.out.println(e.getMessage());return e.getMessage();&#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> -spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -异常处理 -异常 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>spring事务</title>
      <link href="/2020/08/07/2020-08-07-spring%E4%BA%8B%E5%8A%A1/"/>
      <url>/2020/08/07/2020-08-07-spring%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h2 id="事务的特性ACID"><a href="#事务的特性ACID" class="headerlink" title="事务的特性ACID"></a>事务的特性ACID</h2><ul><li>原子性（Atomicity）：事务是一个原子操作，由一系列动作组成。事务的原子性确保动作要么全部完成，要么完全不起作用。</li><li>一致性（Consistency）：一旦事务完成（不管成功还是失败），系统必须确保它所建模的业务处于一致的状态，而不会是部分完成部分失败。在现实中的数据不应该被破坏。</li><li>隔离性（Isolation）：可能有许多事务会同时处理相同的数据，因此每个事务都应该与其他事务隔离开来，防止数据损坏。</li><li>持久性（Durability）：一旦事务完成，无论发生什么系统错误，它的结果都不应该受到影响，这样就能从任何系统崩溃中恢复过来。通常情况下，事务的结果被写到持久化存储器中。</li></ul><h2 id="事务的传播方式"><a href="#事务的传播方式" class="headerlink" title="事务的传播方式"></a>事务的传播方式</h2><blockquote><p>spring通过枚举类Propagation定义好了事务的传播方式 ，默认采用Propagation.REQUIRED</p></blockquote><pre><code class="language-java">public enum Propagation &#123;/** Spring默认的传播机制，能满足绝大部分业务需求，如果外层有事务，则当前事务加入到外层事务，一块提交，一块回滚。如果外层没有事务，新建一个事务执行 */REQUIRED(TransactionDefinition.PROPAGATION_REQUIRED),/** 如果外层有事务，则加入外层事务，如果外层没有事务，则直接使用非事务方式执行。完全依赖外层的事务 */SUPPORTS(TransactionDefinition.PROPAGATION_SUPPORTS),/** * Support a current transaction, throw an exception if none exists. 与NEVER相反，如果外层没有事务，则抛出异常 */MANDATORY(TransactionDefinition.PROPAGATION_MANDATORY),/** 该事务传播机制是每次都会新开启一个事务，同时把外层事务挂起，当当前事务执行完毕，恢复上层事务的执行。如果外层没有事务，执行当前新开启的事务即可 */REQUIRES_NEW(TransactionDefinition.PROPAGATION_REQUIRES_NEW),/** 该传播机制不支持事务，如果外层存在事务则挂起，执行完当前代码，则恢复外层事务，无论是否异常都不会回滚当前的代码 */NOT_SUPPORTED(TransactionDefinition.PROPAGATION_NOT_SUPPORTED),/** * Execute non-transactionally, throw an exception if a transaction exists. 该传播机制不支持外层事务，即如果外层有事务就抛出异常 */NEVER(TransactionDefinition.PROPAGATION_NEVER),/** * Execute within a nested transaction if a current transaction exists, 该传播机制的特点是可以保存状态保存点，当前事务回滚到某一个点，从而避免所有的嵌套事务都回滚，即各自回滚各自的，如果子事务没有把异常吃掉，基本还是会引起全部回滚的。 */NESTED(TransactionDefinition.PROPAGATION_NESTED);&#125;</code></pre><h2 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h2><blockquote><p>spring通过枚举类Isolation定义好事务的隔离级别 Isolation.DEFAULT</p></blockquote><pre><code class="language-java">public enum Isolation &#123;/** * Use the default isolation level of the underlying datastore. 数据库默认级别      */DEFAULT(TransactionDefinition.ISOLATION_DEFAULT),/** * A constant indicating that dirty reads, non-repeatable reads and phantom reads 允许读取尚未提交的更改。可能导致脏读、幻读或不可重复读。 */READ_UNCOMMITTED(TransactionDefinition.ISOLATION_READ_UNCOMMITTED),/** * A constant indicating that dirty reads are prevented; non-repeatable reads * and phantom reads can occur. This level only prohibits a transaction（Oracle 默认级别）允许从已经提交的并发事务读取。可防止脏读，但幻读和不可重复读仍可能会发生。 */READ_COMMITTED(TransactionDefinition.ISOLATION_READ_COMMITTED),/** * A constant indicating that dirty reads and non-repeatable reads are * prevented; phantom reads can occur. This level prohibits a transaction * from reading a row with uncommitted changes in it, and it also prohibits * the situation where one transaction reads a row, a second transaction * alters the row, and the first transaction rereads the row, getting （MYSQL默认级别）对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻读仍可能发生。 */REPEATABLE_READ(TransactionDefinition.ISOLATION_REPEATABLE_READ),/** * A constant indicating that dirty reads, non-repeatable reads and phantom * reads are prevented. This level includes the prohibitions in * &#123;@code ISOLATION_REPEATABLE_READ&#125; and further prohibits the situation * where one transaction reads all rows that satisfy a &#123;@code WHERE&#125; * condition, a second transaction inserts a row that satisfies that * &#123;@code WHERE&#125; condition, and the first transaction rereads for the * same condition, retrieving the additional &quot;phantom&quot; row in the second read. * 完全服从ACID的隔离级别，确保不发生脏读、不可重复读和幻影读。这在所有隔离级别中也是最慢的，因为它通常是通过完全锁定当前事务所涉及的数据表来完成的。 */SERIALIZABLE(TransactionDefinition.ISOLATION_SERIALIZABLE);&#125;</code></pre><h2 id="脏-幻-不可重复读"><a href="#脏-幻-不可重复读" class="headerlink" title="脏 幻 不可重复读"></a>脏 幻 不可重复读</h2><ul><li><p>脏读（Dirty read）：脏读发生在一个事务读取了被另一个事务改写但尚未提交的数据时。如果这些改变在稍后被回滚了，那么第一个事务读取的数据就会是无效的。 </p></li><li><p>幻读（Phantom reads）：幻读和不可重复读相似。当一个事务（T1）读取几行记录后，另一个并发事务（T2）插入了一些记录时，幻读就发生了。在后来的查询中，第一个事务（T1）就会发现一些原来没有的额外记录。     </p></li><li><p>不可重复读（Nonrepeatable read）：不可重复读发生在一个事务执行相同的查询两次或两次以上，但每次查询结果都不相同时。这通常是由于另一个并发事务在两次查询之间更新了数据。</p></li></ul><h2 id="声明式-Transactional的使用"><a href="#声明式-Transactional的使用" class="headerlink" title="声明式 @Transactional的使用"></a>声明式 @Transactional的使用</h2><p>@Transactional可加在类 或方法 上面。Transactional这个注解中有以下参数</p><pre><code class="language-java">public @interface Transactional &#123;/** * Alias for &#123;@link #transactionManager&#125;. * @see #transactionManager 事务管理器别名默认即可 */@AliasFor(&quot;transactionManager&quot;)String value() default &quot;&quot;;/** * 指定一个事务管理器 */@AliasFor(&quot;value&quot;)String transactionManager() default &quot;&quot;;/** * 事务传播方式 */Propagation propagation() default Propagation.REQUIRED;/** * 事务隔离级别 */Isolation isolation() default Isolation.DEFAULT;/** * 事务超时时间 */int timeout() default TransactionDefinition.TIMEOUT_DEFAULT;/** * 当只读取数据时使用 */boolean readOnly() default false;/** * 指定0到多个异常类 当发生这些异常时回滚 */Class&lt;? extends Throwable&gt;[] rollbackFor() default &#123;&#125;;/** * 指定0到多个异常类名 当发生这些异常时回滚 */String[] rollbackForClassName() default &#123;&#125;;/** * 指定0到多个异常类 当发生这些异常时不回滚 */Class&lt;? extends Throwable&gt;[] noRollbackFor() default &#123;&#125;;/** * 指定0到多个异常类名 当发生这些异常时不回滚 */String[] noRollbackForClassName() default &#123;&#125;;&#125;</code></pre><h2 id="编程式事务"><a href="#编程式事务" class="headerlink" title="编程式事务"></a>编程式事务</h2><p>spring提供的一个模板类 TransactionTemplate 该方法一般通过一个事务管理器创建，通过查看spring的测试案例我们可以看到其使用方式。</p><pre><code class="language-java">@Testpublic void testPropagationNeverWithExistingTransaction() throws Exception &#123;        //通过事务管理器创建TransactionTemplatefinal TransactionTemplate tt = new TransactionTemplate(tm);...try &#123;tt.execute(new TransactionCallbackWithoutResult() &#123;@Overrideprotected void doInTransactionWithoutResult(TransactionStatus status) throws RuntimeException &#123;                    //具体的业务逻辑等                     .....&#125;&#125;);&#125;catch (IllegalTransactionStateException ex) &#123;// expected&#125;        ...&#125;//TransactionCallbackWithoutResult是TransactionCallback的实现 ，其中的doInTransaction调用doInTransactionWithoutResultpublic abstract class TransactionCallbackWithoutResult implements TransactionCallback&lt;Object&gt; &#123;@Override@Nullablepublic final Object doInTransaction(TransactionStatus status) &#123;doInTransactionWithoutResult(status);return null;&#125;protected abstract void doInTransactionWithoutResult(TransactionStatus status);&#125;// 也可直接实现TransactionCallback接口的doInTransaction@Testpublic void testPropagationNeverWithExistingTransaction() throws Exception &#123;        //通过事务管理器创建TransactionTemplatefinal TransactionTemplate tt = new TransactionTemplate(tm);...try &#123;tt.execute(status-&gt;&#123;                //具体的业务逻辑等                 ...            &#125;);&#125;catch (IllegalTransactionStateException ex) &#123;// expected&#125;        ...&#125;//事务前后的//是否有进行中的事务if(TransactionSynchronizationManager.isActualTransactionActive())&#123;    TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronization() &#123;        //事务提交后执行@Override        public void afterCommit() &#123;            // 具体的业务逻辑等              ...            &#125; @Override            public void beforeCommit(boolean readOnly) &#123;                //事务提交前 beforeCompletion之前            &#125;            @Override            public void beforeCompletion() &#123;                //事务提交/回滚前             &#125;            @Override            public void afterCompletion(int status) &#123;                //事务提交/回滚后执行            &#125;&#125;);&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> -spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>springMock的使用</title>
      <link href="/2020/08/05/2020-08-05-springMock%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2020/08/05/2020-08-05-springMock%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="mockmvc使用示例"><a href="#mockmvc使用示例" class="headerlink" title="mockmvc使用示例"></a>mockmvc使用示例</h2><pre><code class="language-java">import com.App;import org.junit.Test;import org.junit.Ignore;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.http.MediaType;import org.springframework.test.context.event.annotation.BeforeTestMethod;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.MvcResult;import org.springframework.test.web.servlet.ResultMatcher;import org.springframework.test.web.servlet.result.MockMvcResultHandlers;import org.springframework.web.context.WebApplicationContext;import static org.springframework.test.web.servlet.request.MockMvcRequestBuilders.*;import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.*;import static org.springframework.test.web.servlet.setup.MockMvcBuilders.*;@RunWith(SpringRunner.class)//App.class 启动类@SpringBootTest(classes = &#123;App.class&#125;)public class TestMock &#123;@AutowiredWebApplicationContext wac;private MockMvc mvc;    /**    * 任何测试方法执行前执行    */@Beforepublic void prepareMockMvc() &#123;this.mvc = webAppContextSetup(wac).build();&#125;/**    * 任何测试方法执行后执行    */@Afterpublic void endMockMvc() &#123;&#125;//MockMvcRequestBuilders.multipart().file( MockMultipartFile  mockMultipartFile)  测试文件上传@Testpublic void test() throws  Exception&#123;MvcResult res= mvc.perform(MockMvcRequestBuilders.get(&quot;/hello&quot;)).andExpect(ResultMatcher.matchAll(status().isOk())).andExpect(ResultMatcher.matchAll(content().contentType(MediaType.APPLICATION_JSON))).andDo(MockMvcResultHandlers.log()).andReturn();        System.out.print(res.getResponce().getContextAsString());//获取返回结果&#125;    /**    * 忽略test1    */    @Ignore    @Testpublic void test1() throws  Exception&#123;MvcResult res= mvc.perform(MockMvcRequestBuilders.get(&quot;/hello&quot;).param(&quot;a&quot;,&quot;1&quot;)).andExpect(ResultMatcher.matchAll(status().isOk())).andExpect(ResultMatcher.matchAll(content().contentType(MediaType.APPLICATION_JSON))).andDo(MockMvcResultHandlers.log()).andReturn();&#125;    /**  @beforeClass  @AfterClass  所以测试方法前执行 所以方法执行后执行  必须使用 public static void  修饰方法      执行顺序 1.@beforeClass 2.@Before 3.@Test 4.@After 5.@AfterClass*/&#125;</code></pre><h2 id="shiro测试"><a href="#shiro测试" class="headerlink" title="shiro测试"></a>shiro测试</h2><pre><code class="language-java">private MockMvc mvc;@Autowiredprivate WebApplicationContext context;@Resourceprivate SecurityManager securityManager;private Subject subject;private MockHttpServletRequest mockHttpServletRequest;private MockHttpServletResponce mockHttpServletResponce;@Beforepublic void setup()&#123;mockHttpServletRequest = new MockHttpServletRequest(context.getServletContext());mockHttpServletResponce = new MockHttpServletResponce();MockHttpSession mockHttpSession = new MockHttpSession(context.getServletContext())mockHttpServletRequest.setSession(mockHttpSession);SecurityUtils.setSecurityManager(securityManager);this.mvc = webAppContextSetup(wac).build();subject = new WebSubject.builder(mockHttpServletRequest,mockHttpServletResponce).buildWebSubject();UsernamePasswordToken  token = new UsernamePasswordToken(......);subject.login(token);ThreadContext.bind(subject);&#125;@Testpublic void Test()&#123;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> -spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -mock -junit </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重新认识weblogic</title>
      <link href="/2020/07/13/2020-07-13-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86weblogic/"/>
      <url>/2020/07/13/2020-07-13-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86weblogic/</url>
      
        <content type="html"><![CDATA[<blockquote><p>&emsp;&emsp;由于之前所接触的项目中，使用weblogic实在windowsserver上面操作，安装界面部署界面都是以图形化为主，最近的项目使用的weblogic则是在linux环境下的，所有重新了解下weblogic在linux下的使用。此处以weblogic12为例</p></blockquote><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><blockquote><p>&emsp;&emsp;其实在linux下面也是可以使用图形化安装界面的，但是,是不是觉得在Linux下面还用图形化界面，太low了。所有这里采用静默安装的方式，看着这一堆小黑窗口是不是感觉很高大上。</p></blockquote><ul><li>1.创建weblogic用户 配置jdk1.8环境变量</li></ul><pre><code class="language-cmd">#创建用户组[root@192 home]$ groupadd weblogic[root@192 home]$ useradd  -g weblogic weblogic[root@192 home]$ passwd weblogic # 切换用户到weblogic 配置环境变量[weblogic@192 home]$ cat  &lt;&lt; EOF &gt;&gt; ~/.bash_profileexport JAVA_HOME=/home/weblogic/jdk/jdk1.8.0_201export JRE_HOME=\$JAVA_HOME/jreexport CLASSPATH=.:\$JAVA_HOME/lib/dt.jar:\$JAVA_HOME/lib/tools.jar:\$JRE_HOME/libexport PATH=\$JAVA_HOME/bin:\$PATHEOF[weblogic@192 home]$source ~/.bash_profile</code></pre><p>*NOTE 提示权限不足需要给足权限</p><blockquote><p>chmod +x  &#x2F;home&#x2F;weblogic&#x2F;jdk&#x2F;jdk1.8.0_201&#x2F;bin&#x2F;javac<br>chmod +x  &#x2F;home&#x2F;weblogic&#x2F;jdk&#x2F;jdk1.8.0_201&#x2F;bin&#x2F;java </p></blockquote><ul><li>2.创建rsp响应文件</li></ul><pre><code class="language-cmd">[weblogic@192 home]$ touch wls.rsp[weblogic@192 home]$ cat &lt;&lt; EOF &gt;wls.rsp[ENGINE]Response File Version=1.0.0.0.0[GENERIC]#ORACLE_HOME weblogic位置 主要文件位置权限ORACLE_HOME=/home/weblogic/beaINSTALL_TYPE=WebLogic ServerMYORACLESUPPORT_USERNAME=MYORACLESUPPORT_PASSWORD=&lt;SECURE VALUE&gt;DECLINE_SECURITY_UPDATES=trueSECURITY_UPDATES_VIA_MYORACLESUPPORT=falsePROXY_HOST=PROXY_PORT=PROXY_USER=PROXY_PWD=&lt;SECURE VALUE&gt;COLLECTOR_SUPPORTHUB_URL=EOF</code></pre><ul><li>3.创建loc文件</li></ul><pre><code class="language-cmd">[root@192 home]$ touch oraInst.loc[root@192 home]$ cat &lt;&lt; EOF &gt;&gt;oraInst.locinventory_loc=/home/weblogic/oraInventory# 实际创建的用户组inst_group=weblogicEOF</code></pre><ul><li>执行静默安装</li></ul><pre><code class="language-cmd">#-silent表示采用静默安装#-ignoreSysPrereqs 忽略一些输出 可以不加[weblogic@192 home]$ java -jar /home/weblogic/fmw_12.2.1.4.0_wls_lite_generic.jar \-silent \-responseFile /home/weblogic/wls.rsp \-invPtrLoc /home/weblogic/oraInst.loc -ignoreSysPrereqs</code></pre><h2 id="域创建"><a href="#域创建" class="headerlink" title="域创建"></a>域创建</h2><ul><li>1.复制建域的脚本文件</li></ul><pre><code class="language-cmd">## 重置linux随机数来源 建域较快[weblogic@192 home]$ export CONFIG_JVM_ARGS=&#39;-Djava.security.egd=file:/dev/urandom&#39;[weblogic@192 home]$ cd /home/weblogic/bea/wlserver/common/templates/scripts/wlst[weblogic@192 wlst]$ cp basicWLSDomain.py mybasicWLSDomain.py</code></pre><ul><li>2.编辑模板文件</li></ul><pre><code class="language-cmd">#=======================================================================================# This is an example of a simple WLST offline configuration script. The script creates# a simple WebLogic domain using the Basic WebLogic Server Domain template. The script# demonstrates how to open a domain template, create and edit configuration objects,# and write the domain configuration information to the specified directory.## This sample uses the demo Derby Server that is installed with your product.# Before starting the Administration Server, you should start the demo Derby server# by issuing one of the following commands:## Windows: WL_HOME\common\derby\bin\startNetworkServer.cmd# UNIX: WL_HOME/common/derby/bin/startNetworkServer.sh## (WL_HOME refers to the top-level installation directory for WebLogic Server.)## The sample consists of a single server, representing a typical development environment.# This type of configuration is not recommended for production environments.## Please note that some of the values used in this script are subject to change based on# your WebLogic installation and the template you are using.## Usage:#      java weblogic.WLST &lt;WLST_script&gt;## Where:#      &lt;WLST_script&gt; specifies the full path to the WLST script.#=======================================================================================#=======================================================================================# Open a domain template.#=======================================================================================#默认就可以readTemplate(&quot;/home/weblogic/bea/wlserver/common/templates/wls/wls.jar&quot;)#=======================================================================================# Configure the Administration Server and SSL port.## To enable access by both local and remote processes, you should not set the# listen address for the server instance (that is, it should be left blank or not set).# In this case, the server instance will determine the address of the machine and# listen on it.#=======================================================================================cd(&#39;Servers/AdminServer&#39;)#监听地址set(&#39;ListenAddress&#39;,&#39;&#39;) #端口set(&#39;ListenPort&#39;, 7001)create(&#39;AdminServer&#39;,&#39;SSL&#39;)cd(&#39;SSL/AdminServer&#39;)set(&#39;Enabled&#39;, &#39;True&#39;)set(&#39;ListenPort&#39;, 7002)#=======================================================================================# Define the user password for weblogic.#=======================================================================================cd(&#39;/&#39;)cd(&#39;Security/base_domain/User/weblogic&#39;)# Please set password here before using this script, e.g. cmo.setPassword(&#39;value&#39;)#设置控制台登录密码cmo.setPassword(&#39;weblogic123&#39;)#=======================================================================================# Create a JMS Server.#=======================================================================================#cd(&#39;/&#39;)#create(&#39;myJMSServer&#39;, &#39;JMSServer&#39;)#=======================================================================================# Create a JMS System resource.#=======================================================================================#cd(&#39;/&#39;)#create(&#39;myJmsSystemResource&#39;, &#39;JMSSystemResource&#39;)#cd(&#39;JMSSystemResource/myJmsSystemResource/JmsResource/NO_NAME_0&#39;)#=======================================================================================# Create a JMS Queue and its subdeployment.#=======================================================================================#myq=create(&#39;myQueue&#39;,&#39;Queue&#39;)#myq.setJNDIName(&#39;jms/myqueue&#39;)#myq.setSubDeploymentName(&#39;myQueueSubDeployment&#39;)#cd(&#39;/&#39;)#cd(&#39;JMSSystemResource/myJmsSystemResource&#39;)#create(&#39;myQueueSubDeployment&#39;, &#39;SubDeployment&#39;)#=======================================================================================# Create and configure a JDBC Data Source, and sets the JDBC user.#=======================================================================================#cd(&#39;/&#39;)#create(&#39;myDataSource&#39;, &#39;JDBCSystemResource&#39;)#cd(&#39;JDBCSystemResource/myDataSource/JdbcResource/myDataSource&#39;)#create(&#39;myJdbcDriverParams&#39;,&#39;JDBCDriverParams&#39;)#cd(&#39;JDBCDriverParams/NO_NAME_0&#39;)#set(&#39;DriverName&#39;,&#39;org.apache.derby.jdbc.ClientDriver&#39;)#set(&#39;URL&#39;,&#39;jdbc:derby://localhost:1527/db;create=true&#39;)#set(&#39;PasswordEncrypted&#39;, &#39;PBPUBLIC&#39;)#set(&#39;UseXADataSourceInterface&#39;, &#39;false&#39;)#create(&#39;myProps&#39;,&#39;Properties&#39;)#cd(&#39;Properties/NO_NAME_0&#39;)#create(&#39;user&#39;, &#39;Property&#39;)#cd(&#39;Property/user&#39;)#cmo.setValue(&#39;PBPUBLIC&#39;)#cd(&#39;/JDBCSystemResource/myDataSource/JdbcResource/myDataSource&#39;)#create(&#39;myJdbcDataSourceParams&#39;,&#39;JDBCDataSourceParams&#39;)#cd(&#39;JDBCDataSourceParams/NO_NAME_0&#39;)#set(&#39;JNDIName&#39;, java.lang.String(&quot;myDataSource_jndi&quot;))#cd(&#39;/JDBCSystemResource/myDataSource/JdbcResource/myDataSource&#39;)#create(&#39;myJdbcConnectionPoolParams&#39;,&#39;JDBCConnectionPoolParams&#39;)#cd(&#39;JDBCConnectionPoolParams/NO_NAME_0&#39;)#set(&#39;TestTableName&#39;,&#39;SYSTABLES&#39;)#=======================================================================================# Target resources to the servers.#=======================================================================================#cd(&#39;/&#39;)#assign(&#39;JMSServer&#39;, &#39;myJMSServer&#39;, &#39;Target&#39;, &#39;AdminServer&#39;)#assign(&#39;JMSSystemResource.SubDeployment&#39;, &#39;myJmsSystemResource.myQueueSubDeployment&#39;, &#39;Target&#39;, &#39;myJMSServer&#39;)#assign(&#39;JDBCSystemResource&#39;, &#39;myDataSource&#39;, &#39;Target&#39;, &#39;AdminServer&#39;)#=======================================================================================# Write the domain and close the domain template.#=======================================================================================setOption(&#39;OverwriteDomain&#39;, &#39;true&#39;)setOption(&#39;JavaHome&#39;, &#39;/home/weblogic/jdk/jdk1.8.0_201&#39;)#新建域指定路径writeDomain(&#39;/home/weblogic/bea/wlserver/../user_projects/domains/basicWLSDomain&#39;)closeTemplate()#=======================================================================================# Exit WLST.#=======================================================================================exit()</code></pre><ul><li>3.通过模板创建域</li></ul><p>相关配置信息<a href="https://docs.oracle.com/en/middleware/fusion-middleware/weblogic-server/12.2.1.4/wlstc/reference.html">https://docs.oracle.com/en/middleware/fusion-middleware/weblogic-server/12.2.1.4/wlstc/reference.html</a></p><pre><code>/home/weblogic/bea/wlserver/common/bin/wlst.sh /home/weblogic/bea/wlserver/common/templates/scripts/wlst/mybasicWLSDomain.py</code></pre><h2 id="weblogic免密后台启动"><a href="#weblogic免密后台启动" class="headerlink" title="weblogic免密后台启动"></a>weblogic免密后台启动</h2><p>&emsp;&emsp;weblogic生产模式启动时候会在控制台提示输入用户名密码，所有当我们在后台启动时 我们需要为其提供用户名密码的认证信息 ，在管理服务器域路径下，我们找到 域路径&#x2F;servers&#x2F;AdminServer&#x2F;security&#x2F; 下面创建引导文件 ，boot.properties ,被管服务器只需将管理服务器的复制过去即可。<br>内容如下：</p><pre><code>#Wed Jul 15 09:44:19 CST 2020password=weblogicusername=weblogic#Wed Jul 15 09:44:19 CST 2020password=&#123;AES256&#125;M8r8F3clbzHlwaa2FiE0z9qlpw/8U3Km1Ak/CdZzpPI\=username=&#123;AES256&#125;LoWSJCP+eiK8fBw/M1kIC1t3/WAG2h0uCGBVP6RzolU\=</code></pre><p>该文件只需输入明文密码即可 ，在启动服务器后，weblogic会将明文加密 。之后即可使用后台启动服务 ，无需在控制台输入密码。</p><pre><code># 启动管理服务器nohup ./startWeblogic.sh &gt; Adminserver.log 2&gt;&amp;1 &amp;# Server-1 启动的被管服务器 ip 管理服务器ip port 管理服务器端口nohup ./startManagedWebLogic.sh Server-1 t3://ip:port &gt; server-1.log 2&gt;&amp;1 &amp;</code></pre><h2 id="命令行部署"><a href="#命令行部署" class="headerlink" title="命令行部署"></a>命令行部署</h2><p>官方文档：<a href="https://docs.oracle.com/middleware/12212/wls/DEPGD/wldeployer.htm#DEPGD318">https://docs.oracle.com/middleware/12212/wls/DEPGD/wldeployer.htm#DEPGD318</a></p><p>在Server-0,Server-1 上部署项目 多个被管服务器逗号分开不能有空格。<br>用户名密码可以使用配置文件和key这样密码就不会暴露在命令行[-userconfigfile config-file [-userkeyfile admin-key]]</p><pre><code>java -cp /home/weblogic/bea/wlserver/server/lib/weblogic.jar weblogic.Deployer \-adminurl t3://192.168.118.131:7001 \-userconfigfile /home/weblogic/script/myuserconfigfile.secure -userkeyfile /home/weblogic/script/myuserkfile.secure \-targets Server-0,Server-1 \-name webapp \-deploy /home/weblogic/script/App/webapp.war \-appversion v1.0.0</code></pre><h2 id="使用weblogic脚本工具-wlst"><a href="#使用weblogic脚本工具-wlst" class="headerlink" title="使用weblogic脚本工具 wlst"></a>使用weblogic脚本工具 wlst</h2><p>官方文档:<a href="https://docs.oracle.com/en/middleware/fusion-middleware/12.2.1.4/wlstg/using_wlst.html">https://docs.oracle.com/en/middleware/fusion-middleware/12.2.1.4/wlstg/using_wlst.html</a></p><pre><code>java -cp /home/weblogic/bea/wlserver/server/lib/weblogic.jar weblogic.WLST</code></pre><ul><li>生成连接的配置和key</li></ul><pre><code>wls:/offline&gt; connect(&#39;weblogic&#39;,&#39;weblogic123&#39;,&#39;t3://192.168.118.131:7001&#39;)Connecting to t3://192.168.118.131:7001 with userid weblogic ...wls:/basicWLSDomain/serverConfig/&gt; storeUserConfig(&#39;/home/weblogic/script/myuserconfigfile.secure&#39;,&#39;/home/weblogic/script/myuserkfile.secure&#39;)wls:/offline&gt; connect(userConfigFile=&#39;/home/weblogic/script/myuserconfigfile.secure&#39;,userKeyFile=&#39;/home/weblogic/script/myuserkfile.secure&#39;)wls:/basicWLSDomain/serverConfig/&gt; exit()</code></pre>]]></content>
      
      
      <categories>
          
          <category> -服务器 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -weblogic -oracle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Oracle常用命令</title>
      <link href="/2020/06/19/2020-06-19-Oracle%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/2020/06/19/2020-06-19-Oracle%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h3 id="Jdbc连接的方式"><a href="#Jdbc连接的方式" class="headerlink" title="Jdbc连接的方式"></a>Jdbc连接的方式</h3><pre><code class="language-sql">-- 1.SID-- jdbc:oracle:thin:@localhost:1521:SID-- 2.url-- jdbc:oracle:thin:@//host:port/service_name -- tns-- jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.16.91)(PORT=1521)))(CONNECT_DATA=(SERVICE_NAME=orcl)))-- tns名-- jdbc:oracle:thin:@tnsname/*方法一：在启动VM 时添加如下参数:-Doracle.net.tns_admin=D:\app\Administrator\product\11.2.0\dbhome_1\NETWORK\ADMIN     方法二：在java 代码里添加：System.setProperty(&quot;oracle.net.tns_admin&quot;,&quot;D:\\app\\Administrator\\product\\11.2.0\\dbhome_1\\NETWORK\\ADMIN&quot;); */</code></pre><!-- ### 表分析```sql/*目前表分析策略并行度设置为15；数据量分布如下<1G 抽样30%;<10G 抽样10%;<50G 抽样5%; >50G 抽样1%*/select case         when sizes <= 1 then          'execute dbms_stats.gather_table_stats(' || '''' || OWNER || '''' || ',' || '''' ||          segment_name || '''' || ',' || 'method_opt => ' || '''' ||          'FOR ALL COLUMNS SIZE 1' || '''' ||          ',estimate_percent => 30,degree => 15,cascade =>true,no_invalidate => false);'         when (sizes < 10 and sizes > 1) then          'execute dbms_stats.gather_table_stats(' || '''' || OWNER || '''' || ',' || '''' ||          segment_name || '''' || ',' || 'method_opt => ' || '''' ||          'FOR ALL COLUMNS SIZE 1' || '''' ||          ',estimate_percent => 10,degree => 15,cascade =>true,no_invalidate => false);'         when (sizes >= 10 and sizes <= 50) then          'execute dbms_stats.gather_table_stats(' || '''' || OWNER || '''' || ',' || '''' ||          segment_name || '''' || ',' || 'method_opt => ' || '''' ||          'FOR ALL COLUMNS SIZE 1' || '''' ||          ',estimate_percent => 5,degree => 15,cascade =>true,no_invalidate => false);'         when (sizes > 50) then          'execute dbms_stats.gather_table_stats(' || '''' || OWNER || '''' || ',' || '''' ||          segment_name || '''' || ',' || 'method_opt => ' || '''' ||          'FOR ALL COLUMNS SIZE 1' || '''' ||          ',estimate_percent => 1,degree => 15,cascade =>true,no_invalidate => false);'       end  from (select t.owner,               t.segment_name,               (sum(t.bytes) / 1024 / 1024 / 1024) sizes          from dba_segments t, dba_tables b         where 1=1          --T.OWNER IN ('ACCOUNT', 'USERINFO', 'CUSTUPLOAD', 'REPORT')          --T.OWNER IN ('TBCS','COMMON','IM','IM_COMM')           and t.segment_name not like 'BIN$%'          --and t.owner='ICDPUB'           and t.segment_type like 'TABLE%'           and b.table_name = t.segment_name           and b.owner = t.owner           and b.last_analyzed < sysdate - 1          --and b.table_name='SUBS_PRIVILEGE'         group by t.owner, t.segment_name         order by sizes);``` --><h3 id="表空间占用"><a href="#表空间占用" class="headerlink" title="表空间占用"></a>表空间占用</h3><pre><code class="language-sql">select a.tablespace_name &quot;表空间&quot;, total &quot;总量&quot;, free &quot;剩余大小&quot;, (total - free) &quot;已用&quot;, total / 1024 / 1024 / 1024 &quot;总量GB&quot;, free / 1024 / 1024 / 1024 &quot;剩余GB&quot;, (total - free) / 1024 / 1024 / 1024 &quot;已用GB&quot;, round((total - free) / total, 4) * 100 &quot;使用率%&quot;from (select tablespace_name, sum(bytes) freefrom dba_free_space group by tablespace_name) a, (select tablespace_name, sum(bytes) totalfrom dba_data_files group by tablespace_name) b where a.tablespace_name = b.tablespace_name;</code></pre><h3 id="表空间内表排序"><a href="#表空间内表排序" class="headerlink" title="表空间内表排序"></a>表空间内表排序</h3><pre><code class="language-sql">select segment_name as 表名, sum(bytes) / 1024 / 1024 &quot;size(MB)&quot;, sum(bytes) / 1024 / 1024 / 1024 &quot;size(GB)&quot;from user_segments where tablespace_name = &#39;CORE_DATA&#39; group by segment_name order by &quot;size(GB)&quot; desc;</code></pre><h3 id="查询表字段"><a href="#查询表字段" class="headerlink" title="查询表字段"></a>查询表字段</h3><pre><code class="language-sql">select * from user_tab_cols q where q.TABLE_NAME=upper(&#39;Table_name&#39;)</code></pre><h3 id="导出"><a href="#导出" class="headerlink" title="导出"></a>导出</h3><pre><code class="language-sql">--客户端exp username/passowrd@ip:port/sid file=/test.dmp tables=tablename1,tablename2,......--服务端 oracle10g及之后版本expdp username/passowrd@ip:port/sid directory=/path dumpfile=filename.dp  logfile=filename.dp.log schema= \     Full=y \-- 备份全表     tables=&#39;table1&#39;,&#39;table2&#39;,&#39;table3&#39; \ --指定表</code></pre><h3 id="导入"><a href="#导入" class="headerlink" title="导入"></a>导入</h3><pre><code class="language-sql">--客户端imp username/passowrd@ip:port/sid file=/test.dmp  from user1 to user2   full=y ignore=y--服务端 oracle10g及之后版本impdp username/passowrd@ip:port/sid directory=/path dumpfile=filename.dp  logfile=filename.dp.log remap_schema=</code></pre><h2 id="sql查询"><a href="#sql查询" class="headerlink" title="sql查询"></a>sql查询</h2><h3 id="填充函数"><a href="#填充函数" class="headerlink" title="填充函数"></a>填充函数</h3><pre><code class="language-sql">Lpad(str , len,  padstr);  --左填充  str 字段 len 填充长度，padstr 填充字符Rpad(str , len,  padstr);  --右填充eg：左边补0 select Lpad(&#39;test&#39;, 10, &#39;0&#39;) from dual ; -- out：   0000000000test</code></pre><h3 id="树查询-start-with"><a href="#树查询-start-with" class="headerlink" title="树查询  start with"></a>树查询  start with</h3><pre><code class="language-sql">select * from  table where 1=1and connect_by_isleaf=1 -- 是否叶子节点（0否/1是）start with  树起始条件connect by prior (父字段=子字段)(子字段-=父字段)</code></pre><h2 id="常用分析函数"><a href="#常用分析函数" class="headerlink" title="常用分析函数"></a>常用分析函数</h2><blockquote><p>分析函数形式 xxxx(….) over( [partittion by colom1,colom2….] [order by colom1,colom2…. ] )</p></blockquote><h3 id="1-排序"><a href="#1-排序" class="headerlink" title="1.排序"></a>1.排序</h3><pre><code class="language-sql">--1.遇到相同记录数据 按排名递增row_number() over(     [partittion by colom1,colom2....]     [order by colom1,colom2.... ] )--2.遇到相同记录数据 按排名相同dense-rank() over(     [partittion by colom1,colom2....]     [order by colom1,colom2.... ] )--3.遇到相同记录数据 按排名相同 同时会在最后一条相同记录和下一个不同记录之间空出排名rank() over(     [partittion by colom1,colom2....]     [order by colom1,colom2.... ] )</code></pre><h3 id="2-求之前之后的第N行"><a href="#2-求之前之后的第N行" class="headerlink" title="2.求之前之后的第N行"></a>2.求之前之后的第N行</h3><pre><code class="language-sql">-- comlm 指定字段 offset 偏移量 即N 默认为1，defval 默认返回值 （默认为null）lag(colom ,offset,defval) over() -- 前N行lead(colom ,offset,defval) over()-- 后N行</code></pre><h3 id="3-排列组合"><a href="#3-排列组合" class="headerlink" title="3.排列组合"></a>3.排列组合</h3><pre><code class="language-sql">-- 1.rollup()--eg: group by rollup( a ,b,c)-- 按照 abc  ab a 依次进行分组-- 2.cube()--eg:group by cube( a ,b,c)-- 按照 abc ab ac a bc b c 依次进行分组</code></pre>]]></content>
      
      
      <categories>
          
          <category> -数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -Oracle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Rabbitmq的介绍及使用</title>
      <link href="/2020/04/28/2020-04-28-Rabbitmq%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
      <url>/2020/04/28/2020-04-28-Rabbitmq%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="AMQP协议"><a href="#AMQP协议" class="headerlink" title="AMQP协议"></a>AMQP协议</h2><blockquote><p>&emsp;&emsp;AMQP，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端&#x2F;中间件不同产品，不同的开发语言等条件的限制。Erlang中的实现有RabbitMQ等。</p></blockquote><h2 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h2><blockquote><p>&emsp;&emsp;rabbitmq就是一个支持amqp协议的消息中间件 ,主要以 交换机（Exchange）、队列（queue）、 消息（Messages）、路由（routing key） 组成. 交换机呢又分为directExchange、 fanoutExchange 、headersExchange、 topicExchange 这几种 </p></blockquote><blockquote><ul><li>direct: 分发到完全匹配 路由key的所有队列</li><li>fanout: 分发所有交换机数据到所有队列</li><li>headers: 分发消息通过headers属性匹配的到队列</li><li>topic: 与direct类似 只是路由匹配规则不同</li></ul></blockquote><p>topic key  eg:A.B.C 、A*.B 、A#B ……等等类似</p><img src="/.io//04/28/2020-04-28-Rabbitmq%E7%9A%84%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8/2020-04-28151754.png" class><h2 id="spring-rabbitmq-启动原理"><a href="#spring-rabbitmq-启动原理" class="headerlink" title="spring rabbitmq 启动原理"></a>spring rabbitmq 启动原理</h2><blockquote><p>springboot启动会加载META-INF 下的spring.factories文件对其中的部分类自动注入 ， 其中包括RabbitAutoConfiguration ，对rabbitmq的连接工厂 rabbitTemplate amqpAdmin  等 进行bean注入  </p></blockquote><pre><code class="language-txt">org.springframework.boot.autoconfigure.EnableAutoConfiguration=\...org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\...</code></pre><h2 id="rabbitmq-使用"><a href="#rabbitmq-使用" class="headerlink" title="rabbitmq 使用"></a>rabbitmq 使用</h2><blockquote><p>&emsp;&emsp;通过RabbitProperties类可以查看spring提供了哪些配置给我们使用，例如下面几个。</p></blockquote><pre><code class="language-yml">spring:  rabbitmq:    host: 192.168.118.134    port: 5672    username: admin    password: 1    virtualHost: /HOST</code></pre><h3 id="交换机队列绑定"><a href="#交换机队列绑定" class="headerlink" title="交换机队列绑定"></a>交换机队列绑定</h3><blockquote><p>我们知道rabbitmq自动注入时候会自动注入个amqpAdmin()类 该类同时实现了InitializingBean 所以, bean初始化时候会调用afterPropertiesSet()方法 。</p></blockquote><pre><code class="language-java">public class RabbitAdmin implements AmqpAdmin, ApplicationContextAware, ApplicationEventPublisherAware,BeanNameAware, InitializingBean </code></pre><blockquote><p>查看该方法实现关键点 会在这里向连接工程添加添加监听器，在连接rabbitmq服务时候会调用initialize()</p></blockquote><pre><code class="language-java">final AtomicBoolean initializing = new AtomicBoolean(false);this.connectionFactory.addConnectionListener(connection -&gt; &#123;if (!initializing.compareAndSet(false, true)) &#123;// If we are already initializing, we don&#39;t need to do it again...return;&#125;try &#123;if (this.retryTemplate != null) &#123;this.retryTemplate.execute(c -&gt; &#123;initialize();return null;&#125;);&#125;else &#123;initialize();&#125;&#125;finally &#123;initializing.compareAndSet(true, false);&#125;&#125;);</code></pre><blockquote><p>继续查看 initialize()方法 该方法会从spring bean工厂中获取Exchange Queue Binding 这三个类型各自的集合 并将其在rabbitmq服务上创建 绑定 。</p></blockquote><pre><code class="language-java">public void initialize() &#123;......Collection&lt;Exchange&gt; contextExchanges = new LinkedList&lt;Exchange&gt;(this.applicationContext.getBeansOfType(Exchange.class).values());Collection&lt;Queue&gt; contextQueues = new LinkedList&lt;Queue&gt;(this.applicationContext.getBeansOfType(Queue.class).values());Collection&lt;Binding&gt; contextBindings = new LinkedList&lt;Binding&gt;(this.applicationContext.getBeansOfType(Binding.class).values());processLegacyCollections(contextExchanges, contextQueues, contextBindings);processDeclarables(contextExchanges, contextQueues, contextBindings); .......this.rabbitTemplate.execute(channel -&gt; &#123;declareExchanges(channel, exchanges.toArray(new Exchange[exchanges.size()]));declareQueues(channel, queues.toArray(new Queue[queues.size()]));declareBindings(channel, bindings.toArray(new Binding[bindings.size()]));return null;&#125;);&#125;</code></pre><blockquote><p>这样我们就可以同过@bean的方式 创建交换机 对列 及绑定关系</p></blockquote><pre><code class="language-java">@Configurationpublic class Rabbitconfig &#123;    //交换机    @Bean    public Exchange topicExchange()    &#123;        return  ExchangeBuilder.topicExchange(&quot;Mytopic&quot;).build();    &#125;    //队列     @Bean    public Queue myQueue()&#123;    return   QueueBuilder.durable(&quot;MyQueue&quot;).build();    &#125;    //绑定关系    @Bean    public Binding myBinding() &#123;        return BindingBuilder.bind(myQueue()).to(topicExchange()).with(&quot;&quot;).noargs();    &#125;&#125;</code></pre><h3 id="发送消息"><a href="#发送消息" class="headerlink" title="发送消息"></a>发送消息</h3><blockquote><p>&emsp;&emsp; 发送消息一般使用rabbitTemplate来发送,通过指定交换机，路由key 以及一个消息类实例org.springframework.amqp.core.Message 其中Message实际是一个被封装起来的byte[] body 字节数组。</p></blockquote><pre><code class="language-java">@Autowired    RabbitTemplate rabbitTemplate;/**交换机为Mytopic 路由key为空 发现消息*/public String testsend()&#123;        rabbitTemplate.send(&quot;Mytopic&quot;,&quot;&quot;,new Message((&quot;helloworld&quot;+UUID.randomUUID()).getBytes(),new MessageProperties()));        return &quot;ok&quot;;    &#125;</code></pre><h3 id="接受消息"><a href="#接受消息" class="headerlink" title="接受消息"></a>接受消息</h3><blockquote><p>&emsp;&emsp;接受消息spring提供了@RabbitListener注解 ，该注解可在类和方法上使用， 在方法上使用时 调用该方法处理消息 ，在类上使用是 配合@RabbitHandler 根据MessageConverter转换类型选择处理方法。</p></blockquote><pre><code class="language-java">@RabbitListener(queues=&#123;&quot;MyQueue&quot;&#125;)public class RabbitMqClient &#123;    @RabbitHandler    public void testreceive(Message message)&#123;       System.out.println(&quot;testreceive：&quot;+message.getBody());    &#125;     // @Payload  @Headers 注解可以直接获取消息 和头信息     //头信息 就在 发送时候的MessageProperties中     //private final Map&lt;String, Object&gt; headers = new HashMap&lt;&gt;();    /*@RabbitHandler    public void testreceiveA(@Payload String body, @Headers Map&lt;String,Object&gt; headers)&#123;        System.out.println(&quot;testreceiveA：&quot;+body+&quot;-----&quot;+headers);*/    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> MQ </category>
          
          <category> 消息中间件 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Rabbitmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring初始化的几种方式</title>
      <link href="/2020/04/28/2020-04-28-Spring%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/"/>
      <url>/2020/04/28/2020-04-28-Spring%E5%88%9D%E5%A7%8B%E5%8C%96%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="实现InitializingBean"><a href="#实现InitializingBean" class="headerlink" title="实现InitializingBean"></a>实现InitializingBean</h2><blockquote><p>实现该接口 在bean被加载时调用 afterPropertiesSet()方法</p></blockquote><pre><code class="language-java">public interface InitializingBean &#123;/** * Invoked by the containing &#123;@code BeanFactory&#125; after it has set all bean properties * and satisfied &#123;@link BeanFactoryAware&#125;, &#123;@code ApplicationContextAware&#125; etc. * &lt;p&gt;This method allows the bean instance to perform validation of its overall * configuration and final initialization when all bean properties have been set. * @throws Exception in the event of misconfiguration (such as failure to set an * essential property) or if initialization fails for any other reason */void afterPropertiesSet() throws Exception;&#125;</code></pre><h2 id="实现ApplicationContextInitializer"><a href="#实现ApplicationContextInitializer" class="headerlink" title="实现ApplicationContextInitializer"></a>实现ApplicationContextInitializer</h2><pre><code class="language-java">public interface ApplicationContextInitializer&lt;C extends ConfigurableApplicationContext&gt; &#123;/** * Initialize the given application context. * @param applicationContext the application to configure */void initialize(C applicationContext);&#125;</code></pre><blockquote><p>配合springboot极易使用</p></blockquote><pre><code class="language-java">public static void main(String[] args) &#123;        SpringApplication springApplication = new SpringApplication(APP.class);        springApplication.addInitializers(多个ApplicationContextInitializer的实现 可通过@order排序);        springApplication.run(args);    &#125;public void addInitializers(ApplicationContextInitializer&lt;?&gt;... initializers) &#123;this.initializers.addAll(Arrays.asList(initializers));&#125;   </code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>springboot下redis的使用</title>
      <link href="/2020/04/20/2020-04-20-springboot%E4%B8%8Bredis%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2020/04/20/2020-04-20-springboot%E4%B8%8Bredis%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="启动原理"><a href="#启动原理" class="headerlink" title="启动原理"></a>启动原理</h2><blockquote><p>&emsp;&emsp;首先，我们需要了解对于redis是如何在spring中进行注入的，在springboot启动时, 会加载 MEAT-INF下的spring.factories文件将常用的类注入到spring的beanfactory中，其中就包括redis ，下面是一段该文件的内容，其中的org.springframework.boot.autoconfigure.EnableAutoConfiguration就是关键。</p></blockquote><pre><code class="language-txt">...org.springframework.boot.autoconfigure.EnableAutoConfiguration=\...org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisReactiveAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\...</code></pre><blockquote><p>RedisAutoConfiguration 就是redis自动注入所用的类。该类中将redisTemplate 注入到spring中以供我们使用 ，同时可以通过RedisProperties找到redis在springboot中可以配置的参数有哪些。可以看到 无论是redisTemplate 还是stringRedisTemplate 都需要一个RedisConnectionFactory 而连接工程则是通过@Import({ LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class }) 这个注解 导入的类主动注入redisConnectionFactory的获取的。 ok </p></blockquote><pre><code class="language-java">@Configuration(proxyBeanMethods = false)@ConditionalOnClass(RedisOperations.class)@EnableConfigurationProperties(RedisProperties.class)@Import(&#123; LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class &#125;)public class RedisAutoConfiguration &#123;@Bean@ConditionalOnMissingBean(name = &quot;redisTemplate&quot;)public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory)throws UnknownHostException &#123;RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;();template.setConnectionFactory(redisConnectionFactory);return template;&#125;@Bean@ConditionalOnMissingBeanpublic StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory)throws UnknownHostException &#123;StringRedisTemplate template = new StringRedisTemplate();template.setConnectionFactory(redisConnectionFactory);return template;&#125;&#125;</code></pre><pre><code class="language-java">@Bean@ConditionalOnMissingBean(RedisConnectionFactory.class)public JedisConnectionFactory redisConnectionFactory() throws UnknownHostException &#123;return createJedisConnectionFactory();&#125;private JedisConnectionFactory createJedisConnectionFactory() &#123;JedisClientConfiguration clientConfiguration = getJedisClientConfiguration();if (getSentinelConfig() != null) &#123;return new JedisConnectionFactory(getSentinelConfig(), clientConfiguration);&#125;if (getClusterConfiguration() != null) &#123;return new JedisConnectionFactory(getClusterConfiguration(),clientConfiguration);&#125;return new JedisConnectionFactory(getStandaloneConfig(), clientConfiguration);&#125;</code></pre><hr><h2 id="使用-redisTemplate"><a href="#使用-redisTemplate" class="headerlink" title="使用 -redisTemplate"></a>使用 -redisTemplate</h2><h3 id="redis-字符串类型的应用"><a href="#redis-字符串类型的应用" class="headerlink" title="redis 字符串类型的应用"></a>redis 字符串类型的应用</h3><pre><code class="language-java">    @Autowired    RedisTemplate redisTemplate;        @RequestMapping(value = &quot;/getkey&quot;,method = RequestMethod.GET)    @ResponseBody    public String getkey(@RequestParam String key)&#123;        String val=(String)redisTemplate.boundValueOps(key).get();        return val;    &#125;    @RequestMapping(value = &quot;/setkey/&#123;v&#125;&quot;,method = RequestMethod.POST)    @ResponseBody    public String setkey(@PathVariable String v)&#123;        redisTemplate.boundValueOps(&quot;dd&quot;).set(v);        return &quot;ok&quot;;    &#125;    //设定key val 值 及过期时间 使用lua脚本保证原子性    private static final String lock_lua= &quot;if (redis.call(&#39;SETNX&#39; ,KEYS[1],ARGV[1]) ==1 ) then if (redis.call(&#39;EXPIRE&#39; ,KEYS[1],ARGV[2])==1 ) then return 1 end end  return 0&quot;;    // 获取 key 对应的值 判断是否是自己设定的 是就删除    private static final String unlock_lua=&quot;local getVal = redis.call(&#39;get&#39;, KEYS[1]) if getVal == false then return 1 end if getVal ~= ARGV[1] then return 0 end return redis.call(&#39;del&#39;, KEYS[1])&quot;;    private static final String rdlock=&quot;redis_lock&quot;;    //redis 分布式锁 模拟操作redis共享数据    @RequestMapping(value = &quot;/rdlock/&quot;,method = RequestMethod.POST)    @ResponseBody    public String rdlock() throws InterruptedException &#123;        //模拟被操做的共享数据        redisTemplate.boundValueOps(&quot;count&quot;).set(1);        //向下的计数器 countDown() 向下计数 await()阻塞线程        CountDownLatch countDownLatch = new CountDownLatch(10);        ThreadPoolExecutor threadPool =  new ThreadPoolExecutor(10,10,10,TimeUnit.SECONDS,new LinkedBlockingDeque&lt;&gt;());        long time= 50L;        for(int i=0 ;i&lt;10 ;i++)&#123;            //模拟多个请求操作            threadPool.execute(()-&gt;&#123;                String val = RandomStringUtils.randomAlphanumeric(10)+Thread.currentThread().getId();                //加锁                int count=0;                while(true)&#123;                    boolean islock = (boolean) redisTemplate.execute(new DefaultRedisScript(lock_lua,Boolean.class), Arrays.asList(new String[]&#123;rdlock&#125;),val,new Integer(30));                    System.out.println(Thread.currentThread().getName()+&quot;加锁:&quot;+islock);                    //加锁失败操作                    if(!islock)&#123;                        if(count==50)&#123;                            //todo 50次都没获得锁 。。。 do something 扔MQ里？                        &#125;                        count+=1;                        try &#123;                            Thread.sleep(100);                            continue;                        &#125; catch (InterruptedException e) &#123;                            e.printStackTrace();                        &#125;                    &#125;                    //获得锁就跳出循环                    break;                &#125;                //操作数据                redisTemplate.boundValueOps(&quot;count&quot;).set((int)redisTemplate.boundValueOps(&quot;count&quot;).get()+1);                //解锁                boolean isunlock = (boolean) redisTemplate.execute(new DefaultRedisScript(unlock_lua,Boolean.class), Arrays.asList(new String[]&#123;rdlock&#125;),val);                System.out.println(Thread.currentThread().getName()+&quot;解锁:&quot;+isunlock);                if(isunlock)&#123;                    countDownLatch.countDown();                &#125;                else&#123;                    //todo 解锁失败 do something                &#125;            &#125;);        &#125;        countDownLatch.await();        return String.valueOf(redisTemplate.boundValueOps(&quot;count&quot;).get());    &#125;</code></pre><h3 id="redis-set-集合"><a href="#redis-set-集合" class="headerlink" title="redis set 集合"></a>redis set 集合</h3><blockquote><p>set 就像java的hashset似的使用一个value为空的map作为内部存储 多数情况下会使用他的 交 并 差 三种 例如 好友之间的共同关注内容 或者 推荐可能认识的好友 等等</p></blockquote><pre><code class="language-java"> //set 提供 交集、并集、差集 操作较为常见    @RequestMapping(value = &quot;/setoption&quot;,method = RequestMethod.POST)    @ResponseBody    public Map setoption()&#123;        Map map = new HashMap();        String[] set1 =new String[]&#123;&quot;张三&quot;,&quot;李四&quot;,&quot;王五&quot;,&quot;李白&quot;,&quot;杜甫&quot;&#125;;        String[] set2 =new String[]&#123;&quot;张三&quot;,&quot;李四&quot;,&quot;李白&quot;,&quot;杜甫&quot;,&quot;孟浩然&quot;,&quot;米开朗基罗&quot;&#125;;        //准备测试数据        redisTemplate.opsForSet().add(&quot;set1&quot;,set1);        redisTemplate.opsForSet().add(&quot;set2&quot;,set2);        //判断元素是否存在         boolean isMember=  redisTemplate.opsForSet().isMember(&quot;set1&quot;,&quot;米开朗基罗&quot;);         map.put(&quot;isMember&quot;,isMember);//false 不存在        //交集        Set intersect= redisTemplate.opsForSet().intersect(&quot;set1&quot; ,Arrays.asList(&quot;set2&quot;));        map.put(&quot;intersect&quot;,intersect);//返回set1 和其他set的相交部分        //并集        Set union= redisTemplate.opsForSet().union(&quot;set1&quot; ,Arrays.asList(&quot;set2&quot;));        map.put(&quot;union&quot;,union);//返回set1 和其他set的相并集合        //差集        Set diff= redisTemplate.opsForSet().difference(&quot;set1&quot; ,Arrays.asList(&quot;set2&quot;));        map.put(&quot;diff&quot;,diff);//返回set1 和其他set的差异        return map;    &#125;</code></pre><h3 id="redis-zset-有序集合"><a href="#redis-zset-有序集合" class="headerlink" title="redis zset 有序集合"></a>redis zset 有序集合</h3><blockquote><p>zset 和set类似  只不过是使用score对set进行排序，同时也可用以 并集 交集的计算 会把 计算的结果存放在一个新的集合中以供使用。</p></blockquote><pre><code class="language-java">//有序集合  通过score 进行排序    @PostMapping(&quot;/zsetoption&quot;)    @ResponseBody    public Map zsetoption()&#123;        Map map = new HashMap();        Set&lt;ZSetOperations.TypedTuple&gt; sets= new HashSet&lt;&gt;();        Set&lt;ZSetOperations.TypedTuple&gt; sets1= new HashSet&lt;&gt;();        List&lt;DefaultTypedTuple&gt; list = new ArrayList&lt;&gt;();        list.add(new DefaultTypedTuple(&quot;张三&quot;,10.00));        list.add(new DefaultTypedTuple(&quot;李四&quot;,7.00));        list.add(new DefaultTypedTuple(&quot;王五&quot;,11.00));        list.add(new DefaultTypedTuple(&quot;李白&quot;,15.00));        list.add(new DefaultTypedTuple(&quot;杜甫&quot;,3.00));        list.add(new DefaultTypedTuple(&quot;孟浩然&quot;,2.00));        list.add(new DefaultTypedTuple(&quot;米开朗基罗&quot;,1.00));        sets.addAll(list);        //准备测试数据        redisTemplate.opsForZSet().add(&quot;zset1&quot;,sets);        list.remove(6);        list.add(new DefaultTypedTuple(&quot;卡夫卡&quot;,9.00));        sets.addAll(list);        redisTemplate.opsForZSet().add(&quot;zset2&quot;,sets);        // 获取 7条数据        //start  从0开始        //从小到大        Set range =  redisTemplate.opsForZSet().range(&quot;zset1&quot;,1,7);        map.put(&quot;range&quot;,range);        //从大到小        Set reverseRange =  redisTemplate.opsForZSet().reverseRange(&quot;zset1&quot;,1,7);        map.put(&quot;reverseRange&quot;,reverseRange);        //并集 zset3        redisTemplate.opsForZSet().unionAndStore(&quot;zset1&quot;,Arrays.asList(&quot;zset2&quot;),&quot;zset3&quot;);        Set unionAndStore =redisTemplate.opsForZSet().range(&quot;zset3&quot;,0,10);        map.put(&quot;unionAndStore&quot;,unionAndStore);        //交集 zset4        redisTemplate.opsForZSet().intersectAndStore(&quot;zset1&quot;,Arrays.asList(&quot;zset2&quot;),&quot;zset4&quot;);        Set intersectAndStore =redisTemplate.opsForZSet().range(&quot;zset4&quot;,0,10);        map.put(&quot;intersectAndStore&quot;,intersectAndStore);        return map;    &#125;</code></pre><hr><blockquote><p>除此之外还包括对地理位置的存储等功能 </p></blockquote><ul><li>GEOADD Sicily 13.361389 38.115556 “Palermo” 15.087269 37.502669 “Catania”</li><li>GEOPOS Sicily Palermo Catania 不存在返回nil</li><li>GEODIST Sicily Palermo Catania km （计算两点距离【单位包括 m米  km千米 mi英里 ft 英尺】）</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>MessageDigest类</title>
      <link href="/2020/03/08/2020-03-08-MessageDigest%E7%B1%BB/"/>
      <url>/2020/03/08/2020-03-08-MessageDigest%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="MessageDigest"><a href="#MessageDigest" class="headerlink" title="MessageDigest"></a>MessageDigest</h2><ul><li>可用于为文件生成sha1 md5 等校验信息，对文件进行文件完整性校验</li></ul><pre><code class="language-java">//获取MessageDigest通过getInstanceMessageDigest messageDigest = MessageDigest.getInstance(&quot;SHA1&quot;);File f = new File(&quot;c:\\install.log&quot;);           if(!f.isFile())&#123;return;&#125;           FileInputStream Fis= new FileInputStream(f);           //此处借助DigestInputStream           DigestInputStream digestInputStream = new DigestInputStream(Fis,messageDigest);           //为文件生成加密信息的字节数组           byte[] res =digestInputStream.getMessageDigest().digest();           //转换16进制           System.out.println(byteArrayToHex(res));</code></pre><pre><code class="language-java">public static String byteArrayToHex(byte[] byteArray) &#123;        // 首先初始化一个字符数组，用来存放每个16进制字符        char[] hexDigits = &#123;&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;&#125;;        // new一个字符数组，这个就是用来组成结果字符串的（解释一下：一个byte是八位二进制，也就是2位十六进制字符（2的8次方等于16的2次方））        char[] resultCharArray = new char[byteArray.length * 2];        // 遍历字节数组，通过位运算（位运算效率高），转换成字符放到字符数组中去        int index = 0;        for (byte b : byteArray) &#123;            resultCharArray[index++] = hexDigits[b &gt;&gt;&gt; 4 &amp; 0xf];            resultCharArray[index++] = hexDigits[b &amp; 0xf];        &#125;        // 字符数组组合成字符串返回        return new String(resultCharArray);    &#125;</code></pre><h2 id="DigestInputStream"><a href="#DigestInputStream" class="headerlink" title="DigestInputStream"></a>DigestInputStream</h2><blockquote><p>这里使用的DigestInputStream 通过一个输入流和MessageDigest 获取实例 并通过getMessageDigest 获取具体的MessageDigest 使用MessageDigest 的 digest()得到加密的字节信息</p></blockquote><pre><code class="language-java">public DigestInputStream(InputStream stream, MessageDigest digest) &#123;        super(stream);        setMessageDigest(digest);    &#125;public MessageDigest getMessageDigest() &#123;        return digest;    &#125;</code></pre><h2 id="digest方法"><a href="#digest方法" class="headerlink" title="digest方法"></a>digest方法</h2><pre><code class="language-java">public byte[] digest() &#123;        /* Resetting is the responsibility of implementors. */        //调用了抽象类的engineDigest方法        byte[] result = engineDigest();        state = INITIAL;        return result;    &#125;</code></pre><blockquote><p>抽象类的具体实现则是在Security.getImpl(…)方法获得sun.security.provider.SHA</p></blockquote><pre><code class="language-java">public static MessageDigest getInstance(String algorithm)    throws NoSuchAlgorithmException &#123;        try &#123;          ...            Object[] objs = Security.getImpl(algorithm, &quot;MessageDigest&quot;,(String)null);            if (objs[0] instanceof MessageDigest) &#123;                md = (MessageDigest)objs[0];            &#125; else &#123;                md = new Delegate((MessageDigestSpi)objs[0], algorithm);            &#125;            ...    &#125;</code></pre><blockquote><p>engineDigest具体调用为sun.security.provider.SHA 的父类sun.security.provider.DigestBase 中的engineDigest</p></blockquote><pre><code class="language-java">abstract class DigestBase extends MessageDigestSpi implements Cloneable &#123;    ...    protected final byte[] engineDigest() &#123;            byte[] var1 = new byte[this.digestLength];            try &#123;                this.engineDigest(var1, 0, var1.length);                return var1;            &#125; catch (DigestException var3) &#123;                throw (ProviderException)(new ProviderException(&quot;Internal error&quot;)).initCause(var3);            &#125;        &#125;    ...&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MessageDigest </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go语言基础语法</title>
      <link href="/2020/03/01/2020-03-01-Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"/>
      <url>/2020/03/01/2020-03-01-Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>详见地址:<a href="https://github.com/zhangzt123/Golearn">https://github.com/zhangzt123/Golearn</a></p>]]></content>
      
      
      <categories>
          
          <category> Go语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AbstractApplicationContext</title>
      <link href="/2019/11/27/2020-02-29-AbstractApplicationContext/"/>
      <url>/2019/11/27/2020-02-29-AbstractApplicationContext/</url>
      
        <content type="html"><![CDATA[<h2 id="AbstractApplicationContext的refresh（）方法"><a href="#AbstractApplicationContext的refresh（）方法" class="headerlink" title="AbstractApplicationContext的refresh（）方法"></a><strong>AbstractApplicationContext的refresh（）方法</strong></h2><blockquote><p>AbstractApplicationContext 继承DefaultResourceLoader ， 实现了ConfigurableApplicationContext， ConfigurableApplicationContext继承了ApplicationContext, Lifecycle, Closeable 接口。</p></blockquote><img src="/.io//11/27/2020-02-29-AbstractApplicationContext/AbstractApplicationContext_uml.png" class title="AbstractApplicationContext_uml.png AbstractApplicationContext_uml.png"><pre><code class="language-java">@Overridepublic void refresh() throws BeansException, IllegalStateException &#123;synchronized (this.startupShutdownMonitor) &#123;// Prepare this context for refreshing.            //初始化PropertySources 验证配置 validateRequiredPropertiesprepareRefresh();// Tell the subclass to refresh the internal bean factory.ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();// Prepare the bean factory for use in this context.prepareBeanFactory(beanFactory);try &#123;// Allows post-processing of the bean factory in context subclasses.postProcessBeanFactory(beanFactory);// Invoke factory processors registered as beans in the context.invokeBeanFactoryPostProcessors(beanFactory);// Register bean processors that intercept bean creation.registerBeanPostProcessors(beanFactory);// Initialize message source for this context.initMessageSource();// Initialize event multicaster for this context.initApplicationEventMulticaster();// Initialize other special beans in specific context subclasses.onRefresh();// Check for listener beans and register them.registerListeners();// Instantiate all remaining (non-lazy-init) singletons.finishBeanFactoryInitialization(beanFactory);// Last step: publish corresponding event.finishRefresh();&#125;catch (BeansException ex) &#123;if (logger.isWarnEnabled()) &#123;logger.warn(&quot;Exception encountered during context initialization - &quot; +&quot;cancelling refresh attempt: &quot; + ex);&#125;// Destroy already created singletons to avoid dangling resources.destroyBeans();// Reset &#39;active&#39; flag.cancelRefresh(ex);// Propagate exception to caller.throw ex;&#125;finally &#123;// Reset common introspection caches in Spring&#39;s core, since we// might not ever need metadata for singleton beans anymore...resetCommonCaches();&#125;&#125;&#125;protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123;//bean工厂的创建 bean的加载 以及 一些bean处理器的注册refreshBeanFactory();        //getBeanFactory 由子类实现 例如 xmlwebapplicationcontext 的createBeanFactory方法 会创建默认DefaultListableBeanFactory使用ConfigurableListableBeanFactory beanFactory = getBeanFactory();if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory);&#125;return beanFactory;&#125;</code></pre><blockquote><p>此处以xmlwebapplicationcontext为例 刷新bean工厂方法如下</p></blockquote><pre><code class="language-java">protected final void refreshBeanFactory() throws BeansException &#123;if (hasBeanFactory()) &#123;destroyBeans();closeBeanFactory();&#125;try &#123;DefaultListableBeanFactory beanFactory = createBeanFactory();beanFactory.setSerializationId(getId());customizeBeanFactory(beanFactory);//关键调用  所有的bean工厂都会调用对应的applicationcontext的loadBeanDefinitions方法 加载BeanDefinition （不实例化只加载） 注册bean工厂处理器loadBeanDefinitions(beanFactory);synchronized (this.beanFactoryMonitor) &#123;this.beanFactory = beanFactory;&#125;&#125;catch (IOException ex) &#123;throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex);&#125;&#125;protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123;// Tell the internal bean factory to use the context&#39;s class loader etc.        //设置类加载器 为当前applacationcontext的类加载器 如果没有则使用当前线程的类加载器beanFactory.setBeanClassLoader(getClassLoader());        //bean工厂中注册Spring EL 解析模块         /*        *&lt;bean name =&quot;test&quot;  ... &gt;        *&lt;property name=&quot;test&quot; value=&quot;#&#123;test&#125;&quot;&gt;&lt;/property&gt;        *&lt;bean/&gt;        */beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader()));        //注册一个资源管理的注册器 applicationcontext 本身实现了ResourceLoader beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment()));// Configure the bean factory with context callbacks.beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this));        //忽略依赖注入的接口beanFactory.ignoreDependencyInterface(EnvironmentAware.class);beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class);beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class);beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class);beanFactory.ignoreDependencyInterface(MessageSourceAware.class);beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);// BeanFactory interface not registered as resolvable type in a plain factory.// MessageSource registered (and found for autowiring) as a bean.        //注册依赖beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);beanFactory.registerResolvableDependency(ResourceLoader.class, this);beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this);beanFactory.registerResolvableDependency(ApplicationContext.class, this);// Register early post-processor for detecting inner beans as ApplicationListeners.        //注册一个bean处理的监听器的检查器beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this));// Detect a LoadTimeWeaver and prepare for weaving, if found.        //LOAD_TIME_WEAVER_BEAN_NAME=loadTimeWeaverif (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123;beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));// Set a temporary ClassLoader for type matching.beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));&#125;// Register default environment beans. ENVIRONMENT_BEAN_NAME=environmentif (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123;beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment());&#125;        //SYSTEM_PROPERTIES_BEAN_NAME=systemPropertiesif (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123;beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties());&#125;        //SYSTEM_ENVIRONMENT_BEAN_NAME =systemEnvironmentif (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123;beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment());&#125;&#125;</code></pre><blockquote><p>这里注册了这么多到底是干啥用呢? 别急，继续往下看。</p></blockquote><pre><code class="language-java">protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123;PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors());// Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime// (e.g. through an @Bean method registered by ConfigurationClassPostProcessor)if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123;beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));&#125;&#125;</code></pre><blockquote><p>调用invokeBeanFactoryPostProcessors方法， 这段代码中的重点在于sortPostProcessors，invokeBeanDefinitionRegistryPostProcessors，invokeBeanFactoryPostProcessors 这三个方法，sortPostProcessors 对要执行的解析器根据依赖进行排序，invokeBeanDefinitionRegistryPostProcessors则是会调用解析器的postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry)方法，invokeBeanFactoryPostProcessors 会调用postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory)方法。</p></blockquote><pre><code class="language-java">public static void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123;// Invoke BeanDefinitionRegistryPostProcessors first, if any.Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;();if (beanFactory instanceof BeanDefinitionRegistry) &#123;BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new ArrayList&lt;&gt;();List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new ArrayList&lt;&gt;();for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123;if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123;BeanDefinitionRegistryPostProcessor registryProcessor =(BeanDefinitionRegistryPostProcessor) postProcessor;registryProcessor.postProcessBeanDefinitionRegistry(registry);registryProcessors.add(registryProcessor);&#125;else &#123;regularPostProcessors.add(postProcessor);&#125;&#125;// Do not initialize FactoryBeans here: We need to leave all regular beans// uninitialized to let the bean factory post-processors apply to them!// Separate between BeanDefinitionRegistryPostProcessors that implement// PriorityOrdered, Ordered, and the rest.List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;();// First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered.String[] postProcessorNames =beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);for (String ppName : postProcessorNames) &#123;if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));processedBeans.add(ppName);&#125;&#125;sortPostProcessors(currentRegistryProcessors, beanFactory);registryProcessors.addAll(currentRegistryProcessors);invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);currentRegistryProcessors.clear();// Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered.postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);for (String ppName : postProcessorNames) &#123;if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));processedBeans.add(ppName);&#125;&#125;sortPostProcessors(currentRegistryProcessors, beanFactory);registryProcessors.addAll(currentRegistryProcessors);invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);currentRegistryProcessors.clear();// Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear.boolean reiterate = true;while (reiterate) &#123;reiterate = false;postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);for (String ppName : postProcessorNames) &#123;if (!processedBeans.contains(ppName)) &#123;currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));processedBeans.add(ppName);reiterate = true;&#125;&#125;sortPostProcessors(currentRegistryProcessors, beanFactory);registryProcessors.addAll(currentRegistryProcessors);invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);currentRegistryProcessors.clear();&#125;// Now, invoke the postProcessBeanFactory callback of all processors handled so far.invokeBeanFactoryPostProcessors(registryProcessors, beanFactory);invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory);&#125;else &#123;// Invoke factory processors registered with the context instance.invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory);&#125;// Do not initialize FactoryBeans here: We need to leave all regular beans// uninitialized to let the bean factory post-processors apply to them!String[] postProcessorNames =beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false);// Separate between BeanFactoryPostProcessors that implement PriorityOrdered,// Ordered, and the rest.List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;();List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;();List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;();for (String ppName : postProcessorNames) &#123;if (processedBeans.contains(ppName)) &#123;// skip - already processed in first phase above&#125;else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class));&#125;else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;orderedPostProcessorNames.add(ppName);&#125;else &#123;nonOrderedPostProcessorNames.add(ppName);&#125;&#125;// First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered.sortPostProcessors(priorityOrderedPostProcessors, beanFactory);invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory);// Next, invoke the BeanFactoryPostProcessors that implement Ordered.List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;();for (String postProcessorName : orderedPostProcessorNames) &#123;orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));&#125;sortPostProcessors(orderedPostProcessors, beanFactory);invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory);// Finally, invoke all other BeanFactoryPostProcessors.List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;();for (String postProcessorName : nonOrderedPostProcessorNames) &#123;nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));&#125;invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory);// Clear cached merged bean definitions since the post-processors might have// modified the original metadata, e.g. replacing placeholders in values...beanFactory.clearMetadataCache();&#125;protected void initMessageSource() &#123;//获取bean工厂 例如DefaultListableBeanFactoryConfigurableListableBeanFactory beanFactory = getBeanFactory();//如果包含messageSource bean 则设置他的符消息源为当前父上下文的消息源if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) &#123;this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class);// Make MessageSource aware of parent MessageSource.if (this.parent != null &amp;&amp; this.messageSource instanceof HierarchicalMessageSource) &#123;HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource;if (hms.getParentMessageSource() == null) &#123;// Only set parent context as parent MessageSource if no parent MessageSource// registered already.hms.setParentMessageSource(getInternalParentMessageSource());&#125;&#125;if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Using MessageSource [&quot; + this.messageSource + &quot;]&quot;);&#125;&#125;else &#123;// Use empty MessageSource to be able to accept getMessage calls.//创建一个代理消息源 注册他父消息源 并注册messageSource beanDelegatingMessageSource dms = new DelegatingMessageSource();dms.setParentMessageSource(getInternalParentMessageSource());this.messageSource = dms;beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource);if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Unable to locate MessageSource with name &#39;&quot; + MESSAGE_SOURCE_BEAN_NAME +&quot;&#39;: using default [&quot; + this.messageSource + &quot;]&quot;);&#125;&#125;&#125;protected void initApplicationEventMulticaster() &#123;ConfigurableListableBeanFactory beanFactory = getBeanFactory();//初始化applicationEventMulticaster 事件发布相关 默认是SimpleApplicationEventMulticasterif (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123;this.applicationEventMulticaster =beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class);if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Using ApplicationEventMulticaster [&quot; + this.applicationEventMulticaster + &quot;]&quot;);&#125;&#125;else &#123;this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory);beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster);if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Unable to locate ApplicationEventMulticaster with name &#39;&quot; +APPLICATION_EVENT_MULTICASTER_BEAN_NAME +&quot;&#39;: using default [&quot; + this.applicationEventMulticaster + &quot;]&quot;);&#125;&#125;&#125;</code></pre><blockquote><p>onRefresh() 方法由子类实现 此处以xmlwebapplicationcontext为例。此方法在他的父类AbstractRefreshableWebApplicationContext中实现，AbstractRefreshableWebApplicationContext继承自abstractapplicationcontext. 他所做的是初始化主题资源，你问主题是啥， 想想你使用的手机，上面不是有主题切换么 ，意思是一个意思 ，道理是一个道理 ，但他们可不是一个东西。主题的话包括themeSource，themeResolver，themeChangeInterceptor三种。此处不做过多概述。</p></blockquote><pre><code class="language-java">@Overrideprotected void onRefresh() &#123;this.themeSource = UiApplicationContextUtils.initThemeSource(this);&#125;注册监听器protected void registerListeners() &#123;// Register statically specified listeners first.//getApplicationEventMulticaster 就是上面初始化是事件发布相关的类 比如SimpleApplicationEventMulticasterfor (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123;getApplicationEventMulticaster().addApplicationListener(listener);&#125;// Do not initialize FactoryBeans here: We need to leave all regular beans// uninitialized to let post-processors apply to them!// 遍历所有监听器类型的bean名字 注册给事件发布相关的类String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false);for (String listenerBeanName : listenerBeanNames) &#123;getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName);&#125;// Publish early application events now that we finally have a multicaster...Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents;this.earlyApplicationEvents = null;if (earlyEventsToProcess != null) &#123;for (ApplicationEvent earlyEvent : earlyEventsToProcess) &#123;getApplicationEventMulticaster().multicastEvent(earlyEvent);&#125;&#125;&#125;protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123;// Initialize conversion service for this context.// 如果有conversionService这个bean 并且是一个ConversionService.class类型的则设置bean工厂的conversionServiceif (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp;beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123;beanFactory.setConversionService(beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class));&#125;// Register a default embedded value resolver if no bean post-processor// (such as a PropertyPlaceholderConfigurer bean) registered any before:// at this point, primarily for resolution in annotation attribute values.//添加一个解析表达式值得解析器if (!beanFactory.hasEmbeddedValueResolver()) &#123;beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal));&#125;// Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early.//LoadTimeWeaver被Spring用来在将类加载到Java虚拟机(JVM)中时动态地转换类String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false);for (String weaverAwareName : weaverAwareNames) &#123;getBean(weaverAwareName);&#125;// Stop using the temporary ClassLoader for type matching.beanFactory.setTempClassLoader(null);// Allow for caching all bean definition metadata, not expecting further changes.//bean名字转换为数组？为啥 比较快？beanFactory.freezeConfiguration();// Instantiate all remaining (non-lazy-init) singletons.//实例化剩下的beanbeanFactory.preInstantiateSingletons();&#125;protected void finishRefresh() &#123;// Clear context-level resource caches (such as ASM metadata from scanning).clearResourceCaches();// Initialize lifecycle processor for this context.initLifecycleProcessor();// Propagate refresh to lifecycle processor first.//调用默认DefaultLifecycleProcessor解析器的onRefresh//DefaultLifecycleProcessor 实现 LifecycleProcessor  关键方法是onRefresh ，onClosegetLifecycleProcessor().onRefresh();// Publish the final event 将自己包装进成事件对象.添加到事件的集合中（这个操作就是发布事件 有监听器触发事件）publishEvent(new ContextRefreshedEvent(this));// Participate in LiveBeansView MBean, if active. JMX相关Mbean的注册（我也不知道这啥啊）LiveBeansView.registerApplicationContext(this);&#125;//初始化生命周期的beanprotected void initLifecycleProcessor() &#123;ConfigurableListableBeanFactory beanFactory = getBeanFactory();if (beanFactory.containsLocalBean(LIFECYCLE_PROCESSOR_BEAN_NAME)) &#123;this.lifecycleProcessor =beanFactory.getBean(LIFECYCLE_PROCESSOR_BEAN_NAME, LifecycleProcessor.class);if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Using LifecycleProcessor [&quot; + this.lifecycleProcessor + &quot;]&quot;);&#125;&#125;else &#123;DefaultLifecycleProcessor defaultProcessor = new DefaultLifecycleProcessor();defaultProcessor.setBeanFactory(beanFactory);this.lifecycleProcessor = defaultProcessor;beanFactory.registerSingleton(LIFECYCLE_PROCESSOR_BEAN_NAME, this.lifecycleProcessor);if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Unable to locate LifecycleProcessor with name &#39;&quot; +LIFECYCLE_PROCESSOR_BEAN_NAME +&quot;&#39;: using default [&quot; + this.lifecycleProcessor + &quot;]&quot;);&#125;&#125;&#125;protected void publishEvent(Object event, @Nullable ResolvableType eventType) &#123;Assert.notNull(event, &quot;Event must not be null&quot;);if (logger.isTraceEnabled()) &#123;logger.trace(&quot;Publishing event in &quot; + getDisplayName() + &quot;: &quot; + event);&#125;// Decorate event as an ApplicationEvent if necessaryApplicationEvent applicationEvent;if (event instanceof ApplicationEvent) &#123;applicationEvent = (ApplicationEvent) event;&#125;else &#123;applicationEvent = new PayloadApplicationEvent&lt;&gt;(this, event);if (eventType == null) &#123;eventType = ((PayloadApplicationEvent) applicationEvent).getResolvableType();&#125;&#125;// Multicast right now if possible - or lazily once the multicaster is initializedif (this.earlyApplicationEvents != null) &#123;this.earlyApplicationEvents.add(applicationEvent);&#125;else &#123;getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType);&#125;// Publish event via parent context as well...if (this.parent != null) &#123;if (this.parent instanceof AbstractApplicationContext) &#123;((AbstractApplicationContext) this.parent).publishEvent(event, eventType);&#125;else &#123;this.parent.publishEvent(event);&#125;&#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringDispatcherServlet</title>
      <link href="/2019/11/21/2020-02-29-SpringDispatcherServlet/"/>
      <url>/2019/11/21/2020-02-29-SpringDispatcherServlet/</url>
      
        <content type="html"><![CDATA[<h2 id="DispatcherServlet初始化"><a href="#DispatcherServlet初始化" class="headerlink" title="DispatcherServlet初始化"></a><strong>DispatcherServlet初始化</strong></h2><blockquote><p>说起springmvc我们自然会第一个想到，配置一个springmvc的web项目肯定是要先在web.xml中配置一个叫dispatcherServlet的servlet，servlet此处不做过多讨论，只是我们知道，servlet在web项目启动时会先调用他的init方法，我们顺着这个思路往下看，spring的这个dispatcherservlet他就是一个servlet。以下是他在spring中的uml图。他继承自FrameworkServlet，FrameworkServlet继承自HttpServletBean，再向上便是继承自HttpServlet，那他作为一个servlet自然会在项目启动时调用init方法，我们找到他的init() 方法。看一下他是如何一步一步初始化spring的。</p></blockquote><img src="/.io//11/21/2020-02-29-SpringDispatcherServlet/spring_dispatcherservlet_uml.png" class title="spring_dispatcherservlet_uml spring_dispatcherservlet_uml.png"><blockquote><p>init方法在HttpServletBean中我们，首先他在初始化是先加载web.xml中 dispatcherservlet所在servlet对应的所有的标签的参数，整个spring初始化的init中initServletBean（）最为关键。</p></blockquote><pre><code class="language-java">public final void init() throws ServletException &#123;if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Initializing servlet &#39;&quot; + getServletName() + &quot;&#39;&quot;);&#125;// Set bean properties from init parameters.PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties);if (!pvs.isEmpty()) &#123;try &#123;                //创建一个bean包装类BeanWrapperImplBeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this);                //用当前上下文创建ResourceLoader资源加载器ResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext());                //bw中注册一个用StandardServletEnvironment 创建的ResourceEditorbw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment()));                //初始化bw用用户自己实现initBeanWrapper(bw);bw.setPropertyValues(pvs, true);&#125;catch (BeansException ex) &#123;if (logger.isErrorEnabled()) &#123;logger.error(&quot;Failed to set bean properties on servlet &#39;&quot; + getServletName() + &quot;&#39;&quot;, ex);&#125;throw ex;&#125;&#125;// Let subclasses do whatever initialization they like.initServletBean();if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Servlet &#39;&quot; + getServletName() + &quot;&#39; configured successfully&quot;);&#125;&#125;private static class ServletConfigPropertyValues extends MutablePropertyValues &#123;public ServletConfigPropertyValues(ServletConfig config, Set&lt;String&gt; requiredProperties)throws ServletException &#123;Set&lt;String&gt; missingProps = (!CollectionUtils.isEmpty(requiredProperties) ?new HashSet&lt;&gt;(requiredProperties) : null);            //从servlet所对应的servletconfig中获取所有的&lt;init-param&gt;标签的内容 并将其包装成PropertyValue添加到List&lt;PropertyValue&gt; propertyValueList中Enumeration&lt;String&gt; paramNames = config.getInitParameterNames();while (paramNames.hasMoreElements()) &#123;String property = paramNames.nextElement();Object value = config.getInitParameter(property);addPropertyValue(new PropertyValue(property, value));if (missingProps != null) &#123;missingProps.remove(property);&#125;&#125;// Fail if we are still missing properties.if (!CollectionUtils.isEmpty(missingProps)) &#123;throw new ServletException(&quot;Initialization from ServletConfig for servlet &#39;&quot; + config.getServletName() +&quot;&#39; failed; the following required properties were missing: &quot; +StringUtils.collectionToDelimitedString(missingProps, &quot;, &quot;));&#125;&#125;&#125;</code></pre><blockquote><p>此处关键在于初始化webApplicationContext 以下我们看下初始化的流程。</p></blockquote><pre><code class="language-java">@Overrideprotected final void initServletBean() throws ServletException &#123;getServletContext().log(&quot;Initializing Spring FrameworkServlet &#39;&quot; + getServletName() + &quot;&#39;&quot;);if (logger.isInfoEnabled()) &#123;logger.info(&quot;FrameworkServlet &#39;&quot; + getServletName() + &quot;&#39;: initialization started&quot;);&#125;long startTime = System.currentTimeMillis();try &#123;this.webApplicationContext = initWebApplicationContext();initFrameworkServlet();&#125;catch (ServletException | RuntimeException ex) &#123;logger.error(&quot;Context initialization failed&quot;, ex);throw ex;&#125;if (logger.isInfoEnabled()) &#123;long elapsedTime = System.currentTimeMillis() - startTime;logger.info(&quot;FrameworkServlet &#39;&quot; + getServletName() + &quot;&#39;: initialization completed in &quot; +elapsedTime + &quot; ms&quot;);&#125;&#125;//////////////////////////////////////////protected WebApplicationContext initWebApplicationContext() &#123;        //从servlet上下文中查找是否有叫做org.springframework.web.context.WebApplicationContext.ROOT的根上下文WebApplicationContext rootContext =WebApplicationContextUtils.getWebApplicationContext(getServletContext());WebApplicationContext wac = null;if (this.webApplicationContext != null) &#123;// A context instance was injected at construction time -&gt; use itwac = this.webApplicationContext;if (wac instanceof ConfigurableWebApplicationContext) &#123;ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac;if (!cwac.isActive()) &#123;// The context has not yet been refreshed -&gt; provide services such as// setting the parent context, setting the application context id, etcif (cwac.getParent() == null) &#123;// The context instance was injected without an explicit parent -&gt; set// the root application context (if any; may be null) as the parentcwac.setParent(rootContext);&#125;configureAndRefreshWebApplicationContext(cwac);&#125;&#125;&#125;if (wac == null) &#123;// No context instance was injected at construction time -&gt; see if one// has been registered in the servlet context. If one exists, it is assumed// that the parent context (if any) has already been set and that the// user has performed any initialization such as setting the context idwac = findWebApplicationContext();&#125;if (wac == null) &#123;// No context instance is defined for this servlet -&gt; create a local onewac = createWebApplicationContext(rootContext);&#125;if (!this.refreshEventReceived) &#123;// Either the context is not a ConfigurableApplicationContext with refresh// support or the context injected at construction time had already been// refreshed -&gt; trigger initial onRefresh manually here.synchronized (this.onRefreshMonitor) &#123;onRefresh(wac);&#125;&#125;if (this.publishContext) &#123;// Publish the context as a servlet context attribute.String attrName = getServletContextAttributeName();getServletContext().setAttribute(attrName, wac);if (this.logger.isDebugEnabled()) &#123;this.logger.debug(&quot;Published WebApplicationContext of servlet &#39;&quot; + getServletName() +&quot;&#39; as ServletContext attribute with name [&quot; + attrName + &quot;]&quot;);&#125;&#125;return wac;&#125;protected WebApplicationContext createWebApplicationContext(@Nullable ApplicationContext parent) &#123;//DEFAULT_CONTEXT_CLASS XmlWebApplicationContext.classClass&lt;?&gt; contextClass = getContextClass();if (this.logger.isDebugEnabled()) &#123;this.logger.debug(&quot;Servlet with name &#39;&quot; + getServletName() +&quot;&#39; will try to create custom WebApplicationContext context of class &#39;&quot; +contextClass.getName() + &quot;&#39;&quot; + &quot;, using parent context [&quot; + parent + &quot;]&quot;);&#125;//判断是不是他的继承类或实现类if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) &#123;throw new ApplicationContextException(&quot;Fatal initialization error in servlet with name &#39;&quot; + getServletName() +&quot;&#39;: custom WebApplicationContext class [&quot; + contextClass.getName() +&quot;] is not of type ConfigurableWebApplicationContext&quot;);&#125;//反射实例化XmlWebApplicationContextConfigurableWebApplicationContext wac =(ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);//StandardServletEnvironmentwac.setEnvironment(getEnvironment());//父上下文wac.setParent(parent);String configLocation = getContextConfigLocation();if (configLocation != null) &#123;wac.setConfigLocation(configLocation);&#125;// 初始化关键方法configureAndRefreshWebApplicationContext(wac);return wac;&#125;protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac) &#123;if (ObjectUtils.identityToString(wac).equals(wac.getId())) &#123;// The application context id is still set to its original default value// -&gt; assign a more useful id based on available informationif (this.contextId != null) &#123;wac.setId(this.contextId);&#125;else &#123;// Generate default id...wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX +ObjectUtils.getDisplayString(getServletContext().getContextPath()) + &#39;/&#39; + getServletName());&#125;&#125;wac.setServletContext(getServletContext());wac.setServletConfig(getServletConfig());wac.setNamespace(getNamespace());//添加监听器 参考事件监听设计模式wac.addApplicationListener(new SourceFilteringListener(wac, new ContextRefreshListener()));// The wac environment&#39;s #initPropertySources will be called in any case when the context// is refreshed; do it eagerly here to ensure servlet property sources are in place for// use in any post-processing or initialization that occurs below prior to #refreshConfigurableEnvironment env = wac.getEnvironment();//XmlWebApplicationContext 的环境 空的话默认创建一个 StandardEnvironment 环境//StandardEnvironment 实现是ConfigurableEnvironment接口//eg：StandardServletEnvironment 替换 PropertySource为ServletPropertySourceif (env instanceof ConfigurableWebEnvironment) &#123;((ConfigurableWebEnvironment) env).initPropertySources(getServletContext(), getServletConfig());&#125;postProcessWebApplicationContext(wac);//获取当前servlet上下文 的init-param 的globalInitializerClasses//初始化 添加 ApplicationContextInitializer//遍历调用initialize()初始化方法applyInitializers(wac);//* 刷新上下文 调用abstractapplicationcontext中的refreshwac.refresh();&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>zookeeper集群的安装配置及使用</title>
      <link href="/2019/11/11/2020-02-29-zookeeper%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
      <url>/2019/11/11/2020-02-29-zookeeper%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="zookeeper集群安装与配置"><a href="#zookeeper集群安装与配置" class="headerlink" title="zookeeper集群安装与配置"></a><strong>zookeeper集群安装与配置</strong></h2><blockquote><p>1.下载稳定版本的zookeeper( 下载地址:<a href="https://github.com/apache/zookeeper/releases)%E3%80%82">https://github.com/apache/zookeeper/releases)。</a><br>2.将下载好的zookeeper传到linux上（这里使用centos7）。tar zxfv zookeeper-3.4.14.tar.gz -C &#x2F;usr&#x2F;local&#x2F; 解压到指定位置 （这里使用&#x2F;usr&#x2F;local&#x2F;）。<br>3.重命名为zookeeper mv zookeeper-3.4.14 zookeeper<br>4.取三台机器分别为192.168.118.131,192.168.118.132,192.168.118.133我们看到三台机器解压好的zookeeper目录如下</p></blockquote><img src="/.io//11/11/2020-02-29-zookeeper%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/zookeeper1.png" class title="zookeeper1.png zookeeper1.png"><blockquote><p>我们打开conf可以 这个目录一般为zookeeper的配置文件目录。cp<br>把 zoo_sample.cfg 复制一份重命名为zoo.cfg ,zoo.cfg就是我们需要的配置文件</p></blockquote><pre><code class="language-cmd">$ cd conf &amp;&amp; lsconfiguration.xsl  log4j.properties  zoo.cfg </code></pre><pre><code> zoo_sample.cfg# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.数据目录dataDir=/usr/local/zookeeper/data##### 日志dataLogDir=/usr/local/zookeeper/log# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1# 设置集群相关信息server.1=192.168.118.131:2888:3888server.2=192.168.118.132:2888:3888server.3=192.168.118.133:2888:3888</code></pre><blockquote><p>5.在每台机器的数据目录下创建一个名为myid的文件，内容为表示此机器的标识。 三台机器修改完成后 使用 zkServer.sh start 启动</p></blockquote><pre><code>[root@192 data]# lsmyid[root@192 data]# vim myid1</code></pre><blockquote><p>6.通过zkServer.sh status 我们可以看到三台机器的状态 ，有一台为<br>leader 2台为 follower</p></blockquote><img src="/.io//11/11/2020-02-29-zookeeper%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/zookeeper2.png" class title="zookeeper2.png zookeeper2.png"><blockquote><p>7.连接zk zkCli.sh -h 我们看到 我们通过ZooKeeper -server host:port cmd args 方式可以连接到zk中。我们可以 ls命令 看到部分dubbo的数据。</p></blockquote><pre><code>#zkCli.sh -server 192.168.118.131:2181 [zk: 192.168.118.131:2181(CONNECTED) 17] ls /dubbo[metadata, org.mydubbo.api.DubboApi, org.ztzhang.uumsapi.TokenService, org.dubboapi.DubboApi]</code></pre><h2 id="docker-集群部署"><a href="#docker-集群部署" class="headerlink" title="docker 集群部署"></a>docker 集群部署</h2><blockquote><p>首先创建挂载数据目录 日志目录 并在数据目录下创建myid文件并写入对应的id 然后编写配置文件如下 server.{myid的编号}&#x3D;ip&#x2F;主机名:通信端口(2888):选举端口(3888) 并挂载docker目录 然后分别启动多个容器</p></blockquote><pre><code class="language-conf">dataDir=/datadataLogDir=/datalog#服务器之间或客户端与服务器之间维持心跳的时间间隔 毫秒tickTime=2000#初始化时Leader 和 Follower 心跳间隔数 5*2000initLimit=10#Leader 和 Follower 之间同步通信的超时时间 2*2000syncLimit=5clientPort=2181autopurge.snapRetainCount=3autopurge.purgeInterval=0#最大客户端连接数maxClientCnxns=60standaloneEnabled=falseadmin.enableServer=trueserver.1=zk1:2888:3888server.2=zk2:2888:3888server.3=zk3:2888:3888</code></pre><pre><code class="language-shell">docker run -d --rm --name zk1 --hostname=&quot;zk1&quot; -v /home/docker/zk/config/:/conf/ -v /home/docker/zk/data1:/data -v /home/docker/zk/log1:/datalog -p ::2181 -p ::2888 -p ::3888 --network inet  zookeeper:3.9.2\&amp;&amp;\docker run -d --rm --name zk2 --hostname=&quot;zk2&quot; -v /home/docker/zk/config/:/conf/ -v /home/docker/zk/data2:/data -v /home/docker/zk/log2:/datalog -p ::2181 -p ::2888 -p ::3888 --network inet  zookeeper:3.9.2\&amp;&amp;\docker run -d --rm --name zk3 --hostname=&quot;zk3&quot; -v /home/docker/zk/config/:/conf/ -v /home/docker/zk/data3:/data -v /home/docker/zk/log3:/datalog -p ::2181 -p ::2888 -p ::3888 --network inet  zookeeper:3.9.2requireClientAuthScheme = none</code></pre><pre><code class="language-shell">zhangzhitong@zhangzhitong-virtual-machine:/home/docker$ docker ps CONTAINER ID   IMAGE             COMMAND                   CREATED          STATUS          PORTS                                                                                                                                             NAMES5aa9904ee9cb   zookeeper:3.9.2   &quot;/docker-entrypoint.…&quot;   10 seconds ago   Up 8 seconds    8080/tcp, 0.0.0.0:32849-&gt;2181/tcp, :::32849-&gt;2181/tcp, 0.0.0.0:32850-&gt;2888/tcp, :::32850-&gt;2888/tcp, 0.0.0.0:32851-&gt;3888/tcp, :::32851-&gt;3888/tcp   zk3e97146b48c51   zookeeper:3.9.2   &quot;/docker-entrypoint.…&quot;   10 seconds ago   Up 9 seconds    8080/tcp, 0.0.0.0:32846-&gt;2181/tcp, :::32846-&gt;2181/tcp, 0.0.0.0:32847-&gt;2888/tcp, :::32847-&gt;2888/tcp, 0.0.0.0:32848-&gt;3888/tcp, :::32848-&gt;3888/tcp   zk2f04fd5f8a96b   zookeeper:3.9.2   &quot;/docker-entrypoint.…&quot;   11 seconds ago   Up 10 seconds   8080/tcp, 0.0.0.0:32843-&gt;2181/tcp, :::32843-&gt;2181/tcp, 0.0.0.0:32844-&gt;2888/tcp, :::32844-&gt;2888/tcp, 0.0.0.0:32845-&gt;3888/tcp, :::32845-&gt;3888/tcp   zk1zhangzhitong@zhangzhitong-virtual-machine:/home/docker$ docker exec f04fd5f8a96b /apache-zookeeper-3.9.2-bin/bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /conf/zoo.cfgClient port found: 2181. Client address: localhost. Client SSL: false.Mode: followerzhangzhitong@zhangzhitong-virtual-machine:/home/docker$ docker exec 5aa9904ee9cb /apache-zookeeper-3.9.2-bin/bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /conf/zoo.cfgClient port found: 2181. Client address: localhost. Client SSL: false.Mode: followerzhangzhitong@zhangzhitong-virtual-machine:/home/docker$ docker exec e97146b48c51 /apache-zookeeper-3.9.2-bin/bin/zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /conf/zoo.cfgClient port found: 2181. Client address: localhost. Client SSL: false.Mode: leader</code></pre><h2 id="zookeeper数据结构"><a href="#zookeeper数据结构" class="headerlink" title="zookeeper数据结构"></a><strong>zookeeper数据结构</strong></h2><blockquote><p>zk的数据结构类似于文件系统，其节点被称为Znode，其类似于&#x2F;A&#x2F;S&#x2F;D&#x2F;F 这样的路径。zk的每一个znode中都包括节点的数据信息（data），节点的访问权限（ACL），节点的事务版本号等等信息（stat），以及子节点的引用（child），其只适用于少量信息的存储，每个znode数据最大不会超过1Mb， zk的连接为长连接 ，而临时节点则是在连接断开后就会被删除。</p></blockquote><img src="/.io//11/11/2020-02-29-zookeeper%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E4%BD%BF%E7%94%A8/zookeeper3.png" class title="zookeeper3.png zookeeper3.png"><p>docker run -d –restart always –name zk –hostname&#x3D;”zk”  -v &#x2F;home&#x2F;docker&#x2F;zk&#x2F;zk_data:&#x2F;data  -p 2181:2181 -p ::2888 -p ::3888 –network inet  zookeeper:3.9.2</p>]]></content>
      
      
      
        <tags>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker下的gitlib安装及git使用</title>
      <link href="/2019/11/08/2020-02-29-Docker%E4%B8%8B%E7%9A%84gitlib%E5%AE%89%E8%A3%85%E5%8F%8Agit%E4%BD%BF%E7%94%A8/"/>
      <url>/2019/11/08/2020-02-29-Docker%E4%B8%8B%E7%9A%84gitlib%E5%AE%89%E8%A3%85%E5%8F%8Agit%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="Docker下的gitlib安装"><a href="#Docker下的gitlib安装" class="headerlink" title="Docker下的gitlib安装"></a><strong>Docker下的gitlib安装</strong></h2><blockquote><p>Docker使用此处不做介绍 ，请等待docker篇更新 ，详细安装<br><a href="https://docs.gitlab.com/omnibus/docker/">https://docs.gitlab.com/omnibus/docker/</a></p></blockquote><pre><code>1. 从dockerhub上下载docker镜像 docker pull gitlab/gitlab-ce:17.3.1-ce.02. 运行镜像 </code></pre><pre><code class="language-shell">$ docker run -d -p 1443:443 -p 1080:80 -p 1022:22 \--name gitlab \--restart always \--env GITLAB_OMNIBUS_CONFIG=&quot;external_url &#39;http://192.168.0.106/&#39;; gitlab_rails[&#39;lfs_enabled&#39;] = true; gitlab_rails[&#39;gitlab_ssh_host&#39;] = &#39;192.168.0.106&#39;;gitlab_rails[&#39;gitlab_shell_ssh_port&#39;] = 1022;&quot; \-v /home/docker/gitlab/config:/etc/gitlab \-v /home/docker/gitlab/logs:/var/log/gitlab \-v /home/docker/gitlab/data:/var/opt/gitlab \--network inet \gitlab/gitlab-ce:17.3.1-ce.0</code></pre><blockquote><p>我们看这一段参数 –env GITLAB_OMNIBUS_CONFIG&#x3D;”external_url ‘<a href="http://192.168.0.106/">http://192.168.0.106/</a>‘; gitlab_rails[‘lfs_enabled’] &#x3D; true; gitlab_rails[‘gitlab_ssh_host’] &#x3D; ‘192.168.0.106’;gitlab_rails[‘gitlab_shell_ssh_port’] &#x3D; 1022;”<br>为了保证gitlab有固定的url访问 配置了external_url和 gitlab_rails[‘gitlab_ssh_host’] ,gitlab_rails[‘lfs_enabled’] &#x3D; true 表示是否支持GitLab LFS , gitlab_rails[‘gitlab_shell_ssh_port’] &#x3D; 1022;<br>表示修改ssh的端口为2019 由于此处的配置需要每次启动时添加到参数上，所有我们可以把具体的配置在&#x2F;usr&#x2F;local&#x2F;gitlab&#x2F;config&#x2F;gitlab.rb中进行修改 下次启动时将无需填写该参数。更多配置请自行查询。</p></blockquote><blockquote><p>登录后默认用户密码 root 密码 默认密码在安装完成后会在 &#x2F;etc&#x2F;gitlab&#x2F;initial_root_password</p></blockquote><blockquote><p>修改默认中文 在gitlab.rb配置文件中 新增&#x2F;修改 gitlab_rails[‘locale’] &#x3D; ‘zh-Hans’  重启gitlib服务</p></blockquote><h3 id="高可用部署"><a href="#高可用部署" class="headerlink" title="高可用部署"></a>高可用部署</h3><h3 id="迁移数据"><a href="#迁移数据" class="headerlink" title="迁移数据"></a>迁移数据</h3>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> gitlib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ClassPathXmlApplicationContext</title>
      <link href="/2019/11/04/2020-02-29-ClassPathXmlApplicationContext/"/>
      <url>/2019/11/04/2020-02-29-ClassPathXmlApplicationContext/</url>
      
        <content type="html"><![CDATA[<h2 id="Ioc追本溯源"><a href="#Ioc追本溯源" class="headerlink" title="Ioc追本溯源"></a><strong>Ioc追本溯源</strong></h2><blockquote><p>提及spring，必然会提到他的ioc Di ，依赖注入，控制反正，从最原始的new一个对象转变为 当你需要啥spring为你提供这个对象，通过set方法，或者构造器对需要的类进行注入。 现在，spring已经成为java行业内的基准，我们看下面这段程序。通过spring的bean工厂获取testB 用来执行spring的print方法，这也就是spring加载bean最基本的案例。</p></blockquote><pre><code class="language-java">public class TestA &#123;public static void main(String[] args) &#123;BeanFactory beanFactory;beanFactory = new ClassPathXmlApplicationContext(&quot;application.xml&quot;);TestB testB =(TestB) beanFactory.getBean(&quot;testb&quot;);testB.print();&#125;&#125;class TestB &#123;void print()&#123;Optional.of(&quot;暴击10000点伤害&quot;).ifPresent(System.out::println);&#125;&#125;</code></pre><pre><code class="language-xml">&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;&lt;bean   id =&quot;testb&quot; class=&quot;org.learn.test1.TestB&quot; /&gt;&lt;/beans&gt;</code></pre><blockquote><p>一路向上查看ClassPathXmlApplicationContext的继承关系，可以看到ClassPathXmlApplicationContext继承自AbstractApplicationContext 并且实现了ConfigurableApplicationContext，ConfigurableApplicationContext继承自ApplicationContext接口，ApplicationContext继承自BeanFactory，那么，可以认为ClassPathXmlApplicationContext就是一个BeanFactory。接下来继续查看实例化bean工厂的过程。</p></blockquote><pre><code class="language-java">public ClassPathXmlApplicationContext(String configLocation) throws BeansException &#123;this(new String[] &#123;configLocation&#125;, true, null);&#125;/** * Create a new ClassPathXmlApplicationContext with the given parent, * loading the definitions from the given XML files. * @param configLocations array of resource locations 资源文件的数组。 * @param refresh whether to automatically refresh the context, 释放刷新上下文 * loading all bean definitions and creating all singletons.加载全部bean并且创建单例 * Alternatively, call refresh manually after further configuring the context. * @param parent the parent context 父上下文 * @throws BeansException if context creation failed * @see #refresh() */public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, @Nullable ApplicationContext parent)throws BeansException &#123;super(parent);setConfigLocations(configLocations);if (refresh) &#123;            //主要通过refresh()方法来完成初始化的操作refresh();&#125;&#125;/** * Set the config locations for this application context. * &lt;p&gt;If not set, the implementation may use a default as appropriate. */public void setConfigLocations(@Nullable String... locations) &#123;if (locations != null) &#123;Assert.noNullElements(locations, &quot;Config locations must not be null&quot;);this.configLocations = new String[locations.length];            //遍历配置文件数组。for (int i = 0; i &lt; locations.length; i++) &#123;this.configLocations[i] = resolvePath(locations[i]).trim();&#125;&#125;else &#123;this.configLocations = null;&#125;&#125;    /**     *获取或创建一个StandardEnvironment 并获取所有的配置文件     *     */    protected String resolvePath(String path) &#123;return getEnvironment().resolveRequiredPlaceholders(path);&#125;会调用AbstractApplicationContext类中的关键方法refresh()public void refresh() throws BeansException, IllegalStateException &#123;synchronized (this.startupShutdownMonitor) &#123;// Prepare this context for refreshing.// 遍历配置文件添加到spring环境中并校验配置文件错误prepareRefresh();// Tell the subclass to refresh the internal bean factory.            //创建bean工厂 加载beanConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();// Prepare the bean factory for use in this context.//给bean工厂添加各种处理器等等prepareBeanFactory(beanFactory);try &#123;// Allows post-processing of the bean factory in context subclasses.//子类中调用beanfactory的后置处理postProcessBeanFactory(beanFactory);//实例化并执行所有后置处理器// Invoke factory processors registered as beans in the context.invokeBeanFactoryPostProcessors(beanFactory);// Register bean processors that intercept bean creation.//注册bean的解析器registerBeanPostProcessors(beanFactory);// Initialize message source for this context.//初始化消息源initMessageSource();// Initialize event multicaster for this context.//初始化bean名为applicationEventMulticaster 的事件广播器 没有就创建一个SimpleApplicationEventMulticasterinitApplicationEventMulticaster();// Initialize other special beans in specific context subclasses.//加载其他的bean 关键方法 ，需要由子类实现onRefresh 默认什么都不做onRefresh();// Check for listener beans and register them.registerListeners();// Instantiate all remaining (non-lazy-init) singletons.//实例化剩下的单例beanfinishBeanFactoryInitialization(beanFactory);// Last step: publish corresponding event.//初始化一个DefaultLifecycleProcessor//发布事件finishRefresh();&#125;catch (BeansException ex) &#123;if (logger.isWarnEnabled()) &#123;logger.warn(&quot;Exception encountered during context initialization - &quot; +&quot;cancelling refresh attempt: &quot; + ex);&#125;// Destroy already created singletons to avoid dangling resources.destroyBeans();// Reset &#39;active&#39; flag.cancelRefresh(ex);// Propagate exception to caller.throw ex;&#125;finally &#123;// Reset common introspection caches in Spring&#39;s core, since we// might not ever need metadata for singleton beans anymore...resetCommonCaches();&#125;&#125;&#125;///////////////////////protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123;refreshBeanFactory();ConfigurableListableBeanFactory beanFactory = getBeanFactory();if (logger.isDebugEnabled()) &#123;logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory);&#125;return beanFactory;&#125;    @Overrideprotected final void refreshBeanFactory() throws BeansException &#123;//如果有bean工厂则销毁所有bean和bean工厂        if (hasBeanFactory()) &#123;destroyBeans();closeBeanFactory();&#125;try &#123;            //创建一个DefaultListableBeanFactoryDefaultListableBeanFactory beanFactory = createBeanFactory();beanFactory.setSerializationId(getId());customizeBeanFactory(beanFactory);            //通过XmlBeanDefinitionReader 加载BeanDefinition            //DefaultBeanDefinitionDocumentReader 解析xmlloadBeanDefinitions(beanFactory);synchronized (this.beanFactoryMonitor) &#123;this.beanFactory = beanFactory;&#125;&#125;catch (IOException ex) &#123;throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex);&#125;&#125;</code></pre><blockquote><p>至此， 我们了解了下spring 的ApplicationContext 初始化的大致流程。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java的艺术-设计模式</title>
      <link href="/2019/11/04/2020-02-29-java%E7%9A%84%E8%89%BA%E6%9C%AF-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
      <url>/2019/11/04/2020-02-29-java%E7%9A%84%E8%89%BA%E6%9C%AF-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a><strong>单例模式</strong></h2><h3 id="饿汉模式"><a href="#饿汉模式" class="headerlink" title="饿汉模式"></a><em><strong>饿汉模式</strong></em></h3><pre><code class="language-java">public class SingleClass1 &#123;    private SingleClass1()&#123;&#125;        private static final SingleClass1 singleClass1 = new SingleClass1();        public static SingleClass1 getInstance() &#123;        return singleClass1;    &#125;&#125;</code></pre><h3 id="懒汉模式"><a href="#懒汉模式" class="headerlink" title="懒汉模式"></a><em><strong>懒汉模式</strong></em></h3><pre><code class="language-java">//线程不安全public class SingleClass1 &#123;    private SingleClass1()&#123;&#125;    private static SingleClass1 singleClass1;    public static SingleClass1 getInstance() &#123;        if(singleClass1==null)        &#123;singleClass1 = new SingleClass1();&#125;        return SingleClass1.singleClass1;    &#125;&#125;</code></pre><h3 id="内部类方式懒加载"><a href="#内部类方式懒加载" class="headerlink" title="内部类方式懒加载"></a><em><strong>内部类方式懒加载</strong></em></h3><pre><code class="language-java">public class SingleClass1 &#123;    private SingleClass1() &#123;    &#125;     private static class InnerClass&#123;       private  static final SingleClass1 singleClass1 = new SingleClass1();    &#125;    public static SingleClass1 getInstance() &#123;        return InnerClass.singleClass1;    &#125;&#125;</code></pre><h3 id="枚举方式懒加载"><a href="#枚举方式懒加载" class="headerlink" title="枚举方式懒加载"></a><em><strong>枚举方式懒加载</strong></em></h3><pre><code class="language-java">public class SingleClass1 &#123;    private SingleClass1() &#123;    &#125;    private enum InnerClass &#123;        /**         *         */        INSTANCE;        private final SingleClass1 singleClass1;        /**枚举类型的构造器只会被实例化一次*/        InnerClass() &#123;            singleClass1 = new SingleClass1();        &#125;        SingleClass1 getInstance() &#123;            return singleClass1;        &#125;    &#125;    public static SingleClass1 getInstance() &#123;        return InnerClass.INSTANCE.getInstance();    &#125;&#125;</code></pre><h3 id="双重校验锁懒加载"><a href="#双重校验锁懒加载" class="headerlink" title="双重校验锁懒加载"></a><em><strong>双重校验锁懒加载</strong></em></h3><pre><code class="language-java">//effectivejava中提供的方式public class SingleClass1 &#123;    private SingleClass1() &#123;    &#125;    //volatile 可以保证SingleClass1在初始化完成后再被加载    private static volatile SingleClass1 singleClass1;        public static SingleClass1 getInstance() &#123;        if (singleClass1 == null) &#123;            synchronized (SingleClass1.class) &#123;                if (singleClass1 == null) &#123;                    singleClass1 = new SingleClass1();                &#125;            &#125;        &#125;        return SingleClass1.singleClass1;    &#125;&#125;</code></pre><h2 id="观察者模式"><a href="#观察者模式" class="headerlink" title="观察者模式"></a><strong>观察者模式</strong></h2><img src="/.io//11/04/2020-02-29-java%E7%9A%84%E8%89%BA%E6%9C%AF-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/observer.png" class title="observer.png observer.png"><p>主体</p><pre><code class="language-java">public class Subject &#123;ArrayList&lt;Observer&gt; list = new ArrayList&lt;Observer&gt;();public Subject() &#123;&#125;public Subject register(Observer observer) &#123;list.add(observer);return this;&#125;public Subject remove(Observer observer) &#123;list.remove(observer);return this;&#125;private void notifyToObserver() &#123;if (!list.isEmpty()) &#123;for (Observer o : list) &#123;o.update();&#125;&#125;&#125;public void working()&#123;Optional.of(&quot;准备通知所有看着我的人 我获奖了&quot;).ifPresent(System.out::println);notifyToObserver();&#125;&#125;</code></pre><p>观察者</p><pre><code class="language-java">public interface Observer &#123;void update();&#125;class A implements Observer &#123;@Overridepublic void update() &#123;Optional.of(&quot;A: 他能获奖？&quot;).ifPresent(System.out::println);&#125;void  reg(Subject subject)&#123;subject.register(this);&#125;&#125;class B implements Observer &#123;@Overridepublic void update() &#123;Optional.of(&quot;B:我也想获奖&quot;).ifPresent(System.out::println);&#125;void  reg(Subject subject)&#123;subject.register(this);&#125;&#125;</code></pre><p>test</p><pre><code class="language-java">public class Test &#123;public static void main(String[] args) &#123;Subject subject = new Subject();new A().reg(subject);new B().reg(subject);subject.working();&#125;&#125;</code></pre><blockquote><p>我们可以看到，我们的观察者A和B观察到主体获奖之后也发表了自己的感慨！。</p></blockquote><img src="/.io//11/04/2020-02-29-java%E7%9A%84%E8%89%BA%E6%9C%AF-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/console_obserber.png" class title="console_obserber console_obserber"><h2 id="监听者模式"><a href="#监听者模式" class="headerlink" title="监听者模式"></a><strong>监听者模式</strong></h2><blockquote><p>个人认为 监听者和观察者最大的区别就是需要回调事件的方法 而观察者则调用观察者的方法。</p></blockquote><img src="/.io//11/04/2020-02-29-java%E7%9A%84%E8%89%BA%E6%9C%AF-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/listenner.png" class title="listenner.png listenner.png"><blockquote><p>首先我们提供一个监听器的集合来存储监听器，并提供监听器的注册方法，在要执行的具体方法时事件源注册给事件 再将事件注册给各个监听器，这时 ，监听器就可以触发所需的事件。</p></blockquote><pre><code class="language-java">public class EventSource &#123;//注册事件监听ArrayList&lt;MyEventListenner&gt; eventlist = new ArrayList&lt;&gt;();//报名 项目是否报名ArrayList&lt;String&gt; enlist = new ArrayList&lt;&gt;();EventSource registry(MyEventListenner eventListener) &#123;eventlist.add(eventListener);return this;&#125;//跑步项目void run() &#123;//事件委托给监听器if (!eventlist.isEmpty()) &#123;MyEvent event = new MyEvent(this);for (MyEventListenner e : eventlist)e.getevnsource(event);&#125;Optional.of(&quot;我终于可以参加跑步比赛了&quot;).ifPresent(System.out::println);&#125;//报名void enlist(String run) &#123;enlist.add(run);&#125;ArrayList&lt;String&gt; getenlist() &#123;return enlist;&#125;&#125;public class MyEvent extends EventObject &#123;public MyEvent(Object source) &#123;super(source);&#125;@Overridepublic Object getSource() &#123;return super.getSource();&#125;public void isenlist()&#123;//那个这个事件源判断他报没报名  if(!((EventSource)getSource()).getenlist().contains(&quot;run&quot;))  Optional.of(&quot;兄弟你没报名啊&quot;).ifPresent(System.out::println);&#125;public void isenlist1()&#123;if(!((EventSource)getSource()).getenlist().contains(&quot;run&quot;))Optional.of(&quot;兄弟赶紧报名啊&quot;).ifPresent(System.out::println);&#125;&#125;public abstract class MyEventListenner implements EventListener &#123;public abstract void getevnsource(EventObject eventObject);&#125;class MyEventListenner1 extends MyEventListenner &#123;@Overridepublic void getevnsource(EventObject eventObject) &#123;((MyEvent)eventObject).isenlist();&#125;&#125;class MyEventListenner2 extends MyEventListenner &#123;@Overridepublic void getevnsource(EventObject eventObject) &#123;((MyEvent)eventObject).isenlist1();&#125;&#125;public class Test1 &#123;public static void main(String[] args) &#123;EventSource eventSource = new EventSource();eventSource.registry(new MyEventListenner1()).registry(new MyEventListenner2()).run();try &#123;Thread.sleep(2000);&#125; catch (InterruptedException e) &#123;e.printStackTrace();&#125;eventSource.enlist(&quot;run&quot;);eventSource.run();&#125;&#125;</code></pre><img src="/.io//11/04/2020-02-29-java%E7%9A%84%E8%89%BA%E6%9C%AF-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/console_listenner.png" class title="console_listenner.png console_listenner.png"><ul><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始的高并发之路(三)</title>
      <link href="/2019/11/04/2020-02-29-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B9%8B%E8%B7%AF(%E4%B8%89)/"/>
      <url>/2019/11/04/2020-02-29-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B9%8B%E8%B7%AF(%E4%B8%89)/</url>
      
        <content type="html"><![CDATA[<h2 id="JMM内存模型"><a href="#JMM内存模型" class="headerlink" title="JMM内存模型"></a><strong>JMM内存模型</strong></h2><blockquote><p>  Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。为了保证数据的一致性，会通过总线锁或缓存一致性协议解决。</p></blockquote><p><img src="/.io//JMMmemoryModel.png" alt="JMMmemoryModel.png" title="JMMmemoryModel.png"></p><h2 id="缓存一致性协议MESI"><a href="#缓存一致性协议MESI" class="headerlink" title="缓存一致性协议MESI"></a><strong>缓存一致性协议MESI</strong></h2><blockquote><p>此处不会做过多的了解，主要只，当一个线程的从主存中将数据加载到缓存中，当缓存中的数据被修改时，会第一时间回写到主存，并将其他线程缓存中的数据置为失效，需要重新从主存中获取。</p></blockquote><ul><li>M(Modified)：这行数据有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。</li><li>  E(Exclusive)：这行数据有效，数据和内存中的数据一致，数据只存在于本Cache中。</li><li>  S(Shared)：这行数据有效，数据和内存中的数据一致，数据存在于很多Cache中。</li><li>  I(Invalid)：这行数据无效。</li></ul><h2 id="并发三大特性"><a href="#并发三大特性" class="headerlink" title="并发三大特性"></a><strong>并发三大特性</strong></h2><h3 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a><strong>可见性</strong></h3><blockquote><p>  可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。</p></blockquote><h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a><strong>原子性</strong></h3><blockquote><p>  即一个或者多个操作作为一个整体，要么全部执行，要么都不执行，并且操作在执行过程中不会被线程调度机制打断；而且这种操作一旦开始，就一直运行到结束，中间不会有任何上下文切换。</p></blockquote><h3 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a><strong>有序性</strong></h3><blockquote><p>  即程序执行的顺序按照代码的先后顺序执行。</p></blockquote><h2 id="指令重排"><a href="#指令重排" class="headerlink" title="指令重排"></a><strong>指令重排</strong></h2><blockquote><p>程序执行过程中, 为了性能考虑, 编译器和CPU可能会对指令重新排序.</p></blockquote><pre><code>修改JAVA_HOME/jre/lib/i386/jvm.cfg, 将jvm调整为server模式 server模式相较于client模式启动较慢 ，但运行更快，性能更高， 在server模式也更容易出现可见性问题 将文件中的server调整到client上方。-server KNOWN-client KNOWN</code></pre><h2 id="happens-before"><a href="#happens-before" class="headerlink" title="happens-before"></a><strong>happens-before</strong></h2><ul><li><strong>顺序原则</strong></li></ul><p>一个线程内保证语义的串行性; a &#x3D; 1; b &#x3D; a + 1;</p><ul><li><strong>volatile规则</strong></li></ul><p>volatile变量的写，先发生于读，这保证了volatile变量的可见性,</p><ul><li><strong>锁规则</strong></li></ul><p>解锁（unlock）必然发生在随后的加锁（lock）前.</p><ul><li><strong>传递性</strong></li></ul><p>A先于B，B先于C，那么A必然先于C.</p><ul><li><strong>线程启动法则</strong></li></ul><p>线程的start()方法先于它的每一个动作.</p><ul><li><strong>线程终结法则</strong></li></ul><p>线程的所有操作先于线程的终结 或者从Thread.join()中调用成功返回或者Thread.isAlive返回false</p><ul><li><strong>终结法则</strong></li></ul><p>对象的构造函数执行结束先于finalize()方法.</p><ul><li>中断法则<br>一个线程调用另一个线程的interrupt happen-before 于被中断的线程发现中断 （通过抛出innterruptedException 或者调用isinterrupted 和interrupted）</li></ul><h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a><strong>volatile</strong></h2><p>  volatile可以保证数据的可见性，当一个线程中的数据修改之后，这个修改是对其他线程可见的。effective java 中描述， 当一个线程对某一变量具有读操作，而其他线程可能同时对该变量有写操作，使用volatile 或者当一个线程对某一变量有写操作，而同时其他线程可能对改变了有读操作是使用volatile。</p><h2 id="读写锁设计思路"><a href="#读写锁设计思路" class="headerlink" title="读写锁设计思路"></a><strong>读写锁设计思路</strong></h2><p>当需求中对共享资源的读写操作读操作比较多时，对读写同时加锁就难念会浪费大量的资源，我们知道，多个线程读操作之间并不会产生线程安全问题，那么我们可以这样考虑下，我们看下表 ，多个线程直接当都是读操作时，我们其实并不需要锁，当出现写操作时则一定要加锁保证数据安全问题。</p><table border="1"><thead><tr>    <td width="100px"></td>    <td width="50px">读操作</td>    <td>写操作</td></tr></thead><tbody></tbody><tbody><tr>    <td>读操作</td>    <td>false</td>    <td>true</td></tr><tr>    <td>写操作</td>    <td>true</td>    <td>true</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多线程 </tag>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java基础查漏补缺</title>
      <link href="/2019/10/16/2019-10-16-java%E5%9F%BA%E7%A1%80%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/"/>
      <url>/2019/10/16/2019-10-16-java%E5%9F%BA%E7%A1%80%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="i-i-i–-–i"><a href="#i-i-i–-–i" class="headerlink" title="i++;++i;i–;–i"></a><strong>i++;++i;i–;–i</strong></h2><blockquote><p>i++ 原理 ，先将i压入栈中 ，再将i取出放到local variable区域1处，local variable 区域的位置1处的值压入到stack中。将local variable 区域的位置1处的值加1。再次压入栈中完成自增。</p></blockquote><pre><code class="language-java">public static void main(String[] args) throws  Exception &#123;        int i =100;        System.out.println(i++);//自增返回加法之前的结果 100        System.out.println(++i);// 自增 返回加法之后的结果102        System.out.println(i--);//返回减之前结果102        System.out.println(--i);//返回减之后的结果100    &#125;</code></pre><h2 id="值传递-引用传递"><a href="#值传递-引用传递" class="headerlink" title="值传递 引用传递"></a><strong>值传递 引用传递</strong></h2><pre><code class="language-java">static void a (StringBuffer s1 ,StringBuffer s2)    &#123;        s1.append(s2);        s2=s1;    &#125;    public static void main(String[] args) throws  Exception &#123;    StringBuffer s1 = new StringBuffer(&quot;A&quot;);        StringBuffer s2 = new StringBuffer(&quot;B&quot;);        a(s1,s2);        System.out.println(s1.toString()+s2.toString());//输出结果 AB,B    &#125;&#125;</code></pre><h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a><strong>继承</strong></h2><blockquote><p>子类继承父类方法 子类方法的修饰符要大于等于父类方法的修饰符 子类方法的抛出的异常范围要小于等于父类方法的异常 。 public &gt; project &gt; default &gt;private </p></blockquote><pre><code class="language-java">class ClassB &#123;        float getnum() throws  Exception&#123;         return 1.1f;     &#125;&#125;class ClassC  extends  ClassB&#123;    protected     float getnum() throws IOException &#123;        return 1.1f;    &#125;</code></pre><h2 id="if-else-和-switch-case-的区别"><a href="#if-else-和-switch-case-的区别" class="headerlink" title="if else 和 switch case 的区别"></a><strong>if else 和 switch case 的区别</strong></h2><blockquote><p>对于一个即可以使用ifelse又可以使用switch的代码段，如果判断较多优先使用switch， 因为switch使用btree算法只计算一次之后在跳转表中查找，而ifelse则是对每一条都进行判断直到通过或全部结束。</p></blockquote><h2 id="抽象类可以有构造器"><a href="#抽象类可以有构造器" class="headerlink" title="抽象类可以有构造器"></a><strong>抽象类可以有构造器</strong></h2><blockquote><p>抽象类可以有构造器,默认会生成一个protected的构造器,只是抽象类不能实例化，但这只是代表不应该有(不是不能有)public的构造器，抽象类的构造器可以为子类继承使用， 用来初始化抽象类中的成员变量。 例如：spring中的GenericBeanDefinition 继承自AbstractBeanDefinition。</p></blockquote><pre><code class="language-java">public class GenericBeanDefinition extends AbstractBeanDefinition &#123;public GenericBeanDefinition(BeanDefinition original) &#123;super(original);&#125;    ...&#125;----------------------------------------public abstract class AbstractBeanDefinition extends BeanMetadataAttributeAccessorimplements BeanDefinition, Cloneable &#123;    ...        protected AbstractBeanDefinition(BeanDefinition original) &#123;    ...    &#125;      ...        &#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2019-10-16-set集合之hashset</title>
      <link href="/2019/10/16/2019-10-16-set%E9%9B%86%E5%90%88%E4%B9%8Bhashset/"/>
      <url>/2019/10/16/2019-10-16-set%E9%9B%86%E5%90%88%E4%B9%8Bhashset/</url>
      
        <content type="html"><![CDATA[<blockquote><p>我们看这一段代码 ，输出结果应该是100 因为当hashset移除元素时调用hashmap的remove方法 在判断hash值时，要移除元素的hash值与存在hashmap中的hash值不同导致无法对hashmap的size进行减操作，导致最终获得到的结果是因为hashmap 的size加了100次，所有结果是100.</p></blockquote><pre><code class="language-java">public static void main(String[] args) throws  Exception &#123;        System.out.println(a=a+1);        System.out.println(x);             Set&lt;Short&gt; set = new HashSet();       for(short i =0 ;i &lt;100 ;i++)       &#123;           set.add(i);           set.remove(i-1);       &#125;        System.out.println(set.size());    &#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初识Go语言-环境配置</title>
      <link href="/2019/10/15/2019-10-15-%E5%88%9D%E8%AF%86Go%E8%AF%AD%E8%A8%80/"/>
      <url>/2019/10/15/2019-10-15-%E5%88%9D%E8%AF%86Go%E8%AF%AD%E8%A8%80/</url>
      
        <content type="html"><![CDATA[<h2 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h2><pre><code class="language-cmd">C:\Users\zhangzt&gt;go envset GO111MODULE=on //启用 gomodset GOARCH=amd64 set GOBIN=set GOCACHE=C:\Users\zhangzt\AppData\Local\go-buildset GOEXE=.exeset GOFLAGS=set GOHOSTARCH=amd64set GOHOSTOS=windowsset GOOS=windowsset GOPATH=C:\Users\zhangzt\go;C:\Users\zhangzt\go1 --工作目录 可以多个 用;分隔set GOPROXY=set GORACE=set GOROOT=C:\Go --go安装位置set GOTMPDIR=set GOTOOLDIR=C:\Go\pkg\tool\windows_amd64set GCCGO=gccgo //go垃圾回收 gcset CC=gccset CXX=g++set CGO_ENABLED=1set GOMOD=set CGO_CFLAGS=-g -O2set CGO_CPPFLAGS=set CGO_CXXFLAGS=-g -O2set CGO_FFLAGS=-g -O2set CGO_LDFLAGS=-g -O2set PKG_CONFIG=pkg-configset GOGCCFLAGS=-m64 -mthreads -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=C:\Users\zhangzt\AppData\Local\Temp\go-build736731342=/tmp/go-build -gno-record-gcc-switches</code></pre><h2 id="Go项目目录结构-gopath模式"><a href="#Go项目目录结构-gopath模式" class="headerlink" title="Go项目目录结构  (gopath模式)"></a>Go项目目录结构  (gopath模式)</h2><pre><code class="language-cmd">F:\GOPROJECT --工作目录├─bin --go编译可执行文件存放路径├─pkg --go编译包时，生成的.a文件存放路径└─src --源码路径。按照golang默认约定，go run，go install等命令的当前工作路径（即在此路径下执行上述命令）。    ├─myproject.com --域名    目录结构为 src -&gt;域名-&gt;具体项目-&gt; 源码    │  └─project --项目    └─myproject1.com</code></pre><hr><p><a href="https://code.visualstudio.com/">VSCode</a>安装后，安装中文和go插件，然后执行以下命令</p><ul><li>go get -u -v github.com&#x2F;nsf&#x2F;gocode</li><li>go get -u -v github.com&#x2F;rogpeppe&#x2F;godef</li></ul><blockquote><p>克隆 2个 git clone http s:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;tools.git git clone http s:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;lint.git 到 src&#x2F;golang.org&#x2F;x 目录下</p></blockquote><ul><li><p>go get golang.org&#x2F;x&#x2F;lint&#x2F;golint</p></li><li><p>go get -u -v github.com&#x2F;lukehoban&#x2F;go-find-references</p></li><li><p>go get -u -v github.com&#x2F;lukehoban&#x2F;go-outline</p></li><li><p>go get -u -v sourcegraph.com&#x2F;sqs&#x2F;goreturns</p></li><li><p>go get -u -v golang.org&#x2F;x&#x2F;tools&#x2F;cmd&#x2F;gorename</p></li><li><p>go get -u -v github.com&#x2F;tpng&#x2F;gopkgs</p></li><li><p>go get -u -v github.com&#x2F;newhook&#x2F;go-symbols</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Go语言 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Go语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅析HashMap</title>
      <link href="/2019/10/14/2019-10-14-HashMap/"/>
      <url>/2019/10/14/2019-10-14-HashMap/</url>
      
        <content type="html"><![CDATA[<h1 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a><strong>HashMap</strong></h1><blockquote><p>HashMap有数组+单向链表&#x2F;红黑树组成，他在数组大于DEFAULT_INITIAL_CAPACITY（2^4）*DEFAULT_LOAD_FACTOR（0.75f）时进行扩容，最大扩展MAXIMUM_CAPACITY（2^30）大小，而链表大于TREEIFY_THRESHOLD（8）时将链表转化为<a href>红黑树</a>。</p></blockquote><img src="/.io//10/14/2019-10-14-HashMap/hashmap1.png" class title="hashmap数据结构 hashmap"><h2 id="HashMap初始化参数"><a href="#HashMap初始化参数" class="headerlink" title="HashMap初始化参数"></a><strong>HashMap初始化参数</strong></h2><pre><code class="language-java">    /**     * The default initial capacity - MUST be a power of two.     * hashmap的默认容量 16     */    static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16    /**     * The maximum capacity, used if a higher value is implicitly specified     * by either of the constructors with arguments.     * MUST be a power of two &lt;= 1&lt;&lt;30.最大容量 2^30     */    static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;    /**     * 默认加载因子 可通过初始化时进行修改     * The load factor used when none specified in constructor.     */    static final float DEFAULT_LOAD_FACTOR = 0.75f;    /**     * The bin count threshold for using a tree rather than list for a     * bin.  Bins are converted to trees when adding an element to a     * bin with at least this many nodes. The value must be greater     * than 2 and should be at least 8 to mesh with assumptions in     * tree removal about conversion back to plain bins upon     * shrinkage. 链表大于该值时树化 必须是2的倍数     */    static final int TREEIFY_THRESHOLD = 8;    /**     * The bin count threshold for untreeifying a (split) bin during a     * resize operation. Should be less than TREEIFY_THRESHOLD, and at     * most 6 to mesh with shrinkage detection under removal.     * 小于该值时反树化     */    static final int UNTREEIFY_THRESHOLD = 6;    /**     * The smallest table capacity for which bins may be treeified.     * (Otherwise the table is resized if too many nodes in a bin.)     * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts     * between resizing and treeification thresholds.     * 最小树形化容量阈值：即 当哈希表中的容量 &gt; 该值时，才允许树化,否则直接扩容     */    static final int MIN_TREEIFY_CAPACITY = 64;    /**     * hashtable 数组     *     */    transient Node&lt;K,V&gt;[] table;    /**     * The number of key-value mappings contained in this map.     * hashmap大小     */    transient int size;    /**     * The next size value at which to resize (capacity * load factor).     *     * @serial     */    // (The javadoc description is true upon serialization.    // Additionally, if the table array has not been allocated, this    // field holds the initial array capacity, or zero signifying    // DEFAULT_INITIAL_CAPACITY.)    int threshold;    /**     * The load factor for the hash table.     * 加载因子     * @serial     */    final float loadFactor;    // 该构造方法可以初始化容量和加载因子大小    // public HashMap(int initialCapacity, float loadFactor)</code></pre><p><strong>链表</strong></p><pre><code class="language-java">static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;        final int hash;        final K key;        V value;        Node&lt;K,V&gt; next;        Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;            this.hash = hash;            this.key = key;            this.value = value;            this.next = next;        &#125;    &#125;</code></pre><p><strong><a href="https://zhangzt123.github.io/2019/10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/">红黑树</a></strong></p><p><img src="/.io//hashmap2.png" alt="树化转换简图" title="树化转换简图"></p><pre><code class="language-java">//继承自Node&lt;K,V&gt;static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123;        TreeNode&lt;K,V&gt; parent;  // red-black tree links        TreeNode&lt;K,V&gt; left;        TreeNode&lt;K,V&gt; right;        TreeNode&lt;K,V&gt; prev;    // needed to unlink next upon deletion        boolean red;//默认新结点都是红色 红色对红黑树影响最小        TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123;            super(hash, key, val, next);        &#125;        /**         *链表树化         * Forms tree of the nodes linked from this node.         * @return root of tree         */        final void treeify(Node&lt;K,V&gt;[] tab) &#123;            TreeNode&lt;K,V&gt; root = null;            //x从根节点开始 next 当前节点的下一个节点            for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123;//遍历链表                next = (TreeNode&lt;K,V&gt;)x.next;                 x.left = x.right = null;                if (root == null) &#123;                    x.parent = null; //根节点的父节点为null                    x.red = false; //根节点变色                    root = x;//x为根节点                &#125;                else &#123;                    K k = x.key;                     int h = x.hash;                    Class&lt;?&gt; kc = null;                    //从根节点开始遍历，                    //直到找到该节点在树中的位置进行插入                    for (TreeNode&lt;K,V&gt; p = root;;) &#123;                         int dir, ph;//                        K pk = p.key;                        //把链表第一个节点设定为根节点                        //用根节点循环和链表的下一个比较                        //判断当前节点是否大于上一个节点的hash值                        if ((ph = p.hash) &gt; h)                            dir = -1; //小于0为左子树                        else if (ph &lt; h)                            dir = 1;  //大于0右子树                        else if ((kc == null &amp;&amp;                                  (kc = comparableClassFor(k)) == null) ||                                 (dir = compareComparables(kc, k, pk)) == 0) //相等的话                            dir = tieBreakOrder(k, pk);//再次比较                        TreeNode&lt;K,V&gt; xp = p;//当前节点                        if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123;//判断左子树或右子树是否为null                            x.parent = xp;//当前链表的节点的父节点指向树中该节点对应的树节点                            if (dir &lt;= 0)                                xp.left = x;                            else                                xp.right = x;                            root = balanceInsertion(root, x);//重新平衡树节点                            break;                        &#125;                    &#125;                &#125;            &#125;            moveRootToFront(tab, root);        &#125;        /**         * Returns a list of non-TreeNodes replacing those linked from         * this node. 反树化 红黑树转化为链表         */        final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123;            Node&lt;K,V&gt; hd = null, tl = null;            for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123;                Node&lt;K,V&gt; p = map.replacementNode(q, null);                if (tl == null)                    hd = p;                else                    tl.next = p;                tl = p;            &#125;            return hd;        &#125;        /**         * Tree version of putVal.         */        final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab,                                       int h, K k, V v) &#123;            Class&lt;?&gt; kc = null;            boolean searched = false;            TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this;            for (TreeNode&lt;K,V&gt; p = root;;) &#123;                int dir, ph; K pk;                if ((ph = p.hash) &gt; h)                    dir = -1;                else if (ph &lt; h)                    dir = 1;                else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk)))                    return p;                else if ((kc == null &amp;&amp;                          (kc = comparableClassFor(k)) == null) ||                         (dir = compareComparables(kc, k, pk)) == 0) &#123;                    if (!searched) &#123;                        TreeNode&lt;K,V&gt; q, ch;                        searched = true;                        if (((ch = p.left) != null &amp;&amp;                             (q = ch.find(h, k, kc)) != null) ||                            ((ch = p.right) != null &amp;&amp;                             (q = ch.find(h, k, kc)) != null))                            return q;                    &#125;                    dir = tieBreakOrder(k, pk);                &#125;                TreeNode&lt;K,V&gt; xp = p;                if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123;                    Node&lt;K,V&gt; xpn = xp.next;                    TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn);                    if (dir &lt;= 0)                        xp.left = x;                    else                        xp.right = x;                    xp.next = x;                    x.parent = x.prev = xp;                    if (xpn != null)                        ((TreeNode&lt;K,V&gt;)xpn).prev = x;                    moveRootToFront(tab, balanceInsertion(root, x));                    return null;                &#125;            &#125;        &#125;        /**         * Removes the given node, that must be present before this call.         * This is messier than typical red-black deletion code because we         * cannot swap the contents of an interior node with a leaf         * successor that is pinned by &quot;next&quot; pointers that are accessible         * independently during traversal. So instead we swap the tree         * linkages. If the current tree appears to have too few nodes,         * the bin is converted back to a plain bin. (The test triggers         * somewhere between 2 and 6 nodes, depending on tree structure).         */        final void removeTreeNode(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab,                                  boolean movable) &#123;            int n;            if (tab == null || (n = tab.length) == 0)                return;            int index = (n - 1) &amp; hash;            TreeNode&lt;K,V&gt; first = (TreeNode&lt;K,V&gt;)tab[index], root = first, rl;            TreeNode&lt;K,V&gt; succ = (TreeNode&lt;K,V&gt;)next, pred = prev;            if (pred == null)                tab[index] = first = succ;            else                pred.next = succ;            if (succ != null)                succ.prev = pred;            if (first == null)                return;            if (root.parent != null)                root = root.root();            if (root == null || root.right == null ||                (rl = root.left) == null || rl.left == null) &#123;                tab[index] = first.untreeify(map);  // too small                return;            &#125;            TreeNode&lt;K,V&gt; p = this, pl = left, pr = right, replacement;            if (pl != null &amp;&amp; pr != null) &#123;                TreeNode&lt;K,V&gt; s = pr, sl;                while ((sl = s.left) != null) // find successor                    s = sl;                boolean c = s.red; s.red = p.red; p.red = c; // swap colors                TreeNode&lt;K,V&gt; sr = s.right;                TreeNode&lt;K,V&gt; pp = p.parent;                if (s == pr) &#123; // p was s&#39;s direct parent                    p.parent = s;                    s.right = p;                &#125;                else &#123;                    TreeNode&lt;K,V&gt; sp = s.parent;                    if ((p.parent = sp) != null) &#123;                        if (s == sp.left)                            sp.left = p;                        else                            sp.right = p;                    &#125;                    if ((s.right = pr) != null)                        pr.parent = s;                &#125;                p.left = null;                if ((p.right = sr) != null)                    sr.parent = p;                if ((s.left = pl) != null)                    pl.parent = s;                if ((s.parent = pp) == null)                    root = s;                else if (p == pp.left)                    pp.left = s;                else                    pp.right = s;                if (sr != null)                    replacement = sr;                else                    replacement = p;            &#125;            else if (pl != null)                replacement = pl;            else if (pr != null)                replacement = pr;            else                replacement = p;            if (replacement != p) &#123;                TreeNode&lt;K,V&gt; pp = replacement.parent = p.parent;                if (pp == null)                    root = replacement;                else if (p == pp.left)                    pp.left = replacement;                else                    pp.right = replacement;                p.left = p.right = p.parent = null;            &#125;            TreeNode&lt;K,V&gt; r = p.red ? root : balanceDeletion(root, replacement);            if (replacement == p) &#123;  // detach                TreeNode&lt;K,V&gt; pp = p.parent;                p.parent = null;                if (pp != null) &#123;                    if (p == pp.left)                        pp.left = null;                    else if (p == pp.right)                        pp.right = null;                &#125;            &#125;            if (movable)                moveRootToFront(tab, r);        &#125;        /** ------------------------------------------------------------         *Red-black tree methods, all adapted from CLR 左旋         * p 当前节点 root 根节点         * r 右子树 rl 右子树的左子树 pp 当前节点的父节点         */        static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateLeft(TreeNode&lt;K,V&gt; root,                                              TreeNode&lt;K,V&gt; p) &#123;            TreeNode&lt;K,V&gt; r, pp, rl;            if (p != null &amp;&amp; (r = p.right) != null) &#123;//判断当前节点和右子节点非空                if ((rl = p.right = r.left) != null)//右子树的左子树不等于null                     rl.parent = p; //rl的父节点指向p                if ((pp = r.parent = p.parent) == null) //p的父节点等于空 说明当前节点为根节点                    (root = r).red = false;//右子树变成根节点 变色                else if (pp.left == p)//当前节点是其父节点的左子树                    pp.left = r; //左旋后 p的父节点的左子树变成p的右子树                else                    pp.right = r;//左旋后 p的父节点的右子树变成p的右子树                r.left = p;  //左旋后r的左子树是p                p.parent = r;//p的父节点是r            &#125;            return root;        &#125;        //右旋同理        static &lt;K,V&gt; TreeNode&lt;K,V&gt; rotateRight(TreeNode&lt;K,V&gt; root,                                               TreeNode&lt;K,V&gt; p) &#123;            TreeNode&lt;K,V&gt; l, pp, lr;            if (p != null &amp;&amp; (l = p.left) != null) &#123;                if ((lr = p.left = l.right) != null)                    lr.parent = p;                if ((pp = l.parent = p.parent) == null)                    (root = l).red = false;                else if (pp.right == p)                    pp.right = l;                else                    pp.left = l;                l.right = p;                p.parent = l;            &#125;            return root;        &#125;        //树维持平衡        static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceInsertion(TreeNode&lt;K,V&gt; root,                                                    TreeNode&lt;K,V&gt; x) &#123;            x.red = true;//新插入的节点一定是红色            for (TreeNode&lt;K,V&gt; xp, xpp, xppl, xppr;;) &#123; //向上遍历直至根节点                if ((xp = x.parent) == null) &#123;//父节点是null，说明x是根节点 变黑色 红黑树情况1                    x.red = false;                    return x;                &#125;                else if (!xp.red || (xpp = xp.parent) == null)//父节点是黑色或祖父节点是null 红黑树情况2                    return root;                if (xp == (xppl = xpp.left)) &#123;//父节点是祖父节点的左节点                    if ((xppr = xpp.right) != null &amp;&amp; xppr.red) &#123;//叔叔节点不为空且是红色 红黑树情况3                        xppr.red = false;// 叔叔节点变色                        xp.red = false; //父节点变色                         xpp.red = true;// 祖父节点变色                        x = xpp; // 指向他的祖父节点 一直向上遍历直到根节点                    &#125;                    else &#123;//LR型 先按父节点左旋 再祖父节点右旋                         if (x == xp.right) &#123; //如果是父节点的右节点  情况4？                            root = rotateLeft(root, x = xp);//先进行左旋                            xpp = (xp = x.parent) == null ? null : xp.parent;                        &#125;                        if (xp != null) &#123;//父节点是祖父节点的左节点 父节点不是null 情况5？                            xp.red = false; //父节点黑色                            if (xpp != null) &#123; //父节点是祖父节点的左节点 父节点不是null 祖父节点不是null                                xpp.red = true; //祖父节点变为红色                                root = rotateRight(root, xpp);//右旋                            &#125;                        &#125;                    &#125;                &#125;                else &#123; //父节点是祖父节点的右节点                    if (xppl != null &amp;&amp; xppl.red) &#123; //叔叔节点不为空且是红色 变色                        xppl.red = false;                        xp.red = false;                        xpp.red = true;                        x = xpp;                    &#125;                    else &#123; //RL型 先以父节点右旋，再以祖父节点左旋                        if (x == xp.left) &#123;//父节点是祖父节点的右节点 且当前节点是父节点的左子树 父节点右旋                            root = rotateRight(root, x = xp);                            xpp = (xp = x.parent) == null ? null : xp.parent;                        &#125;                        if (xp != null) &#123; //祖父节点左旋                            xp.red = false;                            if (xpp != null) &#123;                                xpp.red = true;                                root = rotateLeft(root, xpp);                            &#125;                        &#125;                    &#125;                &#125;            &#125;        &#125;        static &lt;K,V&gt; TreeNode&lt;K,V&gt; balanceDeletion(TreeNode&lt;K,V&gt; root,                                                   TreeNode&lt;K,V&gt; x) &#123;            for (TreeNode&lt;K,V&gt; xp, xpl, xpr;;)  &#123;                if (x == null || x == root)                    return root;                else if ((xp = x.parent) == null) &#123;                    x.red = false;                    return x;                &#125;                else if (x.red) &#123;                    x.red = false;                    return root;                &#125;                else if ((xpl = xp.left) == x) &#123;                    if ((xpr = xp.right) != null &amp;&amp; xpr.red) &#123;                        xpr.red = false;                        xp.red = true;                        root = rotateLeft(root, xp);                        xpr = (xp = x.parent) == null ? null : xp.right;                    &#125;                    if (xpr == null)                        x = xp;                    else &#123;                        TreeNode&lt;K,V&gt; sl = xpr.left, sr = xpr.right;                        if ((sr == null || !sr.red) &amp;&amp;                            (sl == null || !sl.red)) &#123;                            xpr.red = true;                            x = xp;                        &#125;                        else &#123;                            if (sr == null || !sr.red) &#123;                                if (sl != null)                                    sl.red = false;                                xpr.red = true;                                root = rotateRight(root, xpr);                                xpr = (xp = x.parent) == null ?                                    null : xp.right;                            &#125;                            if (xpr != null) &#123;                                xpr.red = (xp == null) ? false : xp.red;                                if ((sr = xpr.right) != null)                                    sr.red = false;                            &#125;                            if (xp != null) &#123;                                xp.red = false;                                root = rotateLeft(root, xp);                            &#125;                            x = root;                        &#125;                    &#125;                &#125;                else &#123; // symmetric                    if (xpl != null &amp;&amp; xpl.red) &#123;                        xpl.red = false;                        xp.red = true;                        root = rotateRight(root, xp);                        xpl = (xp = x.parent) == null ? null : xp.left;                    &#125;                    if (xpl == null)                        x = xp;                    else &#123;                        TreeNode&lt;K,V&gt; sl = xpl.left, sr = xpl.right;                        if ((sl == null || !sl.red) &amp;&amp;                            (sr == null || !sr.red)) &#123;                            xpl.red = true;                            x = xp;                        &#125;                        else &#123;                            if (sl == null || !sl.red) &#123;                                if (sr != null)                                    sr.red = false;                                xpl.red = true;                                root = rotateLeft(root, xpl);                                xpl = (xp = x.parent) == null ?                                    null : xp.left;                            &#125;                            if (xpl != null) &#123;                                xpl.red = (xp == null) ? false : xp.red;                                if ((sl = xpl.left) != null)                                    sl.red = false;                            &#125;                            if (xp != null) &#123;                                xp.red = false;                                root = rotateRight(root, xp);                            &#125;                            x = root;                        &#125;                    &#125;                &#125;            &#125;        &#125;    &#125;</code></pre><h1 id="HashMap添加元素"><a href="#HashMap添加元素" class="headerlink" title="HashMap添加元素"></a><strong>HashMap添加元素</strong></h1><blockquote><p>hashmap通过put(K key, V value)方法添加数据，通过取余运算获取该元素要添加到数组的那个位置，如果已经是树了就直接添加到树里 否则再判断链表大小是否大于8来树化链表。</p></blockquote><pre><code class="language-java">public V put(K key, V value) &#123;        return putVal(hash(key), key, value, false, true);    &#125; /**     * Implements Map.put and related methods     *     * @param hash hash for key      * @param key the key     * @param value the value to put     * @param onlyIfAbsent if true, don&#39;t change existing value     * @param evict if false, the table is in creation mode.     * @return previous value, or null if none     */    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,                   boolean evict) &#123;        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;        if ((tab = table) == null || (n = tab.length) == 0)//判断节点数组是不是null 创建node数组            n = (tab = resize()).length;            //(n - 1) &amp; hash 取余        if ((p = tab[i = (n - 1) &amp; hash]) == null)//该key在数组中的位置是null 则创建新节点            tab[i] = newNode(hash, key, value, null);        else &#123;            Node&lt;K,V&gt; e; K k;            if (p.hash == hash &amp;&amp;                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))//如果他们key的hash值和key都相等 则替换为新的节点                e = p;            else if (p instanceof TreeNode) //判断是否已经是红黑树                e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);            else &#123;                for (int binCount = 0; ; ++binCount) &#123;                    if ((e = p.next) == null) &#123;                        p.next = newNode(hash, key, value, null);                        if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st 判断是否大于8 需要树化                            treeifyBin(tab, hash);                        break;                    &#125;                    if (e.hash == hash &amp;&amp;                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))//如果他们key的hash值和key都相等 则替换为新的节点                        break;                    p = e;                &#125;            &#125;            if (e != null) &#123; // existing mapping for key                 V oldValue = e.value;                if (!onlyIfAbsent || oldValue == null)                    e.value = value;                afterNodeAccess(e);                return oldValue;            &#125;        &#125;        ++modCount;        if (++size &gt; threshold)            resize();        afterNodeInsertion(evict);        return null;    &#125;TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123;        return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);    &#125;final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123;        int n, index; Node&lt;K,V&gt; e;        //判断链表是否为null或者链表长度小于最小树化容量        if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY)            resize();//扩容        else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123;//数组位置不是null            TreeNode&lt;K,V&gt; hd = null, tl = null;            do &#123;//循环链表                TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); //创建新树节点                if (tl == null)//表头？                    hd = p;                else &#123;                    p.prev = tl;//双向链表？                    tl.next = p;                &#125;                tl = p;            &#125; while ((e = e.next) != null);            if ((tab[index] = hd) != null)                hd.treeify(tab);//树化        &#125;    &#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>红黑树算法</title>
      <link href="/2019/10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/"/>
      <url>/2019/10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="树介绍"><a href="#树介绍" class="headerlink" title="树介绍"></a><strong>树介绍</strong></h1><blockquote><p>树的特点：</p></blockquote><ul><li><p>(1) 每个节点有零个或多个子节点</p></li><li><p>(2) 没有父节点的为根节点</p></li><li><p>(3) 每一个非根节点都有且只有一个父节点</p></li><li><p>(4) 除了根节点外， 每个子节点可以分为多个不想交的子树</p></li><li><p>结点 ： 指树的一个元素</p></li><li><p>结点的度： 指结点拥有的子树的个数 ，二叉树的度不大于2</p></li><li><p>叶子： 度为0 的节点</p></li><li><p>高度：叶子节点的高度为1 根节点高度最高</p></li><li><p>父节点： 若一个节点含有子节点，则它可成为其子节点的父节点</p></li><li><p>子节点： 父节点的下一层节点</p></li><li><p>层： 从根节点开始，根节点为一层子节点为二层，依次类推。</p></li><li><p>兄弟节点： 用于共同父节点的为兄弟节点</p></li></ul><h1 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h1><blockquote><p>一种特殊的树结构，只包含两个节点。他有五种状态，空集，根节点， 只包含左子树，只包含右子树，同时包含左右子树。</p></blockquote><h1 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h1><blockquote><p>平衡因子: 该节点的左子树高度减去该节点的右子树高度，大于等于2既表示为不平衡状态。  </p></blockquote><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/AVLTree_LL.png" class title="AVLTree_LL"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/AVLTree_LR.png" class title="AVLTree_LR"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/AVLTree_RR.png" class title="AVLTree_RR"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/AVLTree_RL.png" class title="AVLTree_RL"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/AVLTree_eg1.png" class title="AVLTree_eg1"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/AVLTree_eg2.png" class title="AVLTree_eg2"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/AVLTree_eg3.png" class title="AVLTree_eg3"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/AVLTree_eg4.png" class title="AVLTree_eg4"><h1 id="红黑树算法"><a href="#红黑树算法" class="headerlink" title="红黑树算法"></a><strong>红黑树算法</strong></h1><blockquote><p>&ensp;&ensp; 红黑树既自平衡二叉树，不会出现左子树和右子树过长的情况。红黑树适用于存储有序的数据结构，可以在O(logn)时间内做查找，插入和删除红黑树的特性有：</p></blockquote><ul><li><strong>节点为红色或黑色</strong></li><li><strong>根节点是黑色</strong></li><li><strong>每个红色节点的两个子节点必须是黑色（每个叶子节点到根节点不能出现两个相邻的红色）</strong></li><li><strong>每个叶子节点都是黑色的空节点</strong></li><li><strong>从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点</strong></li></ul><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/R-B-Tree1.png" class title="R-B-Tree1"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/R-B-Tree2.png" class title="R-B-Tree2"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/R-B-Tree3.png" class title="R-B-Tree3"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/R-B-Tree4.png" class title="R-B-Tree4"><hr><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/R-B-Tree5_1.png" class title="R-B-Tree5_1"><img src="/.io//10/10/2019-10-10-%E7%BA%A2%E9%BB%91%E6%A0%91%E7%AE%97%E6%B3%95/R-B-Tree5_2.png" class title="R-B-Tree5_2"><blockquote><p><strong>总结：变换主要由情况三四五进行循环变换，直至符合红黑树性质。</strong></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java二进制基础知识</title>
      <link href="/2019/10/03/2019-10-03-java%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
      <url>/2019/10/03/2019-10-03-java%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h1 id="进制转换"><a href="#进制转换" class="headerlink" title="进制转换"></a><strong>进制转换</strong></h1><blockquote><p><em>首先我们先来了解下进制间是如何转换的。</em>  </p></blockquote><h2 id="常用进制"><a href="#常用进制" class="headerlink" title="常用进制"></a><strong>常用进制</strong></h2><ul><li>二进制 : 0-1 逢二进一</li><li>八进制   0-7 逢八进一</li><li>十进制   0-9 逢十进一</li><li>十六进制 0-9 A-F表示10-15 逢十六进一</li></ul><h2 id="eg：二进制转10进制"><a href="#eg：二进制转10进制" class="headerlink" title="eg：二进制转10进制"></a><strong>eg：二进制转10进制</strong></h2><img src="/.io//10/03/2019-10-03-java%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%BD%AC%E5%8D%81%E8%BF%9B%E5%88%B6.jpg" class><blockquote><p><em>所有向十进制转换的都可以采用这样的方式进行计算，二进制以二为底 8进制以8为底，16进制以16为底</em></p></blockquote><h2 id="十进制转二进制"><a href="#十进制转二进制" class="headerlink" title="十进制转二进制"></a><strong>十进制转二进制</strong></h2><img src="/.io//10/03/2019-10-03-java%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%8D%81%E8%BF%9B%E5%88%B6%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6.jpg" class><h2 id="二进制的加减乘除"><a href="#二进制的加减乘除" class="headerlink" title="二进制的加减乘除"></a><strong>二进制的加减乘除</strong></h2><ul><li><strong>加法：</strong></li></ul><img src="/.io//10/03/2019-10-03-java%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%8A%A0%E6%B3%95.jpg" class><ul><li><strong>减法：</strong></li></ul><img src="/.io//10/03/2019-10-03-java%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%87%8F%E6%B3%95.jpg" class><ul><li><p><strong>乘法：</strong></p></li><li><p><strong>除法：</strong></p><blockquote><p>乘法除法暂未研究,后续会进行补充<br>了解了这么多我们开始java的位运算吧。</p></blockquote></li></ul><h1 id="JAVA位运算"><a href="#JAVA位运算" class="headerlink" title="JAVA位运算"></a><strong>JAVA位运算</strong></h1><blockquote><p><em>java中,位运算包括 ^（亦或）, &amp;（与），|（或） ,&lt;&lt;（左移）,&gt;&gt;（右移）,&lt;&lt;&lt;（无符号左移）,&gt;&gt;&gt;（无符号右移）在继续往下看之前，我们还要了解什么是机器码，由于计算机只能识别0和1， 所有在计算机中用0和1表示正负，这就是符号位（最高位表示），符号位连同数据一起代码化的就是机器码。机器码加绝对值表示的数值就是真值。机器码分有符号数和无符号数，无符号数由所有数值表示。</em></p></blockquote><blockquote><p><em>计算机系统中，数值一律用补码来表示：因为补码可以使符号位和数值位统一处理，同时可以使*<em>减法按照加法来处理</em></em>。数值编码分为原码，反码，补码，<strong>符号位（最高位）均为0正1负</strong>。*<br><em>原码表示最接近真值 ，规定最高位为符号位 0+ 1- 数值在符号位后面以绝对值给出</em><br><em>补码表示就是将符号位作为数值参与运算，并使所有加减以均以加法代替。<strong>负数的补码是原码取反加一，正数补码是它本身。</strong></em><br><em>反码是一种特殊的补码，反码的模比补码最低位小1</em></p></blockquote><ul><li><strong>原码 -&gt; 补码</strong>： 数值位取反加1.</li><li><strong>补码 -&gt; 原码</strong>： 对该补码的数值位 取反 加1.</li><li><strong>补码 的绝对值</strong>（称为真值）：正数的真值就是本身，负数的真值是各位（包括符号位）取反加1（即变成原码并把符号位取反）.</li></ul><hr><blockquote><p>NOTE* 补码”或”运算之后为补码</p></blockquote><h2 id="亦或"><a href="#亦或" class="headerlink" title="^(亦或)"></a><strong>^(亦或)</strong></h2><pre><code class="language-java">public static void main(String[] args) &#123;int a=-14;// 0000 1110int b=-9;//  0000 1001/*相同为0，不同为1 *//*     符号位（0）                       | 符号位（1）             14         取反       加一*      0000  1110   14                  |      1111 0010    -14 补码 0000 1110-&gt;1111 0001-&gt;1111 0010*   ^  0000  1001   9                   |  ^   1111 0111     -9 补码 0000 1001-&gt;1111 0110-&gt;1111 0111* ---------------                       | -----------------    补码&quot;异或&quot;运算之后为补码*      0000  0111 补码-&gt;源码 0000  0111  |      0000 0101 补码-&gt;源码  0000 0101*      1*2^2+1*2^1+1*2^0=7              | 1*2^2+1*2^0 =5    结果 5* */System.out.println(&quot;a与b:&quot;+String.valueOf(a^b));&#125;</code></pre><h2 id="与"><a href="#与" class="headerlink" title="&amp;(与)"></a><strong>&amp;(与)</strong></h2><pre><code class="language-java">public static void main(String[] args) &#123;int a=-1;//0000 0001 -&gt;1111 1110-&gt;1111 1111 负数 补符号位（符号位不变）1  取反加一int b=10;//0000 1010 符号位0/*同1为1，否则为0*//*                            |*      1111 1111  -1          |      1111 0010    -14 补码 0000 1110-&gt;1111 0001-&gt;1111 0010*   &amp;  0000 1010  10          |   &amp;  1111 0111     -9 补码 0000 1001-&gt;1111 0110-&gt;1111 0111* --------------              | ----------------*      0000 1010 -&gt;0000 1010  |      1111 0010  -&gt;  1000 1101-&gt;1000 1110*      1*2^3+1*2^1=10         |      1*2^3 +1*2^2+1*2^1= -14*      最高为是0,不用转化             如果最高位为1 即负数 最高位不变 其他位取反，加一 ** */System.out.println(&quot;a与b:&quot;+String.valueOf(a&amp;b));&#125;</code></pre><h2 id="或"><a href="#或" class="headerlink" title="|(或)"></a><strong>|(或)</strong></h2><pre><code class="language-java">public static void main(String[] args) &#123;int a=14;// 0000 1110int b=9;//  0000 1001/*有1为1，否则为0 *//*     符号位（0）                  |     符号位（1）                   负数最高位为1 其他位取反加一*      0000  1110   14             |      1111 0010    -14 补码0000 1110-&gt;1111 0001-&gt;1111 0010*   |  0000  1001   9              |  |   0000 1001     9  补码* ---------------                  | -----------------    *      0000  1111 -&gt;  0000  1111   |      1111 1011   -&gt;1000 0100 -&gt; 1000 0101 *                                  |      补码转原码取反加一*      1*2^3+1*2^2+1*2^1+1*2^0=15  |         1*2^2+1*2^0 =5   符号位为负 结果-5* */System.out.println(&quot;a与b:&quot;+String.valueOf(a|b));&#125;</code></pre><h2 id><a href="#" class="headerlink" title="&lt;&lt;(左移)"></a><strong>&lt;&lt;(左移)</strong></h2><blockquote><p>左移位运算符为«，其运算规则是：按二进制形式把所有的数字向左移动对应的位数，高位移出（舍弃），低位的空位补零。</p></blockquote><pre><code class="language-java">public static void main(String[] args) &#123;int a=-14;// 0000 1110int b=11; // 0000 1011/*                   |符号位（1）取反 | 加一*        0000 1110 -&gt;| 1111 0001 -&gt;  | 1111 0010*        &lt;&lt; 左移1  (1)舍去  1110 0100    左移后的补码 正数最高位补0，负数最高位补1*                          1001 1011    符号位不变 取反*                          1001 1100*                          -  1*2^2+1*2^3+1*2^4= 4+8+16=28*                  符号位为负 结果负28*---------------------------------------------------------------------*                     0 000 1011*        &lt;&lt; 左移1     0 000 1011 0 正数补0   正数的补码和原码相同*                     + 1*2^4+1*2^2+1*2^1= 22** */System.out.println(&quot;a与b:&quot;+String.valueOf(a&lt;&lt;1));System.out.println(&quot;a与b:&quot;+String.valueOf(b&lt;&lt;1));&#125;</code></pre><h2 id="右移"><a href="#右移" class="headerlink" title="&gt;&gt;(右移)"></a><strong>&gt;&gt;(右移)</strong></h2><blockquote><p>右位移运算符为»，其运算规则是：按二进制形式把所有的数字向右移动对应的位数，低位移出（舍弃），高位的空位补零。</p></blockquote><pre><code class="language-java">public static void main(String[] args) &#123;int a=-14;// 0000 1110int b=11; // 0000 1011/*                   |符号位（1）取反 | 加一*        0000 1110 -&gt;| 1111 0001 -&gt;  | 1111 0010*        &gt;&gt; 右移3  111 1111 0(010)舍去    左移后的补码 正数最高位补0，负数最高位补1*                  100 0000 1   符号位不变 取反*                  100 0001 0    +1*                  -     1*2^1=2*                  符号位为负 结果负2*                  右移与左移不同会把移出去的舍掉*---------------------------------------------------------------------*                     0 000 1011*        &gt;&gt; 右移3     0 000 0001（011）  正数补0   正数的补码和原码相同*                     + 1*2^0= 1** */System.out.println(&quot;a与b:&quot;+String.valueOf(a&gt;&gt;3));System.out.println(&quot;a与b:&quot;+String.valueOf(b&gt;&gt;3));&#125;</code></pre><h2 id="（取反）"><a href="#（取反）" class="headerlink" title="~（取反）"></a><strong>~（取反）</strong></h2><p>取反就是1为0,0为1</p><pre><code class="language-java">public static void main(String[] args) &#123;int a=~-14;// 0000 1110int b=~11; // 0000 1011/**     0000 1110 --&gt;1111 0001--&gt;1111 0010*     取反后 ---&gt; 0 000 1101  13*----------------------------------------------------------------*     0000 1011*     取反后 ---&gt; 1 111 0100 (最高位为1)负数 负数都是补码表示，所有要转换为原码*     转换后 ---&gt; 1 000 1100 --&gt; -12** */System.out.println(&quot;a与b:&quot;+String.valueOf(a));System.out.println(&quot;a与b:&quot;+String.valueOf(b));&#125;</code></pre><h2 id="无符号右移"><a href="#无符号右移" class="headerlink" title="&gt;&gt;&gt;(无符号右移)"></a><strong>&gt;&gt;&gt;(无符号右移)</strong></h2><pre><code class="language-java">public static void main(String[] args) &#123;int a = -14;// 0000 1110-&gt;1111 0010int b=11; // 0000 1011/**无符号右移中正数和负数计算方式不同，对于正数，不会改变成负数，对于负数，将会变成正数。* --------------------------------------------------* 负数无符号右移*   11111111111111111111111111110010*   00011111111111111111111111111110(010)舍去*      536870910* --------------------------------------------------* 正数无符号右移*  00000000000000000000000000001011*     00000000000000000000000000001(011)舍去*     1* */System.out.println(&quot;a无符号右移3:&quot;+String.valueOf(a&gt;&gt;&gt;3));System.out.println(&quot;b无符号右移3:&quot;+String.valueOf(b&gt;&gt;&gt;3));&#125;</code></pre><hr><blockquote><p>*<strong>NOTE:</strong> 遇到&amp;&#x3D; 、|&#x3D; 、 ^&#x3D; 、&gt;&gt;&#x3D; 、&gt;&gt;&gt;&#x3D;、 &lt;&lt;&#x3D;  这样的他们表示把计算后的变量重新赋值给变量，就和a+&#x3D;1 表示 a&#x3D;a+1 一样。<br>*<strong>NOTE:</strong> 为何无符号位移时有32位呢，请看下表    </p></blockquote><hr><!--| 数据结构   | 字节  | 范围                                        || :------   |:------|:--------------------------------------------||boolean|1   |true或false                                   ||char    |2   |从字符型对应的整型数来划分，其表示范围是0～65535  | |byte    |1   |-128～127                                     ||short    |2   |-32768～32767                                 ||int    |4   |-2147483648～2147483647 (-2^31 ~ 2^31-1)      ||long    |8   |-9223372036854775808 ~ 9223372036854775807    ||float    |4   |-3.4E38～3.4E38                               ||double    |8   |-1.7E308～1.7E308                             |--><table border="1"><thead><tr>    <td width="100px">数据结构</td>    <td width="50px">字节</td>    <td>范围</td></tr></thead><tbody></tbody><tr>    <td>boolean</td>    <td>1</td><td>true或false</td></tr><tr>    <td>char</td>    <td>2</td><td>从字符型对应的整型数来划分，其表示范围是0～65535</td></tr><tr>    <td>byte</td>    <td>1</td><td>-128～127 </td></tr><tr>    <td>short</td>    <td>2</td><td>-32768～32767  </td></tr><tr>    <td>int</td>    <td>4</td><td>-2147483648～2147483647 (-2^31 ~ 2^31-1)</td></tr><tr>    <td>long</td>    <td>8</td><td>-9223372036854775808 ~ 9223372036854775807</td></tr><tr>    <td>float</td>    <td>4</td><td>-3.4E38～3.4E38 </td></tr><tr>    <td>double</td>    <td>8</td><td>-1.7E308～1.7E308</td></tr></table><hr><!-- > *如有问题，请联系作者。* -->]]></content>
      
      
      <categories>
          
          <category> 计算机组成 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>从零开始的高并发之路(一)</title>
      <link href="/2019/10/02/2019-10-01-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B9%8B%E8%B7%AF(%E4%B8%80)/"/>
      <url>/2019/10/02/2019-10-01-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B9%8B%E8%B7%AF(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a><strong>多线程</strong></h2><h2 id="创建一个多线程的三种方式"><a href="#创建一个多线程的三种方式" class="headerlink" title="创建一个多线程的三种方式"></a><strong>创建一个多线程的三种方式</strong></h2><pre><code class="language-java">public class Testthread &#123;        public static void main(String[] args) &#123;        ThreadA threadA = new ThreadA();//第一种 继承thread        Thread threadB = new Thread(new ThreadB());//第二种 实现 Runnable        threadA.start();        threadB.start();        Thread threadC = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());            &#125;        &#125;); //第三种  匿名类        threadC.start();    &#125;   static  class ThreadA extends  Thread &#123;        @Override        public void run() &#123;            System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());        &#125;    &#125;    static  class ThreadB implements   Runnable &#123;        @Override        public void run() &#123;            System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());        &#125;    &#125;&#125;</code></pre><h2 id="线程状态"><a href="#线程状态" class="headerlink" title="线程状态"></a><strong>线程状态</strong></h2><blockquote><p>线程状态大致分为新建状态、就绪状态、运行状态、阻塞状态及死亡状态。 他们之间的联系见下图:</p></blockquote><p><img src="/.io//threadstatus.png" alt="threadstatus" title="百度图片"></p><ul><li><strong>新建状态 new</strong><br>&emsp;&emsp;新建状态既创建一个线程的实例，此时还未开始运行。</li><li><strong>就绪状态 runable</strong><br>&emsp;&emsp;线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu 的使用权 </li><li><strong>运行状态 running</strong><br>&emsp;&emsp;可运行状态(runnable)的线程获得了cpu 时间片（timeslice） ，执行程序run（）方法，直白点就是等待cpu调度的状态。</li><li><strong>阻塞状态 blocked</strong><br>&emsp;&emsp;阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行 以下几种方式会导致阻塞:<br>&emsp;&emsp;1.正在运行的线程通过调用sleep()方法进入等待阻塞状态，JVM会把该线程放入等待队列(waitting queue)中。<br>&emsp;&emsp;2.正在运行线程在获取对象的同步锁时，若该同步锁被别的线程占用，进入同步阻塞状态，则JVM会把该线程放入锁池(lock pool)中。<br>&emsp;&emsp;3.正在运行的线程产生了I&#x2F;O请求，JVM会把线程调整为阻塞状态，等待处理完成，再次进入可运行状态。</li><li><strong>死亡状态 termate</strong><br>&emsp;&emsp;线程正常完成退出或发生异常，线程死亡。</li></ul><hr><h2 id="策略模式在线程类中的应用"><a href="#策略模式在线程类中的应用" class="headerlink" title="策略模式在线程类中的应用"></a>策略模式在线程类中的应用</h2><blockquote><p>策略模式 本质：分离算法，选择实现 ,我们提供一个具体的策略角色AbstractClassA，它是对具体方法的抽象 ，可以由接口或抽象类完成 我们称他为<strong>抽象策略角色</strong>。 包含该策略必备的属性和方法。ClassB 和ClassC分别是策略的两种不同的策略执行角色，我们称之为<strong>具体策略角色</strong>，是对策略的实现。ClassD 是用来操作策略的角色，其职责本来是隔离客户端与策略类的耦合，让客户端完全与上下文环境沟通，无需关系具体策略,其被称为<strong>上下文角色</strong>，ClassD 内部一定会有一个策略类的一个成员变量(AbstractClassA),当我们需要实现具体的策略时，可以向ClassD中传入具体的策略的实现类，执行具体的策略。</p></blockquote><pre><code class="language-java">public abstract class AbstractClassA &#123;    /*    * 获取一个名字    * */    public abstract  String getname(String str);&#125;class ClassB extends  AbstractClassA&#123;    @Override    public String getname(String str) &#123;        return str;    &#125;&#125;class ClassC extends  AbstractClassA&#123;    @Override    public String getname(String str) &#123;        return &quot;hello world&quot;;    &#125;&#125; final  class  ClassD &#123;   private AbstractClassA a;    ClassD()&#123;    &#125;    ClassD(AbstractClassA a)&#123;        this.a=a;    &#125;    String getname(String str)    &#123;        if(a!=null)            return a.getname(str);        return null;    &#125;&#125;class ClassE&#123;    public static void main(String[] args) &#123;        String name = &quot;xiaoming&quot;;        ClassD D = new ClassD();        /*此时是未使用任何抽象类的 直接调用的我们ClassD的getname方法 */        System.out.println(D.getname(name));        ClassC c = new ClassC();        /*我们给ClassD中传入一个AbstractClassA 我们就可以自由的对AbstractClassA的getname方法进行实现*/        ClassD D1 = new ClassD(c);        System.out.println(D1.getname(name));        ClassB b = new ClassB();        ClassD D2 = new ClassD(b);        System.out.println(D2.getname(name));    &#125;&#125;&gt; 回过头我们再看thread类，thread中包含一个Runnable接口的抽象策略角色，而我们具体去实现Runnable的run方法时，我们就自己去实现了一个具体策略角色,thread类被定义为上下文类。其run方法通过构造方法传入具体的策略角色进行实现run方法。``` java@FunctionalInterfacepublic interface Runnable &#123;        public abstract void run();&#125;publicclass Thread implements Runnable &#123;     /* What will be run. */    private Runnable target;    public Thread(Runnable target) &#123;        init(null, target, &quot;Thread-&quot; + nextThreadNum(), 0);    &#125;    private void init(ThreadGroup g, Runnable target, String name,                      long stackSize) &#123;        init(g, target, name, stackSize, null, true);    &#125;    private void init(ThreadGroup g, Runnable target, String name,                      long stackSize, AccessControlContext acc,                      boolean inheritThreadLocals) &#123;        if (name == null) &#123;            throw new NullPointerException(&quot;name cannot be null&quot;);        &#125;        this.name = name;        Thread parent = currentThread();        SecurityManager security = System.getSecurityManager();        if (g == null) &#123;            /* Determine if it&#39;s an applet or not */            /* If there is a security manager, ask the security manager               what to do. */            if (security != null) &#123;                g = security.getThreadGroup();            &#125;            /* If the security doesn&#39;t have a strong opinion of the matter               use the parent thread group. */            if (g == null) &#123;                g = parent.getThreadGroup();            &#125;        &#125;        /* checkAccess regardless of whether or not threadgroup is           explicitly passed in. */        g.checkAccess();        /*         * Do we have the required permissions?         */        if (security != null) &#123;            if (isCCLOverridden(getClass())) &#123;                security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION);            &#125;        &#125;        g.addUnstarted();        this.group = g;        this.daemon = parent.isDaemon();        this.priority = parent.getPriority();        if (security == null || isCCLOverridden(parent.getClass()))            this.contextClassLoader = parent.getContextClassLoader();        else            this.contextClassLoader = parent.contextClassLoader;        this.inheritedAccessControlContext =                acc != null ? acc : AccessController.getContext();        this.target = target; //将具体策略类传入        setPriority(priority);        if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null)            this.inheritableThreadLocals =                ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);        /* Stash the specified stack size in case the VM cares */        this.stackSize = stackSize;        /* Set thread ID */        tid = nextThreadID();    &#125;    public synchronized void start() &#123;        /**         * This method is not invoked for the main method thread or &quot;system&quot;         * group threads created/set up by the VM. Any new functionality added         * to this method in the future may have to also be added to the VM.         *         * A zero status value corresponds to state &quot;NEW&quot;.         */        if (threadStatus != 0)            throw new IllegalThreadStateException();        /* Notify the group that this thread is about to be started         * so that it can be added to the group&#39;s list of threads         * and the group&#39;s unstarted count can be decremented. */        group.add(this);        boolean started = false;        try &#123;            start0();//调用c++ 的start0  c++再执行java的run方法            started = true;        &#125; finally &#123;            try &#123;                if (!started) &#123;                    group.threadStartFailed(this);                &#125;            &#125; catch (Throwable ignore) &#123;                /* do nothing. If start0 threw a Throwable then                  it will be passed up the call stack */            &#125;        &#125;    &#125;    private native void start0();     @Override    public void run() &#123;        if (target != null) &#123;            target.run(); //执行策略类的run方法        &#125;    &#125;&#125;</code></pre><blockquote><p>我们看到当我们实例化一个thread时，无论是那个构造函数最终都会调用private void init(ThreadGroup g, Runnable target, String name,long stackSize, AccessControlContext acc,boolean inheritThreadLocals)  这个方法，其中有个stacksize表示创建线程所使用的栈的大小，如果为传入的话，默认会由jni的c++ 自动初始化，我们通常不会使用这个参数，如果一定要使用，会通过直接设置java 的栈参数指定 -Xss&lt;size&gt; 指定java线程的栈大小。</p></blockquote><h2 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a><strong>守护线程</strong></h2><blockquote><p>守护线程会随着主线程的消亡而就是当进程不存在或主线程停止，守护线程也会被停止。</p></blockquote><pre><code class="language-java">public class Testthread &#123;    public static void main(String[] args) &#123;        ThreadA threadA = new ThreadA();//第一种 继承thread        threadA.setDaemon(true);//设定为守护线程 必须在start之前调用        threadA.start();            &#125;   static  class ThreadA extends  Thread &#123;        @Override        public void run() &#123;            System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());        &#125;    &#125;&#125;</code></pre><h2 id="线程优先级"><a href="#线程优先级" class="headerlink" title="线程优先级"></a>线程优先级</h2><blockquote><p>线程优先级通过设置一个 thread.setPriority(int newpriority)使该线程具有较高的优先级，cpu会优先分配资源给该线程。<strong>(不代表一定会优先执行)</strong> 范围是0-10 默认是5.</p></blockquote><pre><code class="language-java">public class Testthread &#123;    public static void main(String[] args) throws Exception &#123;        ThreadA threadA = new ThreadA();         Thread threadB = new Thread(new ThreadB(),&quot;thread-B&quot;);        threadA.setName(&quot;thread-A&quot;);        threadA.setPriority(1);        threadA.start();                //threadA.setDaemon(true);        threadB.setPriority(3);        threadB.start();                Thread threadC = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());            &#125;        &#125;,&quot;thread-C&quot;);        threadC.setPriority(2);        threadC.start();        //threadB.join();        //threadC.join();        System.out.println(java.lang.Thread.currentThread().getName());    &#125;   static  class ThreadA extends  Thread &#123;        @Override        public void run() &#123;            System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());        &#125;    &#125;    static  class ThreadB implements   Runnable &#123;        @Override        public void run() &#123;            System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());        &#125;    &#125;&#125;/** *执行结果 *main *这是一个线程thread-A *这是一个线程thread-C *这是一个线程thread-B */</code></pre><h2 id="thread-join"><a href="#thread-join" class="headerlink" title="thread.join()"></a>thread.join()</h2><blockquote><p>join方法的作用是父线程等待所有join的线程都执行完成后，才能继续用下运行 有join() ,join(long),join(long,int) 三种 。  </p></blockquote><ul><li>join() 等待所加入的线程完全执行完成。</li><li>join(long) 等待所加入的线程一段时间（毫秒） ，如果还未完成，父线程继续执行。</li><li>join(long,int)同上 精度更高 例如join(1000,10) 1000毫米10纳秒</li></ul><pre><code class="language-java">public class Testthread &#123;    public static void main(String[] args) throws Exception &#123;        ThreadA threadA = new ThreadA();         Thread threadB = new Thread(new ThreadB(),&quot;thread-B&quot;);        threadA.start();        //threadA.setDaemon(true);        threadB.start();        Thread threadC = new Thread(new Runnable() &#123;            @Override            public void run() &#123;                System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());            &#125;        &#125;);        threadC.start();        threadB.join();         threadC.join();//主线程main会等待线程B和线程C执行完成再执行        System.out.println(java.lang.Thread.currentThread().getName());    &#125;   static  class ThreadA extends  Thread &#123;        @Override        public void run() &#123;            System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());        &#125;    &#125;    static  class ThreadB implements   Runnable &#123;        @Override        public void run() &#123;            System.out.println(&quot;这是一个线程&quot;+ Thread.currentThread().getName());        &#125;    &#125;&#125;</code></pre><pre><code class="language-cmd">--没有joinmain这是一个线程Thread-0这是一个线程Thread-1这是一个线程Thread-2--有join这是一个线程Thread-0这是一个线程Thread-1这是一个线程Thread-2main</code></pre><blockquote><p>*<strong>NOTE:</strong> Thread.currentThread().join() 可以用来阻塞自己，线程一直在等自己死亡执行结束。</p></blockquote><hr><h2 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h2><blockquote><p>中断在方法在线程中包含5个方法，interrupt(),isInterrupted(boolean),isInterrupted()，interrupt0()和interrupted()。他在中断 sleep wait join方法时会抛InterruptedException异常。 </p></blockquote><ul><li>interrupt()设置为中断状态，不能真的中断线程。</li><li>interrupted() 当前线程设置中断状态</li><li>isInterrupted(boolean)可以修改中断状态 私有方法</li><li>isInterrupted()  返回中断状态</li></ul><pre><code class="language-java">private native void interrupt0(); //私有方法public void interrupt() &#123;        if (this != Thread.currentThread())            checkAccess();        synchronized (blockerLock) &#123;            Interruptible b = blocker;            if (b != null) &#123;                interrupt0();           // Just to set the interrupt flag                b.interrupt(this);                return;            &#125;        &#125;        interrupt0();    &#125; public boolean isInterrupted() &#123;        return isInterrupted(false);    &#125;public static boolean interrupted() &#123;        return currentThread().isInterrupted(true);    &#125;private native boolean isInterrupted(boolean ClearInterrupted);//私有方法</code></pre><h2 id="结束线程"><a href="#结束线程" class="headerlink" title="结束线程"></a>结束线程</h2><blockquote><p>我们知道在线程中，stop()方法存在安全问题，suspend()会发生死锁， 那么我们应该如何正确的结束一个线程呢，首先， 我们可以想到 ，守护线程会随着父线程的消亡而消亡，那么就可以把要执行的程序设置为某一父线程的守护线程，我们想办法让他的父线程停止，守护线程就随之停止了，然后，当我们中断一个线程时，被中断的线程在调用 wait sleep join 等方法时会抛出InterruptedException异常，终止当前线程，我们可以利用这个原理，中断守护线程的父线程。达到停止我们要执行的任务的目的。</p></blockquote><pre><code class="language-java">public class Threadinterrupt &#123;    public static void main(String[] args) &#123;        Threadservice threadservice = new Threadservice();        threadservice.exec(()-&gt;&#123;            while (true)&#123;                System.out.println(&quot;正在执行线程&quot;+Thread.currentThread().getName());                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;);        try &#123;            Thread.sleep(5000);            threadservice.stop();        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;class Threadservice&#123;    private Thread thread;       void  exec(Runnable runnable)       &#123;           if(thread==null)           thread = new Thread(()-&gt;&#123;               Thread threadinner = new Thread(runnable);               /*设定为守护线程*/               threadinner.setDaemon(true);               threadinner.start();           &#125;);           thread.start();           try &#123;               thread.join();           &#125; catch (InterruptedException e) &#123;               e.printStackTrace();               return;           &#125;       &#125;       void stop()       &#123;           /*调用*/           if(thread!=null&amp;&amp; thread.isAlive())           thread.interrupt();           System.out.println(&quot;中断守护线程的父线程&quot;);       &#125;&#125;</code></pre><h2 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h2><blockquote><p>CountDownLatch是一个同步工具类 可以理解为线程同步计数器</p></blockquote><pre><code class="language-java">public class countdownlatchdemo&#123;CountDownLatch c = new CountDownLatch(10);    for (int i=0; i&lt;9; i++) &#123;                new Thread(()-&gt;&#123;                c.countDown()                 System.out.println(Thread.currentThread().getThreadID);                &#125;).start();    &#125;c.await()&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多线程 </tag>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始的高并发之路(二)</title>
      <link href="/2019/10/01/2019-10-16-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B9%8B%E8%B7%AF(%E4%BA%8C)/"/>
      <url>/2019/10/01/2019-10-16-%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B9%8B%E8%B7%AF(%E4%BA%8C)/</url>
      
        <content type="html"><![CDATA[<h2 id="多线程安全"><a href="#多线程安全" class="headerlink" title="多线程安全"></a><strong>多线程安全</strong></h2><h3 id="同步关键字Synchronized"><a href="#同步关键字Synchronized" class="headerlink" title="同步关键字Synchronized"></a><strong>同步关键字Synchronized</strong></h3><blockquote><p>&emsp;&emsp;同步代码块可以解决多线程时，操作统一个类变量时的线程安全问题。他可以用来修饰方法和代码块 ，他有类锁和对象锁，一个类可以有多个对象，他们直接的锁是互不打扰的，而一个类只有一个类锁。我们看下面两个例子。第一个例子在对i进行自加时，多个线程同时获得一个数据，导致数据出现问题，我们看第二个，通过对自加操作进行加锁，这样，其他线程在要对i进行自加时，就要等正在做自加的线程完成后获得锁才能再进行自加。这样，数据就不会出现错乱的问题了。</p></blockquote><pre><code class="language-java">public class ThreadSync &#123;    static int i;    public static void main(String[] args) &#123;        for (int j = 0; j &lt; 10; j++) &#123;        Thread thread = new Thread(() -&gt; &#123;            for (int k = 0; k &lt; 100; k++) &#123;                add();                System.out.println(i + Thread.currentThread().getName());                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;);        thread.start();         &#125;    &#125;    static void add() &#123;        //System.out.println(&quot;加之前&quot;+i);           ++i;       // System.out.println(&quot;加之后&quot;+i);    &#125;&#125;</code></pre><pre><code class="language-cmd">结果: 我们看到结果输出了多个15  多个16 这样的 1Thread-03Thread-22Thread-34Thread-15Thread-46Thread-57Thread-68Thread-79Thread-910Thread-811Thread-012Thread-516Thread-716Thread-115Thread-415Thread-915Thread-313Thread-2......</code></pre><pre><code class="language-java">public class ThreadSync &#123;    static Object object = new Object();    static int i;    public static void main(String[] args) &#123;        for (int j = 0; j &lt; 10; j++) &#123;        Thread thread = new Thread(() -&gt; &#123;            for (int k = 0; k &lt; 100; k++) &#123;                add();                System.out.println(i + Thread.currentThread().getName());                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;);        thread.start();         &#125;    &#125;    static void add() &#123;        //System.out.println(&quot;加之前&quot;+i);        synchronized (object) &#123;           ++i;        &#125;       // System.out.println(&quot;加之后&quot;+i);    &#125;&#125;</code></pre><pre><code class="language-cmd">结果: 可以看到虽然不是按照顺序输出，但是，他不会出现重复的两个数字了1Thread-03Thread-22Thread-14Thread-35Thread-46Thread-97Thread-68Thread-79Thread-810Thread-512Thread-017Thread-419Thread-218Thread-918Thread-315Thread-714Thread-113Thread-8......</code></pre><blockquote><p>&emsp;&emsp;造成这样的原因是在多个线程同时对i进行加操作，第一个线程先把i加载进了工作内存，自加操作完成还未返回时，第二个线程又把i加载进了自己的工作内存，此时，两个线程中的i都是相同的，所有，他们自加是对同一个值进行的自加。</p></blockquote><h3 id="对象锁"><a href="#对象锁" class="headerlink" title="对象锁"></a><strong>对象锁</strong></h3><blockquote><p>&emsp;&emsp;对比下面两段代码，可以清晰看出 ，对象锁仅仅对同一个对象生效，第一个是在线程1输出之后在输出线程2 ，而第二个则是两个线程同时输出。他们消耗的时间几乎相同。</p></blockquote><pre><code class="language-java">// 使用同一个对象作为监视器public class ThreadSynchronizedObjLock &#123;    private final Object object= new Object();    public static void main(String[] args) &#123;        ThreadSynchronizedObjLock objlock = new ThreadSynchronizedObjLock();        Thread t1 = new Thread(()-&gt;&#123;            try &#123;                while (true)                &#123;objlock.A();Thread.sleep(500);&#125;            &#125; catch (InterruptedException e) &#123;e.printStackTrace();&#125;        &#125;);        Thread t2 = new Thread(()-&gt;&#123;            try &#123;                while (true)                &#123;objlock.B();Thread.sleep(500);&#125;            &#125; catch (InterruptedException e) &#123;e.printStackTrace();&#125;        &#125;);        t1.start();t2.start();    &#125;     void A() throws InterruptedException &#123;        synchronized (object)&#123;        long starttm = System.currentTimeMillis();        Thread.sleep(2000);        Optional.of(&quot;&quot;+Thread.currentThread().getName()+&quot;耗时：&quot;+(System.currentTimeMillis()-starttm)).ifPresent(System.out::println);&#125;    &#125;     void B() throws InterruptedException &#123;         synchronized (object) &#123;             long starttm = System.currentTimeMillis();             Thread.sleep(2000);             Optional.of(&quot;&quot; + Thread.currentThread().getName() + &quot;耗时：&quot; + (System.currentTimeMillis() - starttm)).ifPresent(System.out::println);         &#125;    &#125;&#125;</code></pre><pre><code class="language-java">public class ThreadSynchronizedObjLock &#123;    private final Object object= new Object();    public static void main(String[] args) &#123;        Thread t1 = new Thread(()-&gt;&#123;            try &#123;                while (true)                &#123;new ThreadSynchronizedObjLock().A();Thread.sleep(500);&#125;            &#125; catch (InterruptedException e) &#123;e.printStackTrace();&#125;        &#125;);        Thread t2 = new Thread(()-&gt;&#123;            try &#123;                while (true)                &#123;new ThreadSynchronizedObjLock().B();Thread.sleep(500);&#125;            &#125; catch (InterruptedException e) &#123;e.printStackTrace();&#125;        &#125;);        t1.start();t2.start();    &#125;     void A() throws InterruptedException &#123;        synchronized (object)&#123;        long starttm = System.currentTimeMillis();        Thread.sleep(2000);        Optional.of(&quot;&quot;+Thread.currentThread().getName()+&quot;耗时：&quot;+(System.currentTimeMillis()-starttm)).ifPresent(System.out::println);&#125;    &#125;     void B() throws InterruptedException &#123;         synchronized (object) &#123;             long starttm = System.currentTimeMillis();             Thread.sleep(2000);             Optional.of(&quot;&quot; + Thread.currentThread().getName() + &quot;耗时：&quot; + (System.currentTimeMillis() - starttm)).ifPresent(System.out::println);         &#125;    &#125;&#125;//两个结果几乎同时输出，说明锁住的不是同一个对象 两个锁之间相互毫无关系</code></pre><h3 id="this锁"><a href="#this锁" class="headerlink" title="this锁"></a><strong>this锁</strong></h3><blockquote><p>  this锁是一种特殊的对象锁 它指的是用当前实例来加锁。</p></blockquote><pre><code class="language-java">public class ThreadSynchronizedThisLock &#123;    private static int i = 0;    public static void main(String[] args) &#123;        ThreadSynchronizedThisLock lock = new ThreadSynchronizedThisLock();        new Thread(() -&gt; &#123;            while (true) &#123;                lock.add();                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;).start();        new Thread(() -&gt; &#123;            while (true) &#123;                lock.dec();                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;).start();    &#125;    void add() &#123;        synchronized (this) &#123;            long startme = System.currentTimeMillis();            i++;            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            Optional.of(&quot;i: &quot;+i+ &quot;当前线程为&quot;+ Thread.currentThread().getName()+&quot;耗时： &quot;+ (System.currentTimeMillis()-startme)).ifPresent(System.out::println);        &#125;    &#125;    void dec() &#123;        synchronized (this) &#123;            long startme = System.currentTimeMillis();            i--;            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            Optional.of(&quot;i: &quot;+i+ &quot;当前线程为&quot;+ Thread.currentThread().getName()+&quot;耗时： &quot;+ (System.currentTimeMillis()-startme)).ifPresent(System.out::println);        &#125;    &#125;&#125;// 当add运行时 dec被阻塞 dec运行时 add被阻塞</code></pre><blockquote><p>直接加在(实例方法)非静态方法前面是表示的是对当前对象加锁，和this代码块意义相同</p></blockquote><h3 id="类锁"><a href="#类锁" class="headerlink" title="类锁"></a><strong>类锁</strong></h3><blockquote><p>对比下面两个例子 无论是在对象本类中调用还是在对象中调用的方式，类锁都会对add 和dec的代码块进行加锁。</p></blockquote><pre><code class="language-java">public class ThreadSynchronizedClassLock &#123;    private final  Object object = new Object();    private static int i = 0;    public static void main(String[] args) &#123;        new Thread(() -&gt; &#123;            while (true) &#123;                add();                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;).start();        new Thread(() -&gt; &#123;            while (true) &#123;                dec();                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;).start();    &#125;    static void add() &#123;//一般会锁要操作的共享变量的类        synchronized (ThreadSynchronizedThisLock.class) &#123;            long startme = System.currentTimeMillis();            i++;            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            Optional.of(&quot;i: &quot;+i+ &quot;当前线程为&quot;+ Thread.currentThread().getName()+&quot;耗时： &quot;+ (System.currentTimeMillis()-startme)).ifPresent(System.out::println);        &#125;    &#125;    static void dec() &#123;        synchronized (ThreadSynchronizedThisLock.class) &#123;            long startme = System.currentTimeMillis();            i--;            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            Optional.of(&quot;i: &quot;+i+ &quot;当前线程为&quot;+ Thread.currentThread().getName()+&quot;耗时： &quot;+ (System.currentTimeMillis()-startme)).ifPresent(System.out::println);        &#125;    &#125;&#125;</code></pre><pre><code class="language-java">public class ThreadSynchronizedClassLock &#123;    private final  Object object = new Object();    private static int i = 0;    public static void main(String[] args) &#123;        new Thread(() -&gt; &#123;            while (true) &#123;                new ThreadSynchronizedClassLock().add();                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;).start();        new Thread(() -&gt; &#123;            while (true) &#123;                new ThreadSynchronizedClassLock().dec();                try &#123;                    Thread.sleep(1000);                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;).start();    &#125;     void add() &#123;//一般会锁要操作的共享变量的类        synchronized (ThreadSynchronizedThisLock.class) &#123;            long startme = System.currentTimeMillis();            i++;            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            Optional.of(&quot;i: &quot;+i+ &quot;当前线程为&quot;+ Thread.currentThread().getName()+&quot;耗时： &quot;+ (System.currentTimeMillis()-startme)).ifPresent(System.out::println);        &#125;    &#125;     void dec() &#123;        synchronized (ThreadSynchronizedThisLock.class) &#123;            long startme = System.currentTimeMillis();            i--;            try &#123;                Thread.sleep(2000);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            Optional.of(&quot;i: &quot;+i+ &quot;当前线程为&quot;+ Thread.currentThread().getName()+&quot;耗时： &quot;+ (System.currentTimeMillis()-startme)).ifPresent(System.out::println);        &#125;    &#125;&#125;</code></pre><p>***NOTE:**加载静态方法上的同步关键字也表示类锁</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h3><blockquote><p>synchronized 会在代码块前后添加 monitorenter，monitorexit 指令  线程执行到enter获得锁，exit后就会释放锁。  在使用对象锁和this锁时，他只对持有相同对象的代码块进行阻塞，在使用类锁时， 会对所有获取该类锁的代码块进行阻塞。</p></blockquote><h2 id="线程间通信"><a href="#线程间通信" class="headerlink" title="线程间通信"></a><strong>线程间通信</strong></h2><h3 id="线程等待与线程通知"><a href="#线程等待与线程通知" class="headerlink" title="线程等待与线程通知"></a><strong>线程等待与线程通知</strong></h3><ul><li><strong>sleep和wait的区别</strong><br>&emsp;&emsp;<strong>sleep:</strong> 1.sleep是Thread的方法。2.sleep可以在任意位置使用。3.sleep只会让出cpu，不会释放资源锁，在时间结束后重新开始执行。<br>&emsp;&emsp;<strong>wait:</strong> 1.wait是object的方法。 2. wait只能在同步块中使用。3.wait方法会使当前线程让出同步资源的锁。并放入一个等待队列中 ，使其他资源可以获得该锁，被通知后重新获得锁。</li></ul><hr><blockquote><p>我们看下面两个例子，第一个例子中，我们先让一个线程进入等待状态，这时他让出obj锁，第二个线程获得了该锁 wait后 他也释放的该锁，第三个线程开始执行，会通知等待队列的第一个正在等待的线程重新开始获得锁。第二个例子，首先5个线程启动后，都进入的等待状态，当我们调用notifyall后，会通知所有的等待队列所有的线程开始进行锁的竞争。</p></blockquote><ul><li><strong>wait set</strong></li></ul><p> <img src="/.io//waitset.png" alt="waitset.png" title="waitset"></p><blockquote><p>1.所有对象都会有一个wait set,用于存放调用了该对象wait方法之后进入block状态的线程,2.线程被notify之后，不一定会立即执行,线程会进入就绪状态准备抢锁。</p></blockquote><hr><ul><li>notify</li></ul><pre><code class="language-java">public class ThreadNotify &#123;    private static final Object obj = new Object();    public static void main(String[] args) throws InterruptedException &#123;        for(int i=0;i&lt;2;i++) &#123;            Thread thread1 = new Thread(() -&gt;            &#123;                mywait();            &#125;);            thread1.start();        &#125;        Thread.sleep(5000);        Thread thread2 = new Thread(() -&gt;        &#123;            mynotify();        &#125;);        thread2.start();    &#125;    static void mywait() &#123;        synchronized (obj) &#123;            try &#123;                Optional.of(&quot;我要开始等待了。。。。--&quot;+Thread.currentThread().getName()).ifPresent(System.out::println);                obj.wait();                Optional.of(&quot;我被通知不等了。。。。&quot;+Thread.currentThread().getName()).ifPresent(System.out::println);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;    static void mynotify() &#123;        synchronized (obj) &#123;            obj.notify();            Optional.of(&quot;我告诉自己不等了。。。。&quot;).ifPresent(System.out::println);        &#125;    &#125;&#125;</code></pre><ul><li><strong>notifyall</strong></li></ul><pre><code class="language-java">public class ThreadNotify &#123;    public static final Object obj = new Object();    public static void main(String[] args) throws InterruptedException &#123;        for(int i=0 ;i&lt;5 ;i++) &#123;            Thread thread1 = new Thread(() -&gt;            &#123;               new ThreadNotify().mywait();            &#125;);            thread1.start();        &#125;        Thread.sleep(5000);        Thread thread2 = new Thread(() -&gt;        &#123;            new ThreadNotify().mynotify();        &#125;);        thread2.start();    &#125;     void mywait() &#123;        synchronized (obj) &#123;            try &#123;                Optional.of(&quot;我要开始等待了。。。。--&quot;+Thread.currentThread().getName()).ifPresent(System.out::println);                obj.wait();                Optional.of(&quot;我被通知不等了。。。。&quot;+Thread.currentThread().getName()).ifPresent(System.out::println);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;     void mynotify() &#123;        synchronized (obj) &#123;            obj.notifyAll();            Optional.of(&quot;我告诉所有人别等了。。。。&quot;).ifPresent(System.out::println);        &#125;    &#125;&#125;</code></pre><hr>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多线程 </tag>
            
            <tag> 高并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM 虚拟机详解(一)</title>
      <link href="/2019/09/30/2019-09-30-JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%AF%A6%E8%A7%A3/"/>
      <url>/2019/09/30/2019-09-30-JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是JVM"><a href="#什么是JVM" class="headerlink" title="什么是JVM"></a>什么是JVM</h1><blockquote><p>&emsp;&emsp;Java 虚拟机是整个 Java 平台的基石，是 Java 语言生成出极小体积的编译代码的运行平台，Java 虚拟机可以看作是一台抽象的计算机，它有自己的指令集以及各种运行时内存区域，它与java语言没有必然的联系，只与二进制文件有所关联，我们知道class文件由java语言编译，class文件中包括字节码（指令集），符号表，及其他辅助信息，既一种不依赖于特定硬件和操作系统的二进制格式，它精确地定义了类与接口的表示形式 ，常以文件形式存在，jvm则接收这样的文件来执行程序。  </p></blockquote><h1 id="JVM虚拟机结构"><a href="#JVM虚拟机结构" class="headerlink" title="JVM虚拟机结构"></a>JVM虚拟机结构</h1><blockquote><p>JVM数据类型包括原始类型和基本类型。  </p></blockquote><ol><li>原始类型：<br>1.1 整数类型：byte 、short 、int、long、char<br>1.2 浮点类型：float 、double<br>1.3 布尔类型：boolean<br>1.4 returnAddress类型 ：returnAddress【表示一条字节码指令的操作码】</li><li>引用类型：Class Type 、Array Type 、Interface Type</li></ol><h1 id="运行时数据区"><a href="#运行时数据区" class="headerlink" title="运行时数据区"></a>运行时数据区</h1><blockquote><p>&emsp;&emsp;Java 虚拟机定义了若干种程序运行期间会使用到的运行时数据区，<strong>其中有一些会随着虚拟机启动而创建，随着虚拟机退出  而销毁</strong>。另外一些则是与线程一一对应的，这些与线程对应的数据区域会随着线程开始和结束而创建和销毁。运行时数据区<strong>包括 PC寄存器、java虚拟机栈、java堆、方法区、运行时常量池、和本地方法栈.</strong>  </p></blockquote><blockquote><p><strong>PC寄存器:</strong> 它可以支持多线程执行，一个正在被线程执行的方法被称为当前方法（CurrentMethod），如果这个方法是native（非java的）的 ，PC寄存器保存JVM执行字节码指令的地址。如果不是，则值是undefined。  </p></blockquote><blockquote><p><strong>java虚拟机栈:</strong> <strong>每一条 Java 虚拟机线程都有自己私有的 Java 虚拟机栈,它与线程同时创建，用于存储栈帧</strong>，和普通的栈一样，符合 “后进先出”原则。 另外，java虚拟机栈中使用的内存不要求是连续的。  </p></blockquote><blockquote><p><strong>栈帧:</strong> 用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接（Dynamic Linking）、方法返回值和异常分派(Dispatch Exception)。随着方法调用而创建，随着方法结束而销毁，<strong>每一个栈帧都有自己的局部变量表、操作数栈和指向当前方法所属的类的运行时常量池的引用</strong>，栈帧容量的大小仅仅取决于 Java 虚拟机的实现和方法调用时可被分配的内存。<strong>栈帧是线程本地私有的数据，不可能在一个栈帧之中引用另外一条线程的栈帧</strong>。   </p></blockquote><blockquote><p><strong>java堆:</strong> 堆（Heap）是可供各条线程共享的运行时内存区域，也是供所有类实例和数组对象分配内存的区域。存储了受GC（Garbage Collector[垃圾收集器】）管理的各种对象，如果实际内存超出最大内存会抛出<strong>OutOfMemoryError</strong>异常。  </p></blockquote><blockquote><p><strong>方法区:</strong> 供各条线程共享的运行时内存区域。它存储了每一个类的结构信息，例如运行时常量池（Runtime Constant Pool）、字段和方法数据、构造函数和普通方法的字节码内容、还包括一些在类、实例、接口初始化时用到的特殊方法。如果方法区的内存空间不能满足内存分配请求，抛出<strong>OutOfMemoryError</strong>异常。  </p></blockquote><blockquote><p><strong>运行时常量池:</strong> 每一个运行时常量池都分配在方法区，类和方法被加载后，常量池被创建。当创建类或接口的时候，如果构造运行时常量池所需要的内存空间超过了方法区所能提供的最大值，那 Java 虚拟机将会抛出一个 <strong>OutOfMemoryError</strong> 异常  </p></blockquote><blockquote><p><strong>本地方法栈:</strong> 用来支持非java语言的方法执行。既java中native 标识的方法。如果线程请求分配的栈容量超过本地方法栈允许的最大容量时， Java 虚拟机将会抛出一个 <strong>StackOverflowError</strong> 异常。      如果本地方法栈可以动态扩展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的本地方法栈，那 Java 虚拟机将会抛出一个 <strong>OutOfMemoryError</strong> 异常。  </p></blockquote><blockquote><p><strong>PC Register程序计数器:</strong> 指向方法区中的方法字节码（下一个将要执行的指令代码），由执行引擎读取下一条指令，是一个非常小的内存空间。</p></blockquote><img src="/.io//09/30/2019-09-30-JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%AF%A6%E8%A7%A3/jvm%E6%A8%A1%E5%9E%8B.png" class><blockquote><p>当我们通过类加载器把类加载进来时，首先存放在方法区中 这里把除了基本数据类型外存储的都是指向堆中的地址，具体的内容都存放在堆中。当我们执行某个方法时，把他压入栈中，再取出执行，每一个方法都会是一个栈帧，递归就是最好的例子，会反复的向栈中压入栈帧，直到返回。方法的执行则交由执行引擎执行，程序计数器指明下一个执行的指令。</p></blockquote><h1 id="jvm调优"><a href="#jvm调优" class="headerlink" title="jvm调优"></a>jvm调优</h1><blockquote><p>&emsp;&emsp;要想了解JVM调优相关的知识，首先我们要知道，JVM的运行原理，我们了解我们当每启动一个JAVA应用就会产生一个java虚拟机实例，那么他是怎么运行的呢，首先，我们会把我们编写的.java文件编译为.class的二进制文件，然后JVM经由<strong>Class Loader</strong>将class文件加载至运行时数据区，之后交由执行引擎进行方法执行。在jdk1.7之前，jvm分为新生代（young）、养老代（old）、以及永久代（permanent） 而新生代有分为伊甸区（eden），和2个存活区（servivor），在1.8中，取消掉了永久区，转而用元空间（metaspace）代替，元空间在本地内存中。我们可以通过非标准参数和非Stable参数命令查看有哪些可以使用的参数。  </p></blockquote><img src="/.io//09/30/2019-09-30-JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%AF%A6%E8%A7%A3/javaX.jpg" class title="java -x java-x"><img src="/.io//09/30/2019-09-30-JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%AF%A6%E8%A7%A3/javaXX.jpg" class title="java -XX:+PrintFlagsFinal java-XX:+PrintFlagsFinal"><blockquote><p>从这上面两幅图中可以看出我们有大量的参数以供选择，下面就先列出常用的一些参数。  </p></blockquote><ul><li>-XX:PermSize&#x3D;512M -XX:MaxPermSize&#x3D;1024M （<strong>1.8以前</strong>）-XX:MetaspaceSize&#x3D;512M XX:MaxMetaspaceSize&#x3D;1024M (** 1.8 **)</li><li>-Xms256m -Xmx512m java堆内存的最大值最小值，一般设定为老年代存活对象的3-4倍。</li><li>-Xss128k：设置每个线程的堆栈大小。</li><li>-XX:NewRatio&#x3D;4 表示新生代和养老代的比例为1:4。</li><li>-XX:SurvivorRatio&#x3D;4 表示伊甸区和存活区（默认有2个存活区）的比例为2:4。</li><li>-XX:MaxTenuringThreshold&#x3D;7 指的是一个对象在存活区移动了7次还未被回收则进入养老代。</li><li>……等等。 [^ parm_more]</li></ul><hr><h1 id="GC垃圾回收"><a href="#GC垃圾回收" class="headerlink" title="GC垃圾回收"></a>GC垃圾回收</h1><hr><blockquote><p>更对内容后续更新</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2019-09-29-ArrayList与LinkedList与Vector</title>
      <link href="/2019/09/29/2019-09-29-ArrayList%E4%B8%8ELinkedList%E4%B8%8EVector/"/>
      <url>/2019/09/29/2019-09-29-ArrayList%E4%B8%8ELinkedList%E4%B8%8EVector/</url>
      
        <content type="html"><![CDATA[<h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a><strong>序言</strong></h1><blockquote><p>&emsp;&emsp;在我们的日常编码中，ArrayList、LinkedList、Vector 这三个是我们经常使用的几个集合，通常，我们会定义一个ArrayList类来存储一个对象的集合，那么 ，他和数组之间有什么不同呢，我们知道，ArrayList和LinkedList之间，当我们在不考虑线程安全情况下，我们通过是要做频繁的操作还是对的数据频繁的查找速度来判断是否采用哪个合适，这又是为什么呢，在多线程的情况下，为什么说ArrayList线程不安全呢，  接下来，带着这些问题， 我将带着大家从源码角度逐步分析，慢慢揭开他们神秘的面纱。</p></blockquote><h1 id="集合关系图"><a href="#集合关系图" class="headerlink" title="集合关系图"></a><strong>集合关系图</strong></h1><blockquote><p>  &emsp;&emsp;我们看这样一幅简图， 图中我们可以看出三者关系，ArrayList，Vector和LinkedList分别继承AbstractListList和AbstractSequentialList ，三者都实现了List接口。 在继续之前，我们先来学习些基础的<a href="https://zhangzt123.github.io/2019/10/03/2019-10-03-java%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">位运算知识</a>吧</p></blockquote><img src="/.io//09/29/2019-09-29-ArrayList%E4%B8%8ELinkedList%E4%B8%8EVector/%E5%9B%BE%E4%B8%80.jpg" class title="图1"><h2 id="ArrayList和Vector"><a href="#ArrayList和Vector" class="headerlink" title="ArrayList和Vector"></a><strong>ArrayList和Vector</strong></h2><blockquote><p>平时，我们在使用ArrayList时候，我们可以常使用 add方法，可get方法，remove方法，等来操作ArrayList的数据。此处 ，我们可以采用数组模拟这样一个集合。如下虽然游标位置有所不同但确实实现了类似arraylist的效果。</p></blockquote><pre><code class="language-java">/** * @author zhangzt */public class MyArrayList &#123;//初始化一个大小为10的数组MyArrayList()&#123;data=new Object[10];&#125;//数据的集合Object[] data;//MyArrayList的大小 int默认值为0int size;//添加数据public void add(Object obj)&#123;//判断要插入数据是否满足data数组的大小 不满足需要自动扩容int temp =size+1;if(temp&gt;data.length)// 判断范围&#123;//扩容copy(data,data.length*2);&#125;//满足条件就把数据插入数组data[size++]=obj;&#125;//获取指定位置的数据public Object get(int index)&#123;if(index&lt;=size) &#123;return data[index-1];&#125;else &#123;return null;&#125;&#125;//移除指定位置的数据public boolean remove(int index)&#123;if(index&lt;=size)&#123; // 判断是否在MyArrayList 大小范围里data[index-1]=null;for(int i=index-1;i&lt;data.length;i++)&#123;data[i]=i+1&gt;=data.length?null:data[i+1];&#125;size--;return true;&#125;else&#123;return false;&#125;&#125;//复制数组到新数组private void copy(Object[] olddata, int i) &#123;if (olddata != null &amp;&amp; i &gt; olddata.length) &#123;Object[] newdata = new Object[i];for (int j = 0; j &lt; olddata.length; j++) &#123;newdata[j] = olddata[j];&#125;data = newdata;&#125;&#125;&#125;class MyArrayListTest&#123;public static MyArrayList myArrayList = new MyArrayList();public static void main(String[] args) &#123;myArrayList.add(&quot;11&quot;);myArrayList.add(&quot;12&quot;);myArrayList.add(&quot;13&quot;);myArrayList.add(&quot;14&quot;);myArrayList.add(&quot;15&quot;);System.out.println(myArrayList.size);System.out.println(&quot;第一个元素&quot;+myArrayList.get(1));System.out.println( &quot;第二个元素&quot;+myArrayList.get(2));myArrayList.remove(1);System.out.println(&quot;第一个元素&quot;+myArrayList.get(1));////////////////////////////////////////////////////////ArrayList&lt;String&gt; arrayList= new ArrayList&lt;&gt;();arrayList.add(&quot;11&quot;);arrayList.add(&quot;12&quot;);arrayList.add(&quot;13&quot;);arrayList.add(&quot;14&quot;);arrayList.add(&quot;15&quot;);System.out.println(arrayList.size());System.out.println(&quot;第一个元素&quot;+arrayList.get(1));System.out.println( &quot;第二个元素&quot;+arrayList.get(2));arrayList.remove(1);System.out.println(&quot;第一个元素&quot;+arrayList.get(1));&#125;&#125;</code></pre><blockquote><p>接下来我们看下在真正的Arraylist中是如何实现的。首先我们可以看到他有很多的成员变量，其中最为重要的就是elementData和size 分别表示存储的数据和大小。</p></blockquote><pre><code class="language-java"> /**     * Default initial capacity.     * 默认初始化的容量大小     */    private static final int DEFAULT_CAPACITY = 10;    /**     * Shared empty array instance used for empty instances.     * 为 ArrayList(int initialCapacity) 分配一个空数组     */    private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;    /**     * Shared empty array instance used for default sized empty instances. We     * distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when     * first element is added.     *为ArrayList()分配一个空数组  通过当第一次add()时扩容来区分EMPTY_ELEMENTDATA     */    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;    /**     * The array buffer into which the elements of the ArrayList are stored.     * The capacity of the ArrayList is the length of this array buffer. Any     * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA     * will be expanded to DEFAULT_CAPACITY when the first element is added.     *任何一个ArrayList都用它存储，他的容量就是ArrayList的容量，任何一个ArrayList     *的elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA 当第一次add()时     *将扩容到DEFAULT_CAPACITY（10）     */    transient Object[] elementData; // non-private to simplify nested class access    /**     * The size of the ArrayList (the number of elements it contains).     *  ArrayList的大小      * @serial     */    private int size;    </code></pre><blockquote><p>*<strong>NOTE:</strong> transient 表示成员变量不参与序列化过程。</p></blockquote><blockquote><p>*<strong>NOTE:</strong> 声明的变量是临时变量是不会初始化的，只有类的成员变量才会被初始化 eg：ArrayList的size 全局默认为0</p></blockquote><pre><code class="language-java">/**    * Appends the specified element to the end of this list.    * 追加明确的元素到list最后    * @param e element to be appended to this list    * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;)    */   public boolean add(E e) &#123;       ensureCapacityInternal(size + 1);  // Increments modCount!! 扩容       elementData[size++] = e;       return true;   &#125;</code></pre><pre><code class="language-java">private void ensureCapacityInternal(int minCapacity) &#123;       if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;//判断是不是初始那个数组（第一次add）           minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);//和初始化大小比较取大的       &#125;       ensureExplicitCapacity(minCapacity);   &#125;</code></pre><pre><code class="language-java">private void ensureExplicitCapacity(int minCapacity) &#123;       modCount++;       // overflow-conscious code       if (minCapacity - elementData.length &gt; 0)//判断是否大于现在的大小           grow(minCapacity);   &#125;</code></pre><pre><code class="language-java">private void grow(int minCapacity) &#123;       // overflow-conscious code       int oldCapacity = elementData.length;//假设旧的大小为10        int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //10&gt;&gt;1  10 右移 1// 1010 --&gt; 0101 --&gt;5 十进制//扩容后的为10 + 5 =15 扩容到15 原来的1.5倍       if (newCapacity - minCapacity &lt; 0)           newCapacity = minCapacity;       if (newCapacity - MAX_ARRAY_SIZE &gt; 0)           newCapacity = hugeCapacity(minCapacity);       // minCapacity is usually close to size, so this is a win:       elementData = Arrays.copyOf(elementData, newCapacity);//数组复制//Arrays.copyof 最终调用System.arraycopy 这是个native方法 //所有他会调用底层c++ 的 复制方法把一个数组向另一个数组复制   &#125;</code></pre><pre><code class="language-java">public static void arraycopy(Object src,int srcPos,Object dest, int destPos,int length)/**Object src：源数组*int srcPos：源数组下标*Object dest：目标数组*int destPos：目标数组下标*int length：复制的长度* */</code></pre><blockquote><p>接下来我们看get和remove方法</p></blockquote><pre><code class="language-java">//获取指定位置元素public E get(int index) &#123;       rangeCheck(index);       return elementData(index);   &#125;//移除指定位置元素 返回指定位置的旧值public E remove(int index) &#123;           rangeCheck(index);       modCount++;//迭代器使用暂不考虑       E oldValue = elementData(index);//获得旧值       int numMoved = size - index - 1;       if (numMoved &gt; 0)           System.arraycopy(elementData, index+1, elementData, index,                            numMoved);//将自己的被删除位置向前复制一个位置，复制numMoved长度       elementData[--size] = null; // 置为null触发GC       return oldValue;    &#125;//校验移除的值是否是list的范围里private void rangeCheck(int index) &#123;       if (index &gt;= size)           throw new IndexOutOfBoundsException(outOfBoundsMsg(index));   &#125;</code></pre><pre><code class="language-java">//和删除同理public void add(int index, E element) &#123;       rangeCheckForAdd(index);       ensureCapacityInternal(size + 1);  // Increments modCount!!       System.arraycopy(elementData, index, elementData, index + 1,                        size - index);       elementData[index] = element;       size++;   &#125;</code></pre><blockquote><p>看到这可能有很多让人会问他和数组间到底有啥区别呢，就我个人理解他们的区别在于数组的灵活性没有ArrayList高，如果你想在数组的指定位置插入数据将会非常的麻烦，而且我们知道，要声明一个数组就需要指定数组的大小，那么我们无法准确的确定这个值到底应该是多大，所有就可能会出现不够用，或浪费内存的问题，而ArrayList的自动扩缩容解决了这个问题。使之更加灵活，但相对数组会有微量的性能的牺牲。</p></blockquote><hr><blockquote><p>接着，我们查看Vector的源码，我们看到，他和ArrayList拥有类似的方法，唯一较为特别的地方就是每个方法上都拥有synchronized关键字，他表示这个方法是同步的，，这时就涉及到了在多线程的环境下，为什么说ArrayList是不安全的，Vector是安全的，我们回看ArrayList的add方法，我们注意到，集合大小的增加采用size++ 的方式，size++表示我们首先要先将size加载到内存中，然后在执行加操作，也就是说这不是个原子性的操作，例如，启动了2个线程，线程A先把size加载到工作内存中，线程B也把size加载到工作内存中，当A执行完毕返回后，由于B线程中所使用的并不是A加完之后的结果，所有会导致，A线程添加的数据会被B线程替换掉，导致数据错乱，产生非常严重的后果。在Vector中，add方法被synchronized修饰，通过锁保证了size++的原子性，表示当A 正在执行的时候，B是不可以执行add操作的，会在add方法上添加monitorenter 和monitorexit 阻塞B的执行,B等待A执行完毕后再次执行add的操作。</p></blockquote><pre><code class="language-java">public synchronized boolean add(E e) &#123;        modCount++;        ensureCapacityHelper(elementCount + 1);        elementData[elementCount++] = e;        return true;    &#125;</code></pre><hr><h2 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a><strong>LinkedList</strong></h2><blockquote><p>linkedlist由一个双向链表组成，他的每个节点包含指向它上一个的节点和指向下一个的节点。他与Arraylist不同，并非由连续的内存组成。LinkedList初始化可通过 LinkedList() 和LinkedList(Collection&lt;? extends E&gt; c) 两种方式，两种方式都没有初始化LinkedList大小的方法。说明LinkedList自动扩展大小的。</p></blockquote><pre><code class="language-java">//LinkedList大小transient int size = 0;    /**    指向第一个元素     * Pointer to first node.     * Invariant: (first == null &amp;&amp; last == null) ||     *            (first.prev == null &amp;&amp; first.item != null)     */    transient Node&lt;E&gt; first;    /**指向最后一个元素     * Pointer to last node.     * Invariant: (first == null &amp;&amp; last == null) ||     *            (last.next == null &amp;&amp; last.item != null)     */    transient Node&lt;E&gt; last;/**初始化一个空的list     * Constructs an empty list.     */    public LinkedList() &#123;    &#125;    /**通过一个特殊的集合构建一个list     * Constructs a list containing the elements of the specified     * collection, in the order they are returned by the collection&#39;s     * iterator.     *     * @param  c the collection whose elements are to be placed into this list     * @throws NullPointerException if the specified collection is null     */    public LinkedList(Collection&lt;? extends E&gt; c) &#123;        this();        addAll(c);    &#125;     public boolean addAll(Collection&lt;? extends E&gt; c) &#123;        return addAll(size, c);    &#125;     public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123;        checkPositionIndex(index);        Object[] a = c.toArray();        int numNew = a.length;        if (numNew == 0)            return false;        Node&lt;E&gt; pred, succ;        if (index == size) &#123;//如果要添加的位置和集合大小相同 则从last开始添加新节点            succ = null;            pred = last;        &#125; else &#123; //否则从指定节点开始            succ = node(index);            pred = succ.prev;        &#125;        //遍历用来构建的集合转成的数组        for (Object o : a) &#123;            @SuppressWarnings(&quot;unchecked&quot;) E e = (E) o;            Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null);            if (pred == null)                first = newNode;            else                pred.next = newNode; //pred（最后一个节点或指定节点的的上一个节点）的下一个节点是新节点            pred = newNode;//修改为新节点 用于数组中下一个节点的添加时从新结点开始        &#125;        if (succ == null) &#123;            last = pred;        &#125; else &#123;            pred.next = succ; //数组中的节点连接完成后 将最后一个节点连接到查找到的节点            succ.prev = pred; //查找到的节点的上一个节点连接为新节点        &#125;        size += numNew;//原集合大小+数组大小        modCount++;        return true;    &#125;//校验索引是一个大于等于0 且在list范围内 的数private void checkPositionIndex(int index) &#123;        if (!isPositionIndex(index))            throw new IndexOutOfBoundsException(outOfBoundsMsg(index));    &#125;private boolean isPositionIndex(int index) &#123;        return index &gt;= 0 &amp;&amp; index &lt;= size;    &#125;//查找节点 判断索引位置 小于一半时从头开始遍历 反之从尾开始遍历Node&lt;E&gt; node(int index) &#123;        // assert isElementIndex(index);        //       eg: 10 右移1 等于5        if (index &lt; (size &gt;&gt; 1)) &#123;            Node&lt;E&gt; x = first;            for (int i = 0; i &lt; index; i++)                x = x.next;            return x;        &#125; else &#123;            Node&lt;E&gt; x = last;            for (int i = size - 1; i &gt; index; i--)                x = x.prev;            return x;        &#125;    &#125;</code></pre><blockquote><p>添加节点方法有 add(E e) ,add(int index, E element)，addAll(int index, Collection&lt;? extends E&gt; c)，addFirst(E e),addLast(E e) 几种，分别表示在集合最后添加一个节点，在指定位置添加节点，在指定位置添加一个集合，在list开头添加一个节点，和在list最后添加一个节点。  删除节点同理， 就是修改指向要删除节点的指针，并把要删除的节点置为null有利于GC回收， 以下是Linkedlist源码。  </p></blockquote><pre><code class="language-java">//创建新的节点，使它的下个节点为原来的frist节点，修改原来frist节点的prev节点为新节点private void linkFirst(E e) &#123;        final Node&lt;E&gt; f = first;        final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f);        first = newNode;        if (f == null)            last = newNode;        else            f.prev = newNode;        size++;        modCount++;    &#125;//创建新的节点，使他prev节点为原来的last节点，修改原来的last节点的next节点为新节点void linkLast(E e) &#123;        final Node&lt;E&gt; l = last;        final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null);        last = newNode;        if (l == null)            first = newNode;        else            l.next = newNode;        size++;        modCount++;    &#125;void linkBefore(E e, Node&lt;E&gt; succ) &#123;        // assert succ != null;        final Node&lt;E&gt; pred = succ.prev;//要插入节点的上一个节点        final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); //创建新结点时上一个节点是pred 下一个节点是要插入的节点        succ.prev = newNode;//改要插入节点的上一个节点是新结点        if (pred == null)            first = newNode;        else            pred.next = newNode;//pred的下一个节点是新结点        size++;        modCount++;    &#125;public boolean add(E e) &#123;        linkLast(e);        return true;    &#125;public void add(int index, E element) &#123;        checkPositionIndex(index);//校验大于0 小于List大小        if (index == size)            linkLast(element);        else            linkBefore(element, node(index));    &#125;public void addFirst(E e) &#123;        linkFirst(e);    &#125; public void addLast(E e) &#123;        linkLast(e);    &#125;</code></pre><blockquote><p>获取节点元素有getFirst()，getLast()，get(int index)，他们可以通过首尾位置遍历，查找到对应的节点并获得到相应的数据。</p></blockquote><pre><code class="language-java">public E getFirst() &#123;        final Node&lt;E&gt; f = first;        if (f == null)            throw new NoSuchElementException();        return f.item;    &#125;public E getLast() &#123;        final Node&lt;E&gt; l = last;        if (l == null)            throw new NoSuchElementException();        return l.item;    &#125;public E get(int index) &#123;        checkElementIndex(index);        return node(index).item;    &#125;</code></pre><blockquote><p>Linkedlist同时实现了Deque接口，表示他可以成为一个<strong>没有大小限制的队列或栈</strong>，我们知道，队列满足”先进先出”原则，而栈则是符合”后进先出 ，先进后出”原则，我们可以通过offer(E e) 和poll() 方法实现入队出队，可以用push(E e)和pop()来实现栈。</p></blockquote><pre><code class="language-java">     public boolean offer(E e) &#123;        return add(e);//在队尾添加元素    &#125;    public E poll() &#123;        final Node&lt;E&gt; f = first;         return (f == null) ? null : unlinkFirst(f);//获取第一个节点的元素    &#125;    private E unlinkFirst(Node&lt;E&gt; f) &#123;        // assert f == first &amp;&amp; f != null;        final E element = f.item;        final Node&lt;E&gt; next = f.next;        f.item = null;        f.next = null; // help GC        first = next;        if (next == null)            last = null;        else            next.prev = null;        size--;        modCount++;        return element;    &#125;    public void push(E e) &#123;        addFirst(e);    &#125;    public E pop() &#123;        return removeFirst();    &#125;</code></pre><blockquote><p>回到问题中 ， 通过源码， 我们知道Arraylist是有数组实现， 是一块连续的内存空间，在查找指定元素时，通过索引就可以快速的取得，而当要扩展时，通过copy数组的方式来实现，而LinkedList则是由一个双向链表实现，当我们要查找指定元素是，需要遍历整个链表获取，但是 ，由于它是不连续的内存空间，当需要扩展是，只需要修改链表中节点的指针就可以实现。这就是Arraylist和linkedlist之间最本质的区别。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅析java集合</title>
      <link href="/2019/09/29/2019-09-29-%E6%B5%85%E6%9E%90java%E9%9B%86%E5%90%88/"/>
      <url>/2019/09/29/2019-09-29-%E6%B5%85%E6%9E%90java%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p> 集合类是Java数据结构的实现。Java的集合类是java.util包中的重要内容，它允许以各种方式将元素分组，并定义了各种使这些元素更容易操作的方法。Java集合类是Java将一些基本的和使用频率极高的基础类进行封装和增强后再以一个类的形式提供。集合类是可以往里面保存多个对象的类，存放的是对象，不同的集合类有不同的功能和特点，适合不同的场合，用以解决一些实际问题。</p>]]></content>
      
      
      <categories>
          
          <category> JAVA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
